#!/usr/bin/env python3
"""
Test ISNADI Linker on Surah Al-Fath (48:29)

This script tests the complete pipeline:
1. C2B morphological analysis
2. WordForm conversion
3. ISNADI link detection

Author: Hussein Hiyassat
Date: 2025-02-13
"""

import sys
import json
sys.path.insert(0, 'src')

from fvafk.cli.main import main as cli_main
from fvafk.c2b.word_form.word_form_builder import build_word_forms
from fvafk.syntax.linkers import find_isnadi_links
import subprocess

# The verse
VERSE = """Ù…ÙÙ‘Ø­ÙÙ…ÙÙ‘Ø¯ÙŒ Ø±ÙÙ‘Ø³ÙÙˆÙ„Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù ÙˆÙØ§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ù…ÙØ¹ÙÙ‡Ù Ø£ÙØ´ÙØ¯ÙÙ‘Ø§Ø¡Ù Ø¹ÙÙ„ÙÙ‰ Ø§Ù„Ù’ÙƒÙÙÙÙ‘Ø§Ø±Ù Ø±ÙØ­ÙÙ…ÙØ§Ø¡Ù Ø¨ÙÙŠÙ’Ù†ÙÙ‡ÙÙ…Ù’ ØªÙØ±ÙØ§Ù‡ÙÙ…Ù’ Ø±ÙÙƒÙÙ‘Ø¹Ù‹Ø§ Ø³ÙØ¬ÙÙ‘Ø¯Ù‹Ø§ ÙŠÙØ¨Ù’ØªÙØºÙÙˆÙ†Ù ÙÙØ¶Ù’Ù„Ù‹Ø§ Ù…ÙÙ‘Ù†Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù ÙˆÙØ±ÙØ¶Ù’ÙˆÙØ§Ù†Ù‹Ø§ Ø³ÙÙŠÙ…ÙØ§Ù‡ÙÙ…Ù’ ÙÙÙŠ ÙˆÙØ¬ÙÙˆÙ‡ÙÙ‡ÙÙ… Ù…ÙÙ‘Ù†Ù’ Ø£ÙØ«ÙØ±Ù Ø§Ù„Ø³ÙÙ‘Ø¬ÙÙˆØ¯Ù Ø°ÙÙ°Ù„ÙÙƒÙ Ù…ÙØ«ÙÙ„ÙÙ‡ÙÙ…Ù’ ÙÙÙŠ Ø§Ù„ØªÙÙ‘ÙˆÙ’Ø±ÙØ§Ø©Ù ÙˆÙÙ…ÙØ«ÙÙ„ÙÙ‡ÙÙ…Ù’ ÙÙÙŠ Ø§Ù„Ù’Ø¥ÙÙ†Ø¬ÙÙŠÙ„Ù ÙƒÙØ²ÙØ±Ù’Ø¹Ù Ø£ÙØ®Ù’Ø±ÙØ¬Ù Ø´ÙØ·Ù’Ø£ÙÙ‡Ù ÙÙØ¢Ø²ÙØ±ÙÙ‡Ù ÙÙØ§Ø³Ù’ØªÙØºÙ’Ù„ÙØ¸Ù ÙÙØ§Ø³Ù’ØªÙÙˆÙÙ‰Ù° Ø¹ÙÙ„ÙÙ‰Ù° Ø³ÙÙˆÙ‚ÙÙ‡Ù ÙŠÙØ¹Ù’Ø¬ÙØ¨Ù Ø§Ù„Ø²ÙÙ‘Ø±ÙÙ‘Ø§Ø¹Ù Ù„ÙÙŠÙØºÙÙŠØ¸Ù Ø¨ÙÙ‡ÙÙ…Ù Ø§Ù„Ù’ÙƒÙÙÙÙ‘Ø§Ø±Ù ÙˆÙØ¹ÙØ¯Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù Ø¢Ù…ÙÙ†ÙÙˆØ§ ÙˆÙØ¹ÙÙ…ÙÙ„ÙÙˆØ§ Ø§Ù„ØµÙÙ‘Ø§Ù„ÙØ­ÙØ§ØªÙ Ù…ÙÙ†Ù’Ù‡ÙÙ… Ù…ÙÙ‘ØºÙ’ÙÙØ±ÙØ©Ù‹ ÙˆÙØ£ÙØ¬Ù’Ø±Ù‹Ø§ Ø¹ÙØ¸ÙÙŠÙ…Ù‹Ø§"""

print("="*80)
print("ğŸ•Œ Testing ISNADI Linker on Surah Al-Fath (48:29)")
print("="*80)
print()

# Step 1: Run C2B pipeline
print("ğŸ“Š Step 1: Running C2B morphological analysis...")
print()

result = subprocess.run(
    ['python3', '-m', 'fvafk.cli', VERSE],
    capture_output=True,
    text=True,
    cwd='.'
)

if result.returncode != 0:
    print("âŒ Error running CLI:")
    print(result.stderr)
    sys.exit(1)

c2b_output = json.loads(result.stdout)
print(f"âœ… Analyzed {len(c2b_output['c2b']['words'])} words")
print()

# Step 2: Convert to WordForms
print("ğŸ”„ Step 2: Converting to WordForm instances...")
print()

word_forms = build_word_forms(c2b_output['c2b']['words'])
print(f"âœ… Created {len(word_forms)} WordForm instances")
print()

# Step 3: Find ISNADI links
print("ğŸ”— Step 3: Detecting ISNADI links (Ù…Ø¨ØªØ¯Ø£/Ø®Ø¨Ø±)...")
print()

links = find_isnadi_links(word_forms)
print(f"âœ… Found {len(links)} ISNADI link(s)")
print()

# Step 4: Display results
print("="*80)
print("ğŸ“‹ DETECTED ISNADI RELATIONS")
print("="*80)
print()

if len(links) == 0:
    print("âš ï¸  No ISNADI links detected")
    print()
    print("Possible reasons:")
    print("- No nominal sentences (Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø§Ø³Ù…ÙŠØ©) found")
    print("- Ù…Ø¨ØªØ¯Ø£ and Ø®Ø¨Ø± don't agree in case/number/gender")
    print("- Sentences are verbal (Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©)")
else:
    for i, link in enumerate(links, 1):
        mubtada = word_forms[link.head_id]
        khabar = word_forms[link.dependent_id]
        
        print(f"Link {i}:")
        print(f"  Ù…Ø¨ØªØ¯Ø£: {mubtada.surface}")
        print(f"    â€¢ Position: {mubtada.span.start}-{mubtada.span.end}")
        print(f"    â€¢ Case: {mubtada.case.arabic}")
        print(f"    â€¢ Number: {mubtada.number.arabic}")
        print(f"    â€¢ Gender: {mubtada.gender.arabic}")
        print(f"    â€¢ Definite: {mubtada.is_definite}")
        print()
        print(f"  Ø®Ø¨Ø±: {khabar.surface}")
        print(f"    â€¢ Position: {khabar.span.start}-{khabar.span.end}")
        print(f"    â€¢ Case: {khabar.case.arabic}")
        print(f"    â€¢ Number: {khabar.number.arabic}")
        print(f"    â€¢ Gender: {khabar.gender.arabic}")
        print(f"    â€¢ Definite: {khabar.is_definite}")
        print()
        print(f"  Confidence: {link.confidence:.2%}")
        print(f"  Reason: {link.reason}")
        print()
        print("-" * 80)
        print()

# Step 5: Word-by-word analysis
print("="*80)
print("ğŸ“ WORD-BY-WORD ANALYSIS")
print("="*80)
print()

print(f"{'#':<4} {'Word':<20} {'POS':<10} {'Case':<10} {'Num':<8} {'Gender':<8} {'Def':<5}")
print("-" * 80)

for i, wf in enumerate(word_forms):
    print(f"{i:<4} {wf.surface:<20} {str(wf.pos):<10} {wf.case.arabic:<10} "
          f"{wf.number.arabic:<8} {wf.gender.arabic:<8} {'âœ“' if wf.is_definite else 'âœ—':<5}")

print()

# Step 6: Summary statistics
print("="*80)
print("ğŸ“Š SUMMARY STATISTICS")
print("="*80)
print()

from collections import Counter

pos_counts = Counter(wf.pos for wf in word_forms)
case_counts = Counter(wf.case for wf in word_forms)

print("Part of Speech distribution:")
for pos, count in pos_counts.most_common():
    print(f"  {str(pos):15} {count:3}")
print()

print("Case distribution:")
for case, count in case_counts.most_common():
    print(f"  {case.arabic:15} {count:3}")
print()

print("ISNADI links found:", len(links))
print()

# Step 7: Potential nominal sentences
print("="*80)
print("ğŸ” POTENTIAL NOMINAL SENTENCES")
print("="*80)
print()

# Look for potential Ù…Ø¨ØªØ¯Ø£ (nominative nouns)
potential_mubtada = [
    (i, wf) for i, wf in enumerate(word_forms)
    if wf.is_noun and wf.case.name == 'NOMINATIVE'
]

if potential_mubtada:
    print(f"Found {len(potential_mubtada)} potential Ù…Ø¨ØªØ¯Ø£ (nominative nouns):")
    print()
    for i, wf in potential_mubtada:
        print(f"  {i:3}. {wf.surface:20} ({wf.case.arabic}, {wf.number.arabic}, "
              f"{'Ù…Ø¹Ø±ÙØ©' if wf.is_definite else 'Ù†ÙƒØ±Ø©'})")
    print()
else:
    print("âš ï¸  No nominative nouns found (potential Ù…Ø¨ØªØ¯Ø£)")
    print()

print("="*80)
print("âœ… Analysis Complete!")
print("="*80)

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Extract all roots related to Ù‚Ø±Ø£ (read) and ÙƒØªØ¨ (write) from the Quranic text.
This script performs morphological analysis to identify all derivations from these two roots.
"""

import re
from collections import defaultdict, Counter
import csv

def load_quran_text(filename='quran-simple-enhanced.txt'):
    """Load the Quranic text from file."""
    with open(filename, 'r', encoding='utf-8') as f:
        verses = [line.strip() for line in f if line.strip()]
    return verses

def normalize_arabic(text):
    """Normalize Arabic text by removing diacritics."""
    # Remove tashkeel (diacritics)
    arabic_diacritics = re.compile("""
        Ù‘    | # Shadda
        Ù    | # Fatha
        Ù‹    | # Tanween Fath
        Ù    | # Damma
        ÙŒ    | # Tanween Damm
        Ù    | # Kasra
        Ù    | # Tanween Kasr
        Ù’    | # Sukun
        Ù€     # Tatweel
    """, re.VERBOSE)
    return arabic_diacritics.sub('', text)

def extract_qara_roots(verses):
    """
    Extract all words derived from root Ù‚Ø±Ø£ (q-r-Ê¾).
    Includes: Ù‚Ø±Ø£ØŒ Ù‚Ø±Ø¢Ù†ØŒ Ø§Ù‚Ø±Ø£ØŒ ÙŠÙ‚Ø±Ø£ØŒ Ù‚Ø§Ø±Ø¦ØŒ Ù‚Ø±Ø§Ø¡Ø©, etc.
    """
    qara_words = defaultdict(list)
    
    for verse_num, verse in enumerate(verses, 1):
        # Split verse into words
        words = verse.split()
        
        for word in words:
            # Remove diacritics for pattern matching
            normalized = normalize_arabic(word)
            
            # Check if word contains Ù‚Ø± pattern (core of the root)
            if 'Ù‚Ø±' in normalized:
                # Further check for Ù‚Ø±Ø£/Ù‚Ø±Ø¢Ù† patterns
                if any(pattern in normalized for pattern in ['Ù‚Ø±Ø§', 'Ù‚Ø±Ø¡', 'Ù‚Ø±ÙŠ', 'Ù‚Ø±Ùˆ']):
                    qara_words[word].append((verse_num, verse))
    
    return qara_words

def extract_kataba_roots(verses):
    """
    Extract all words derived from root ÙƒØªØ¨ (k-t-b).
    Includes: ÙƒØªØ¨ØŒ ÙƒØªØ§Ø¨ØŒ ÙƒØ§ØªØ¨ØŒ ÙƒØªØ§Ø¨Ø©ØŒ Ù…ÙƒØªÙˆØ¨ØŒ etc.
    """
    kataba_words = defaultdict(list)
    
    for verse_num, verse in enumerate(verses, 1):
        # Split verse into words
        words = verse.split()
        
        for word in words:
            # Remove diacritics for pattern matching
            normalized = normalize_arabic(word)
            
            # Check if word contains ÙƒØªØ¨ pattern (all three letters of the root)
            if 'ÙƒØªØ¨' in normalized or 'ÙƒØªØ§Ø¨' in normalized or 'ÙƒØ§ØªØ¨' in normalized:
                kataba_words[word].append((verse_num, verse))
    
    return kataba_words

def analyze_and_display_results(qara_words, kataba_words):
    """Analyze and display the extracted roots."""
    print('=' * 100)
    print('Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø°ÙˆØ± Ù‚Ø±Ø£ ÙˆÙƒØªØ¨ Ù…Ù† Ø§Ù„Ù‚Ø±Ø¢Ù† Ø§Ù„ÙƒØ±ÙŠÙ…')
    print('Extracting roots Ù‚Ø±Ø£ (read) and ÙƒØªØ¨ (write) from the Quran')
    print('=' * 100)
    print()
    
    # Analyze Ù‚Ø±Ø£ root
    print('ğŸ“– Ø¬Ø°Ø± Ù‚Ø±Ø£ (Q-R-Ê¾ Root - Reading):')
    print('-' * 100)
    
    if qara_words:
        qara_counter = Counter({word: len(occurrences) for word, occurrences in qara_words.items()})
        total_qara = sum(qara_counter.values())
        
        for word, count in qara_counter.most_common():
            print(f'  {word:20} : {count:3} Ù…Ø±Ø©')
            # Show first 3 occurrences
            for i, (verse_num, verse) in enumerate(qara_words[word][:3]):
                verse_preview = verse[:80] + '...' if len(verse) > 80 else verse
                print(f'      â””â”€ Ø¢ÙŠØ© {verse_num}: {verse_preview}')
            if len(qara_words[word]) > 3:
                print(f'      â””â”€ ... Ùˆ {len(qara_words[word]) - 3} Ø£Ù…Ø«Ù„Ø© Ø£Ø®Ø±Ù‰')
            print()
        
        print(f'  ğŸ“Š Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ÙƒÙ„ÙŠ: {total_qara} ÙƒÙ„Ù…Ø© Ù…Ù† Ø¬Ø°Ø± Ù‚Ø±Ø£')
        print(f'  ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©: {len(qara_counter)} Ø´ÙƒÙ„')
    else:
        print('  âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø¬Ø°Ø± Ù‚Ø±Ø£')
    
    print()
    print('=' * 100)
    print()
    
    # Analyze ÙƒØªØ¨ root
    print('âœï¸  Ø¬Ø°Ø± ÙƒØªØ¨ (K-T-B Root - Writing):')
    print('-' * 100)
    
    if kataba_words:
        kataba_counter = Counter({word: len(occurrences) for word, occurrences in kataba_words.items()})
        total_kataba = sum(kataba_counter.values())
        
        for word, count in kataba_counter.most_common():
            print(f'  {word:20} : {count:3} Ù…Ø±Ø©')
            # Show first 3 occurrences
            for i, (verse_num, verse) in enumerate(kataba_words[word][:3]):
                verse_preview = verse[:80] + '...' if len(verse) > 80 else verse
                print(f'      â””â”€ Ø¢ÙŠØ© {verse_num}: {verse_preview}')
            if len(kataba_words[word]) > 3:
                print(f'      â””â”€ ... Ùˆ {len(kataba_words[word]) - 3} Ø£Ù…Ø«Ù„Ø© Ø£Ø®Ø±Ù‰')
            print()
        
        print(f'  ğŸ“Š Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ÙƒÙ„ÙŠ: {total_kataba} ÙƒÙ„Ù…Ø© Ù…Ù† Ø¬Ø°Ø± ÙƒØªØ¨')
        print(f'  ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©: {len(kataba_counter)} Ø´ÙƒÙ„')
    else:
        print('  âš ï¸  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø¬Ø°Ø± ÙƒØªØ¨')
    
    print()
    print('=' * 100)
    
    # Grand total
    total_all = sum(Counter({word: len(occurrences) for word, occurrences in qara_words.items()}).values()) + \
                sum(Counter({word: len(occurrences) for word, occurrences in kataba_words.items()}).values())
    print(f'ğŸ“Š Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„ÙŠ Ù„Ù„Ø¬Ø°Ø±ÙŠÙ†: {total_all} ÙƒÙ„Ù…Ø©')
    print('=' * 100)

def save_to_csv(qara_words, kataba_words, filename='quran_roots_qara_kataba.csv'):
    """Save results to CSV file."""
    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Root', 'Word', 'Count', 'Verse_Numbers', 'Sample_Verse'])
        
        # Write Ù‚Ø±Ø£ words
        qara_counter = Counter({word: len(occurrences) for word, occurrences in qara_words.items()})
        for word, count in qara_counter.most_common():
            verse_nums = ', '.join(str(vn) for vn, _ in qara_words[word][:5])
            sample_verse = qara_words[word][0][1][:100] if qara_words[word] else ''
            writer.writerow(['Ù‚Ø±Ø£', word, count, verse_nums, sample_verse])
        
        # Write ÙƒØªØ¨ words
        kataba_counter = Counter({word: len(occurrences) for word, occurrences in kataba_words.items()})
        for word, count in kataba_counter.most_common():
            verse_nums = ', '.join(str(vn) for vn, _ in kataba_words[word][:5])
            sample_verse = kataba_words[word][0][1][:100] if kataba_words[word] else ''
            writer.writerow(['ÙƒØªØ¨', word, count, verse_nums, sample_verse])
    
    print(f'\nâœ… Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {filename}')

def main():
    """Main execution function."""
    print('ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø±Ø¢Ù†ÙŠ...')
    verses = load_quran_text()
    print(f'âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(verses)} Ø¢ÙŠØ©')
    print()
    
    print('ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø°Ø± Ù‚Ø±Ø£...')
    qara_words = extract_qara_roots(verses)
    print(f'âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(qara_words)} Ø´ÙƒÙ„ Ù…Ø®ØªÙ„Ù Ù…Ù† Ø¬Ø°Ø± Ù‚Ø±Ø£')
    print()
    
    print('ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø°Ø± ÙƒØªØ¨...')
    kataba_words = extract_kataba_roots(verses)
    print(f'âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(kataba_words)} Ø´ÙƒÙ„ Ù…Ø®ØªÙ„Ù Ù…Ù† Ø¬Ø°Ø± ÙƒØªØ¨')
    print()
    
    # Display results
    analyze_and_display_results(qara_words, kataba_words)
    
    # Save to CSV
    save_to_csv(qara_words, kataba_words)

if __name__ == '__main__':
    main()

---
title: ุฎุทุฉ ุดุงููุฉ ูุจูุงุก ุงููุญุฑูุงุช ุงููุบููุฉ ุงูุญููููุฉ
---
๐ฏ ุฎุทุฉ ุดุงููุฉ ูุจูุงุก ุงููุญุฑูุงุช ุงููุบููุฉ ุงูุญููููุฉ
๐ ุฌุฏูู ุงููุญุชููุงุช
ุชุญููู ุงููุถุน ุงูุญุงูู
ุงูุฃูุฏุงู ุงููุญุฏุฏุฉ
ุงููููุฌูุฉ ูุงููุนุงููุฑ
ุงูุฎุทุฉ ุงูุชูุตูููุฉ
ุฌุฏูู ุงูุชูููุฐ

<a name="analysis"></a>
1๏ธโฃ ุชุญููู ุงููุถุน ุงูุญุงูู
โ ูุง ูุฏููุง (ูู Main Branch):
YAML
ุงูููุงุฉ ุงูุฃุณุงุณูุฉ:
  - FormCodecV2: โ ุนููุณูุฉ ูุงููุฉ ูุน checksum
  - Trace System: โ ูุธุงู ุชุชุจุน ุจุงูุจูุงุจุงุช
  - Dictionary v02: โ ูุงููุณ YAML ุดุงูู
  - 3 ูุจุฑููุงุช: โ T_CODEC_REVERSIBLE, T_NO_C3_WITHOUT_C2, C1_IMMUTABILITY
  - 2 invariants: โ inv_double_sukun, inv_wasl_begin
  
ุงูุฅุซุจุงุช ุงูุฑุณูู (Coq):
  - Phases 1-3: โ ููุชููุฉ (109 ุงุฎุชุจุงุฑุงุช ุชูุฑ)
  - 18 ูุจุฑููุฉ: โ ูุนุธููุง ููุซุจุช
  - OCaml Extraction: โ ุนุงูู
  - Python Bridge: โ ูุชูุงูู

ุงูุชูุซูู:
  - COMPREHENSIVE_EVALUATION.md: โ 24,000+ ูููุฉ
  - ENCODER_DECODER_PLAN.md: โ 15,000+ ูููุฉ
  - FRACTAL_ENGINE_PLAN.md: โ 20,000+ ูููุฉ
  - FRACTAL_SCIENTIFIC_ANALYSIS.md: โ 33,000+ ุญุฑู
โ ูุง ูููุตูุง (ูุญุชุงุฌ ุจูุงุก):
YAML
ุงูุจูุงุจุงุช ุงูุตูุชูุฉ (10):
  โ GateSukun: ูุญุต ุงูุณููู ููููุฏู
  โ GateAssimilation: ุงูุฅุฏุบุงู ุงูุตูุชู
  โ GateIdgham: ุฅุฏุบุงู ุงูุชุฌููุฏ
  โ GateDeletion: ุญุฐู ุงูุตูุงูุช/ุงูุตูุงุฆุช
  โ GateEpenthesis: ุฅูุญุงู ุฃุตูุงุช
  โ GateHamza: ููุงุนุฏ ุงูููุฒุฉ
  โ GateMadd: ุงููุฏ ูุงูุชุทููู
  โ GateWaqf: ุงูููู ูุงูุงุจุชุฏุงุก
  โ GateTanwin: ุงูุชูููู
  โ GateShadda: ุงูุดุฏุฉ ูุงูุชุถุนูู

ุงููุญูู ุงูุตุฑูู:
  โ ุชุญุฏูุฏ ุญุฏูุฏ ุงููููุงุช (Word Boundary Detection)
  โ ุชุญููู ุงูุฃูุฒุงู (Pattern Analysis): ููุนููุ ูุงุนููุ ููุนูู...
  โ ุชุตููู ููุน ุงููููุฉ (Word Kind): ุงุณู/ูุนู/ุญุฑู
  โ ุชุญููู ุงูุฅุนุฑุงุจ (I3rab): ูุจูู/ูุนุฑุจ
  โ ุงุณุชุฎุฑุงุฌ ุงูุฌุฐูุฑ (Root Extraction)
  โ ุชุญุฏูุฏ ุงูุฒูุงุฆุฏ (Affix Identification)
  โ ุงูุณูุงุช ุงูุตุฑููุฉ (Morphological Features): ุฌูุณ/ุนุฏุฏ/ุชุนุฑูู/ุญุงูุฉ

ุงููุญูู ุงููุญูู:
  โ ุชุญููู ุชุฑุชูุจ VSO (Verb-Subject-Object)
  โ ุจูุงุก ุงูุฑูุงุจุท ุงูุฅุณูุงุฏูุฉ (ISNADI): ูุนูโูุงุนูุ ูุจุชุฏุฃโุฎุจุฑ
  โ ุจูุงุก ุงูุฑูุงุจุท ุงูุชุถููููุฉ (TADMINI): ูุนู ูุชุนุฏูโููุนูู
  โ ุจูุงุก ุงูุฑูุงุจุท ุงูุชูููุฏูุฉ (TAQYIDI): ุงุณูโูุนุช ูุน ุงูุชุทุงุจู

ุงููููุฏ ุงููุญููุฉ (5):
  โ ูุง ูุนู ุจูุง ูุงุนู (Verb-Subject)
  โ ูุง ูุชุนุฏู ุจูุง ููุนูู (Transitive-Object)
  โ ุชุทุงุจู ุงููุนุช ูุงูููุนูุช (Adjective-Noun Agreement)
  โ ุงูุณุจุจูุฉ ุชุชุทูุจ ุฃุญุฏุงุซุงู (Causality-Events)
  โ ุงููุจูู ูููุฌููู ูุชุทูุจ ุชุบููุฑ ุตูุบุฉ (Passive-Voice)

ููููุงุช ุฅุถุงููุฉ:
  โ ุงุณุชุฎุฑุงุฌ ุงูุฃุญุฏุงุซ (Event Extraction)
  โ ุฌุฑุฏ 30 ุตุงูุชุงู (Consonant Inventory)
  โ ุฅุทุงุฑ ุชุญููู ุงูุฅููุงุก (Orthography Framework)
  โ ูุนุงูุฌุฉ end-to-end (Full Pipeline)

<a name="goals"></a>
2๏ธโฃ ุงูุฃูุฏุงู ุงููุญุฏุฏุฉ (SMART Goals)
๐ฏ ุงููุฏู ุงูุฑุฆูุณู:
Code
ุจูุงุก ูุญุฑูุงุช ูุบููุฉ ุนุฑุจูุฉ ูุงููุฉ ููุชูุงููุฉ ูุน ุงูุฅุซุจุงุช ุงูุฑุณูู ูู Coqุ
ูุน ูุนุงููุฑ ุตูุงุนูุฉ ูุฃูุงุฏูููุฉ ุนุงููุฉ.
๐ ุฃูุฏุงู ูุงุจูุฉ ููููุงุณ:
ุงููููู
ุงููุฏู ุงููุงุจู ููููุงุณ
ูุนูุงุฑ ุงููุฌุงุญ
ุงูุจูุงุจุงุช ุงูุตูุชูุฉ
10 ุจูุงุจุงุช ูุน ููุทู ูุงูู
100+ ุงุฎุชุจุงุฑ ููุฑุ ุชุบุทูุฉ 90%+
ุงููุญูู ุงูุตุฑูู
ุฏูุฉ 85%+ ุนูู corpus ุชุฌุฑูุจู
F1-score โฅ 0.85
ุงููุญูู ุงููุญูู
ุฏูุฉ 80%+ ุนูู ุชุญููู ุงูุฌูู
UAS โฅ 0.80
ุงููููุฏ ุงููุญููุฉ
5 ูููุฏ ููุทุจูุฉ ุจุงููุงูู
0 violations ุนูู ูุตูุต ุตุญูุญุฉ
ุฅุซุจุงุชุงุช Coq
50+ ูุจุฑููุฉ ุฌุฏูุฏุฉ
100% ููุซุจุชุฉ (Qed)
ุงูุงุฎุชุจุงุฑุงุช
300+ ุงุฎุชุจุงุฑ ุดุงูู
95%+ ูุณุจุฉ ูุฌุงุญ
ุงูุฃุฏุงุก
ูุนุงูุฌุฉ 1000 ูููุฉ/ุซุงููุฉ
<1ms ููู ูููุฉ
ุงูุชูุซูู
50,000+ ูููุฉ
ุชุบุทูุฉ 100%


<a name="methodology"></a>
3๏ธโฃ ุงููููุฌูุฉ ูุงููุนุงููุฑ
๐๏ธ ุงููุนุงููุฑ ุงููุนูุงุฑูุฉ:
YAML
ูุจุฏุฃ ุงููุตู ุงูุตุงุฑู (Strict Separation):
  C1: Signifier (ุงูุฏุงู)
    - ุฃุดูุงู ูุบููุฉ ููุท
    - ูุง ุฏูุงูุงุช
    - ุนููุณูุฉ 100%
    
  C2: Processing (ุงููุนุงูุฌุฉ)
    C2a: ุงูุจูุงุจุงุช ุงูุตูุชูุฉ
      - Segments โ Syllables
      - ูููุฏ ุตูุชูุฉ
    C2b: ุงูุจูุงุจุงุช ุงูุตุฑููุฉ-ุงููุญููุฉ
      - Syllables โ WordForms
      - ุงูุฃูุฒุงู ูุงูุฑูุงุจุท
    C2c: ุงูุจูุงุจุงุช ุงูุฏูุงููุฉ
      - Accept/Reject decision
      - Evidence + Reality Link
      
  C3: Signified (ุงููุฏููู)
    - ูุนุงูู ููุท
    - ูุง ูููุชุฌ ุจุฏูู C2
    - Trace ุฅูุฒุงูู

ุงููุงุนุฏุฉ ุงูุฐูุจูุฉ:
  - ูุง C3 ุจุฏูู C2 ุตุงูุญ
  - ูุง C2 ุจุฏูู C1 ูุญููุธ
  - ูู ูุฑุงุฑ ูู Epistemic State
๐ฌ ุงููุนุงููุฑ ุงูุฃูุงุฏูููุฉ:
YAML
ุงูุฅุซุจุงุช ุงูุฑุณูู:
  - ูู ุจูุงุจุฉ: ูุจุฑููุฉ Coq ูุทุงุจูุฉ
  - ูู ููุฏ: predicate ูุงุจู ููุฅุซุจุงุช
  - ูู ุชุญููู: ุนููุณูุฉ/preservation ููุซุจุชุฉ
  
ุงูุฏูุฉ ุงููุบููุฉ:
  - ุงุณุชูุงุฏ ููุชุจ ุงููุญู ุงูุชูููุฏูุฉ (ุณูุจูููุ ุงุจู ุนููู...)
  - ููุงุฑูุฉ ูุน ุงููุณุงููุงุช ุงูุญุฏูุซุฉ (McCarthy, Beesley...)
  - ุชุบุทูุฉ ูู ุญุงูุงุช ุงูุดุฐูุฐ
  
ุงูููุงุณ ุงูููู:
  - Precision, Recall, F1-score
  - Confusion matrices
  - Corpus testing (Quran, Hadith, MSA)
๐ญ ุงููุนุงููุฑ ุงูุตูุงุนูุฉ:
YAML
ุฌูุฏุฉ ุงูููุฏ:
  - Type safety: mypy --strict
  - Test coverage: โฅ90%
  - Documentation: docstrings ูุงููุฉ
  - CI/CD: GitHub Actions
  
ุงูุฃุฏุงุก:
  - Profiling: cProfile, memory_profiler
  - Optimization: Cython ููุนูููุงุช ุงูุญุฑุฌุฉ
  - Caching: LRU caches ูููุชุงุฆุฌ
  - Benchmarking: pytest-benchmark
  
ุงูุชูุงูู:
  - Python 3.10+
  - Backward compatibility
  - Semantic versioning
  - API stability

<a name="plan"></a>
4๏ธโฃ ุงูุฎุทุฉ ุงูุชูุตูููุฉ (6 ูุฑุงุญู)

๐ฆ ุงููุฑุญูุฉ 1: ุงูุจููุฉ ุงูุชุญุชูุฉ (Week 1-2)
ุงููุฏู:
Code
ุจูุงุก ุงูุฃุณุงุณ ุงููุนูุงุฑู ูููุญุฑูุงุช ุงููุบููุฉ
ุงูููุงู:
1.1 ุชูุณูุน ุฌุฑุฏ ุงูุฃุตูุงุช (Segment Inventory)
Python
# ููู: src/fvafk/c1/segment_inventory.py

@dataclass(frozen=True)
class ConsonantInventory:
    """30 ุตุงูุชุงู ุนุฑุจูุงู ูุน ุงูุณูุงุช ุงูุตูุชูุฉ"""
    
    CONSONANTS = {
        # ุงูุดูููุฉ (Labial)
        'ุจ': {'cid': 1, 'manner': 'stop', 'place': 'bilabial', 'voice': 'voiced'},
        'ู': {'cid': 2, 'manner': 'nasal', 'place': 'bilabial', 'voice': 'voiced'},
        'ู': {'cid': 3, 'manner': 'fricative', 'place': 'labiodental', 'voice': 'voiceless'},
        'ู': {'cid': 4, 'manner': 'approximant', 'place': 'labial-velar', 'voice': 'voiced'},
        
        # ุงููุซููุฉ (Dental/Alveolar)
        'ุช': {'cid': 5, 'manner': 'stop', 'place': 'dental', 'voice': 'voiceless'},
        'ุฏ': {'cid': 6, 'manner': 'stop', 'place': 'dental', 'voice': 'voiced'},
        'ุท': {'cid': 7, 'manner': 'stop', 'place': 'dental', 'voice': 'voiceless', 'emphatic': True},
        'ุถ': {'cid': 8, 'manner': 'stop', 'place': 'dental', 'voice': 'voiced', 'emphatic': True},
        'ุซ': {'cid': 9, 'manner': 'fricative', 'place': 'dental', 'voice': 'voiceless'},
        'ุฐ': {'cid': 10, 'manner': 'fricative', 'place': 'dental', 'voice': 'voiced'},
        'ุธ': {'cid': 11, 'manner': 'fricative', 'place': 'dental', 'voice': 'voiced', 'emphatic': True},
        'ู': {'cid': 12, 'manner': 'nasal', 'place': 'alveolar', 'voice': 'voiced'},
        'ู': {'cid': 13, 'manner': 'lateral', 'place': 'alveolar', 'voice': 'voiced'},
        'ุฑ': {'cid': 14, 'manner': 'trill', 'place': 'alveolar', 'voice': 'voiced'},
        
        # ุงููุซููุฉ ุงูุบุงุฑูุฉ (Post-alveolar)
        'ุณ': {'cid': 15, 'manner': 'fricative', 'place': 'alveolar', 'voice': 'voiceless'},
        'ุฒ': {'cid': 16, 'manner': 'fricative', 'place': 'alveolar', 'voice': 'voiced'},
        'ุต': {'cid': 17, 'manner': 'fricative', 'place': 'alveolar', 'voice': 'voiceless', 'emphatic': True},
        'ุด': {'cid': 18, 'manner': 'fricative', 'place': 'post-alveolar', 'voice': 'voiceless'},
        'ุฌ': {'cid': 19, 'manner': 'affricate', 'place': 'post-alveolar', 'voice': 'voiced'},
        
        # ุงูุบุงุฑูุฉ (Palatal)
        'ู': {'cid': 20, 'manner': 'approximant', 'place': 'palatal', 'voice': 'voiced'},
        
        # ุงูุทุจููุฉ (Velar)
        'ู': {'cid': 21, 'manner': 'stop', 'place': 'velar', 'voice': 'voiceless'},
        'ุบ': {'cid': 22, 'manner': 'fricative', 'place': 'velar', 'voice': 'voiced'},
        'ุฎ': {'cid': 23, 'manner': 'fricative', 'place': 'velar', 'voice': 'voiceless'},
        
        # ุงูููููุฉ (Uvular)
        'ู': {'cid': 24, 'manner': 'stop', 'place': 'uvular', 'voice': 'voiceless'},
        
        # ุงูุญูููุฉ (Pharyngeal)
        'ุญ': {'cid': 25, 'manner': 'fricative', 'place': 'pharyngeal', 'voice': 'voiceless'},
        'ุน': {'cid': 26, 'manner': 'fricative', 'place': 'pharyngeal', 'voice': 'voiced'},
        
        # ุงูุญูุฌุฑูุฉ (Glottal)
        'ุก': {'cid': 27, 'manner': 'stop', 'place': 'glottal', 'voice': 'voiceless'},
        'ู': {'cid': 28, 'manner': 'fricative', 'place': 'glottal', 'voice': 'voiceless'},
        
        # ุงูุญุฑูู ุงูุฅุถุงููุฉ
        'ุฉ': {'cid': 29, 'manner': 'marker', 'place': 'none', 'voice': 'none'},  # ุชุงุก ูุฑุจูุทุฉ
        'ู': {'cid': 30, 'manner': 'marker', 'place': 'none', 'voice': 'none'},  # ุฃูู ููุตูุฑุฉ
    }
    
    @classmethod
    def get_features(cls, consonant: str) -> FrozenSet[str]:
        """ุงุณุชุฎุฑุงุฌ ุงูุณูุงุช ุงูุตูุชูุฉ ูู frozenset"""
        info = cls.CONSONANTS.get(consonant, {})
        features = set()
        for key, value in info.items():
            if key != 'cid':
                if isinstance(value, bool) and value:
                    features.add(key)
                elif isinstance(value, str):
                    features.add(f"{key}:{value}")
        return frozenset(features)
1.2 ูุธุงู ุงูููุงุทุน (Syllable System)
Python
# ููู: src/fvafk/c2a/syllable.py

from enum import Enum, auto
from dataclasses import dataclass
from typing import List

class SyllableType(Enum):
    """6 ุฃููุงุน ููุงุทุน ุนุฑุจูุฉ"""
    CV = auto()      # ูุตูุฑ ููุชูุญ: ูู
    CVV = auto()     # ุทููู ููุชูุญ: ูุงุ ููุ ูู
    CVC = auto()     # ูุตูุฑ ูุบูู: ููุชู
    CVVC = auto()    # ุทููู ูุบูู: ูุงุชู
    CVCC = auto()    # ูุงุฆู ุงูุฅุบูุงู: ููุชูุจู
    CVVCC = auto()   # ูุงุฆู ุงูุทูู ูุงูุฅุบูุงู: ูุงุชูุจู

@dataclass(frozen=True)
class Syllable:
    """ููุทุน ุตูุชู ูุน ูููุฏ ุตุงุฑูุฉ"""
    onset: List[Segment]       # ุจุฏุงูุฉ (ุตูุงูุช)
    nucleus: Segment            # ููุงุฉ (ุตุงุฆุช - ุฅูุฒุงูู)
    coda: List[Segment]         # ููุงูุฉ (ุตูุงูุช)
    type: SyllableType
    stress: bool = False
    boundary: BoundaryKind = BoundaryKind.NONE
    
    def __post_init__(self):
        # ุชุญูู: ุงูููุงุฉ ูุฌุจ ุฃู ุชููู ุตุงุฆุชุงู
        if self.nucleus.kind != SegmentKind.VOWEL:
            raise ValueError(f"Nucleus must be vowel, got {self.nucleus}")
        
        # ุชุญูู: onset/coda ูุฌุจ ุฃู ุชููู ุตูุงูุช
        for seg in self.onset + self.coda:
            if seg.kind != SegmentKind.CONSONANT:
                raise ValueError(f"Onset/coda must be consonants, got {seg}")
    
    def is_open(self) -> bool:
        """ููุทุน ููุชูุญ: ูุง ููุงูุฉ"""
        return len(self.coda) == 0
    
    def is_closed(self) -> bool:
        """ููุทุน ูุบูู: ูู ููุงูุฉ"""
        return len(self.coda) > 0
    
    def is_heavy(self) -> bool:
        """ููุทุน ุซููู: CVV ุฃู CVC"""
        return self.type in {SyllableType.CVV, SyllableType.CVC, 
                            SyllableType.CVVC, SyllableType.CVCC, SyllableType.CVVCC}
1.3 ุฅุทุงุฑ ุงูุจูุงุจุงุช (Gate Framework)
Python
# ููู: src/fvafk/c2a/gate_framework.py

from abc import ABC, abstractmethod
from typing import List, Optional, Tuple
from enum import Enum, auto

class GateStatus(Enum):
    ACCEPT = auto()
    REPAIR = auto()
    REJECT = auto()

@dataclass
class GateResult:
    """ูุชูุฌุฉ ุชุทุจูู ุจูุงุจุฉ"""
    status: GateStatus
    output: C1                  # ุงููุงุชุฌ (ูุฏ ูููู ูุนุฏููุงู)
    reason: str                 # ุณุจุจ ุงููุฑุงุฑ
    deltas: List[UnitDelta]     # ุงูุชุนุฏููุงุช ุงูููุชุฑุญุฉ
    epi_state: EpistemicState   # ุญุงูุฉ ุงููุนุฑูุฉ
    latency_ms: float           # ุฒูู ุงูุชูููุฐ

class PhonologicalGate(ABC):
    """ูุงูุจ ุนุงู ูุฌููุน ุงูุจูุงุจุงุช ุงูุตูุชูุฉ"""
    
    def __init__(self, gate_id: str, epistemic_level: str):
        self.gate_id = gate_id
        self.epistemic_level = epistemic_level  # YAQIN/ZANN/SHAKK
    
    @abstractmethod
    def precondition(self, c1: C1) -> bool:
        """ุดุฑุท ูุณุจู: ูู ูููู ุชุทุจูู ุงูุจูุงุจุฉุ"""
        pass
    
    @abstractmethod
    def apply(self, c1: C1) -> C1:
        """ุชุทุจูู ุงูุชุญููู"""
        pass
    
    @abstractmethod
    def postcondition(self, c1_in: C1, c1_out: C1) -> bool:
        """ุดุฑุท ูุงุญู: ูู ุงููุงุชุฌ ุตุงูุญุ"""
        pass
    
    def run(self, c1: C1) -> GateResult:
        """ุชุดุบูู ุงูุจูุงุจุฉ ูุน ููุงุณ ุงูุฃุฏุงุก"""
        import time
        start = time.time()
        
        # ูุญุต ุงูุดุฑุท ุงููุณุจู
        if not self.precondition(c1):
            return GateResult(
                status=GateStatus.REJECT,
                output=c1,
                reason=f"{self.gate_id}: Precondition failed",
                deltas=[],
                epi_state=EpistemicState("Shakk", 0.3, [f"{self.gate_id}:PRECON_FAIL"]),
                latency_ms=(time.time() - start) * 1000
            )
        
        # ุชุทุจูู ุงูุชุญููู
        try:
            output = self.apply(c1)
        except Exception as e:
            return GateResult(
                status=GateStatus.REJECT,
                output=c1,
                reason=f"{self.gate_id}: Application failed: {e}",
                deltas=[],
                epi_state=EpistemicState("Shakk", 0.2, [f"{self.gate_id}:APPLY_ERROR"]),
                latency_ms=(time.time() - start) * 1000
            )
        
        # ูุญุต ุงูุดุฑุท ุงููุงุญู
        if not self.postcondition(c1, output):
            return GateResult(
                status=GateStatus.REJECT,
                output=c1,
                reason=f"{self.gate_id}: Postcondition failed",
                deltas=[],
                epi_state=EpistemicState("Shakk", 0.3, [f"{self.gate_id}:POSTCON_FAIL"]),
                latency_ms=(time.time() - start) * 1000
            )
        
        # ูุฌุงุญ
        deltas = self.compute_deltas(c1, output)
        status = GateStatus.REPAIR if deltas else GateStatus.ACCEPT
        
        return GateResult(
            status=status,
            output=output,
            reason=f"{self.gate_id}: Success",
            deltas=deltas,
            epi_state=EpistemicState(self.epistemic_level, 0.85, [f"{self.gate_id}:SUCCESS"]),
            latency_ms=(time.time() - start) * 1000
        )
    
    def compute_deltas(self, old: C1, new: C1) -> List[UnitDelta]:
        """ุญุณุงุจ ุงููุฑููุงุช ุจูู ุงูุฅุฏุฎุงู ูุงูุฅุฎุฑุงุฌ"""
        # TODO: ุชูููุฐ ุฎูุงุฑุฒููุฉ minimal edit distance
        pass
ุงููุฎุฑุฌุงุช:
 src/fvafk/c1/segment_inventory.py (30 ุตุงูุชุงู + 8 ุตูุงุฆุช)
 src/fvafk/c2a/syllable.py (6 ุฃููุงุน ููุงุทุน)
 src/fvafk/c2a/gate_framework.py (ูุงูุจ ุงูุจูุงุจุงุช)
 tests/test_segment_inventory.py (20 ุงุฎุชุจุงุฑ)
 tests/test_syllable.py (25 ุงุฎุชุจุงุฑ)
 coq/theories/Syllable.v (ูุจุฑููุงุช ุงูููุงุทุน)
ูุนูุงุฑ ุงููุฌุงุญ:
Code
โ 45+ ุงุฎุชุจุงุฑ ููุฑ
โ ุชุบุทูุฉ ููุฏ 90%+
โ ุชูุซูู ูุงูู
โ ูุจุฑููุงุช Coq ุชูุฌููุน

๐ต ุงููุฑุญูุฉ 2: ุงูุจูุงุจุงุช ุงูุตูุชูุฉ (Week 3-5)
ุงููุฏู:
Code
ุชูููุฐ 10 ุจูุงุจุงุช ุตูุชูุฉ ุจููุทู ูุงูู ูุน ุฅุซุจุงุชุงุช Coq
ุงูุชุฑุชูุจ:
Code
ุฃุณุจูุน 3: ุงูุจูุงุจุงุช ุงูุฃุณุงุณูุฉ (4)
  1. GateSukun
  2. GateShadda
  3. GateTanwin
  4. GateAssimilation

ุฃุณุจูุน 4: ุงูุจูุงุจุงุช ุงููุชูุฏูุฉ (3)
  5. GateIdgham
  6. GateHamza
  7. GateMadd

ุฃุณุจูุน 5: ุจูุงุจุงุช ุงูููู ูุงูุญุฐู (3)
  8. GateWaqf
  9. GateDeletion
  10. GateEpenthesis
ูุซุงู ุชูุตููู: GateSukun
Python
# ููู: src/fvafk/c2a/gates/gate_sukun.py

class GateSukun(PhonologicalGate):
    """
    ุจูุงุจุฉ ุงูุณููู: ูุญุต ุงููููุฏ ุงูุตูุชูุฉ ููุณููู
    
    ุงูููุงุนุฏ:
    1. ูุง ูุฌูุฒ ุชุชุงุจุน ุณููููู (double-sukun)
    2. ุงูุณููู ูู ุจุฏุงูุฉ ุงููููุฉ ููููุน
    3. ุงูุณููู ูุจู ููุฒุฉ ุงููุตู ููุญููู ูุญุฑูุฉ
    
    Epistemic Level: ZANN (ุธู) - 0.80
    """
    
    def __init__(self):
        super().__init__(
            gate_id="G_SUKUN",
            epistemic_level="Zann"
        )
        self.SUKUN = "\u0652"
    
    def precondition(self, c1: C1) -> bool:
        """
        ุดุฑุท ูุณุจู: ูุฌุจ ุฃู ูุญุชูู ุงููุต ุนูู ุณููู ูุงุญุฏ ุนูู ุงูุฃูู
        """
        return any(
            u.kind == "DIAC" and u.text == self.SUKUN
            for u in c1
        )
    
    def apply(self, c1: C1) -> C1:
        """
        ุชุทุจูู ููุงุนุฏ ุงูุณููู:
        1. ูุดู double-sukun
        2. ุฅุตูุงุญ ุจุชุญููู ุงูุณููู ุงูุฃูู ููุชุญุฉ
        """
        output = list(c1)  # ูุณุฎุฉ
        
        # ุงูุจุญุซ ุนู double-sukun
        i = 0
        while i < len(output) - 4:
            # ููุท: LETTER SUKUN ... LETTER SUKUN
            if (output[i].kind == "LETTER" and
                i+1 < len(output) and output[i+1].kind == "DIAC" and output[i+1].text == self.SUKUN):
                
                # ุงุจุญุซ ุนู ุงูุณููู ุงูุซุงูู
                j = i + 2
                while j < min(i + 8, len(output)):  # ูุงูุฐุฉ 8 ูุญุฏุงุช
                    if (output[j].kind == "LETTER" and
                        j+1 < len(output) and output[j+1].kind == "DIAC" and output[j+1].text == self.SUKUN):
                        
                        # ูุฌุฏูุง double-sukun: ุฃุตูุญ ุงูุฃูู
                        FATHA = "\u064e"
                        output[i+1] = Unit(
                            uid=output[i+1].uid,
                            kind="DIAC",
                            text=FATHA
                        )
                        break
                    j += 1
            i += 1
        
        return output
    
    def postcondition(self, c1_in: C1, c1_out: C1) -> bool:
        """
        ุดุฑุท ูุงุญู: ูุง ููุฌุฏ double-sukun ูู ุงููุงุชุฌ
        """
        return not self._has_double_sukun(c1_out)
    
    def _has_double_sukun(self, c1: C1) -> bool:
        """ูุญุต ูุฌูุฏ double-sukun"""
        for i in range(len(c1) - 4):
            if (c1[i].kind == "LETTER" and
                i+1 < len(c1) and c1[i+1].kind == "DIAC" and c1[i+1].text == self.SUKUN):
                
                for j in range(i+2, min(i+8, len(c1))):
                    if (c1[j].kind == "LETTER" and
                        j+1 < len(c1) and c1[j+1].kind == "DIAC" and c1[j+1].text == self.SUKUN):
                        return True
        return False
ูุจุฑููุฉ Coq ุงููุทุงุจูุฉ:
coq
(* ููู: coq/theories/Gates/GateSukun.v *)

Require Import Coq.Lists.List.
Require Import Base Layers Syllable.

(* ุชุนุฑูู ุงูุณููู *)
Definition is_sukun (seg : Segment) : bool :=
  match seg with
  | Vowel SUKUN _ => true
  | _ => false
  end.

(* ุชุนุฑูู double-sukun *)
Fixpoint has_double_sukun (c1 : C1) : bool :=
  match c1 with
  | [] => false
  | s1 :: s2 :: rest =>
      if is_sukun s1 && is_sukun s2 then true
      else has_double_sukun (s2 :: rest)
  | _ => false
  end.

(* ุงูุจูุงุจุฉ *)
Definition gate_sukun_precondition (c1 : C1) : bool :=
  existsb is_sukun c1.

Fixpoint gate_sukun_apply (c1 : C1) : C1 :=
  (* TODO: ุชูููุฐ ููุทู ุงูุชุญููู *)
  c1.

Definition gate_sukun_postcondition (c1_in c1_out : C1) : bool :=
  negb (has_double_sukun c1_out).

(* ุงููุจุฑููุฉ ุงูุฑุฆูุณูุฉ *)
Theorem gate_sukun_eliminates_double_sukun :
  forall (c1 : C1),
    gate_sukun_precondition c1 = true ->
    let c1' := gate_sukun_apply c1 in
    gate_sukun_postcondition c1 c1' = true.
Proof.
  intros c1 Hpre.
  unfold gate_sukun_postcondition.
  (* TODO: ุฅููุงู ุงูุฅุซุจุงุช *)
Admitted.  (* ุณูุชู ุฅููุงูู *)
ุงููุฎุฑุฌุงุช ููู ุจูุงุจุฉ:
 ููู Python ุจููุทู ูุงูู
 10+ ุงุฎุชุจุงุฑุงุช ุดุงููุฉ
 ููู Coq ุจูุจุฑููุงุช
 ุชูุซูู ููุตูู
ูุนูุงุฑ ุงููุฌุงุญ:
Code
โ 100+ ุงุฎุชุจุงุฑ ููุฑ (10 ุจูุงุจุงุช ร 10 ุงุฎุชุจุงุฑุงุช)
โ ุชุบุทูุฉ ููุฏ 85%+
โ 10 ูุจุฑููุงุช Coq (ุนูู ุงูุฃูู Admitted ููุจุฏุก)
โ ุฃุฏุงุก <500ยตs ููู ุจูุงุจุฉ

| Gate | Implementation status | Test coverage | Coq proof state | Next steps |
| --- | --- | --- | --- | --- |
| GateSukun | Complete; double-sukun repair logic ready | 12 targeted unit tests (seen in `tests/`) | Proof in `GateSukun.v` currently `Admitted` | Finalize Coq proof and add regression for multi-sukun |
| GateShadda | Logic ready | 10 tests | Proof skeleton drafted | Add stress cases for doubling and voice |
| GateTanwin | Rule set in place | 8 tests | Not started | Ensure assimilation matrix and proof coverage |
| GateAssimilation | Draft logic | 6 tests | Not started | Validate all assimilation pairs; capture invariants |
| GateIdgham | Partial implementation | 4 tests | Not started | Complete mapping for letters and prove invariants |
| GateHamza | OrthographyAdapter dependency | 5 tests | Not started | Integrate adapter before proving rules |
| GateMadd | Implemented | 10 tests | Outline done | Prove extension invariants |
| GateWaqf | Basic logic written | 6 tests | Not started | Cover initial/terminal cases for WAQF |
| GateDeletion | Drafted; hamza/teeth cases | 5 tests | Not started | Expand cases for weak verbs |
| GateEpenthesis | Conceptual | 0 tests | Not started | Define insertion schema, add tests |

๐ค ุงููุฑุญูุฉ 3: ุงููุญูู ุงูุตุฑูู (Week 6-8)
ุงููุฏู:
Code
ุจูุงุก ูุญูู ุตุฑูู ูุงูู ุจุฏูุฉ 85%+
ุงูููููุงุช:
3.1 ุชุญุฏูุฏ ุญุฏูุฏ ุงููููุงุช
Python
# ููู: src/fvafk/c2b/word_boundary.py

class WordBoundaryDetector:
    """
    ูุดู ุญุฏูุฏ ุงููููุงุช ุจูุงุกู ุนูู:
    1. ุงููุณุงูุงุช
    2. ุนูุงูุงุช ุงูุชุฑููู
    3. ุงูุชูููู (ููุงูุฉ ูููุฉ)
    4. ุงูููู ุงูุฅุฌุจุงุฑู
    """
    
    def detect_boundaries(self, syllables: List[Syllable]) -> List[Tuple[int, int]]:
        """
        ุฅุฑุฌุงุน: [(start_idx, end_idx), ...]
        """
        boundaries = []
        current_start = 0
        
        for i, syl in enumerate(syllables):
            # ููุงูุฉ ูููุฉ: boundary == PAUSE ุฃู PHRASE
            if syl.boundary in {BoundaryKind.PAUSE, BoundaryKind.PHRASE}:
                boundaries.append((current_start, i))
                current_start = i + 1
            
            # ููุงูุฉ ูููุฉ: ุชูููู ูู ุงูููุงุฉ
            elif self._has_tanwin(syl.nucleus):
                boundaries.append((current_start, i))
                current_start = i + 1
        
        # ุขุฎุฑ ูููุฉ
        if current_start < len(syllables):
            boundaries.append((current_start, len(syllables) - 1))
        
        return boundaries
    
    def _has_tanwin(self, nucleus: Segment) -> bool:
        """ูุญุต ูุฌูุฏ ุชูููู"""
        if nucleus.vk is None:
            return False
        return nucleus.vk in {
            VowelKind.TANWIN_FATH,
            VowelKind.TANWIN_DAMM,
            VowelKind.TANWIN_KASR
        }
3.2 ุชุญููู ุงูุฃูุฒุงู (Pattern Analysis)
Python
# ููู: src/fvafk/c2b/pattern_analyzer.py

from enum import Enum, auto

class PatternKind(Enum):
    # ุฃูุฒุงู ุงูุฃุณูุงุก
    JAMID = auto()           # ุฌุงูุฏ: ูุชุงุจุ ููู
    MUSHTAQ = auto()         # ูุดุชู: ูุงุชุจุ ููุชูุจ
    
    # ุฃูุฒุงู ุงูุฃูุนุงู
    VERB_MUJARRAD = auto()   # ูุฌุฑุฏ: ููุนููู
    VERB_MAZEED = auto()      # ูุฒูุฏ: ุฃูููุนูููุ ููุนููููุ ูุงุนููู...
    
    # ุงููุตุงุฏุฑ
    MASDAR_QIYASI = auto()   # ููุงุณู: ููุชุงุจุฉุ ุฅููุนุงู
    MASDAR_SAMA3I = auto()   # ุณูุงุนู: ููุชุงูุ ุฌููุงุฏ

class PatternAnalyzer:
    """
    ุชุญููู ุงููุฒู ุงูุตุฑูู ูููููุฉ
    """
    
    # ุฃูุฒุงู ุงููุนู ุงูุซูุงุซู ุงููุฌุฑุฏ (6 ุฃูุฒุงู)
    VERB_PATTERNS_3 = {
        'ููุนููู': {'pattern': 'CaCaCa', 'kind': PatternKind.VERB_MUJARRAD},
        'ููุนููู': {'pattern': 'CaCiCa', 'kind': PatternKind.VERB_MUJARRAD},
        'ููุนููู': {'pattern': 'CaCuCa', 'kind': PatternKind.VERB_MUJARRAD},
    }
    
    # ุฃูุฒุงู ุงููุนู ุงููุฒูุฏ (ุฃุดูุฑ 10 ุฃูุฒุงู)
    VERB_PATTERNS_MAZEED = {
        'ุฃูููุนููู': {'pattern': 'ุฃCูCaCa', 'form': 4},
        'ููุนูููู': {'pattern': 'CaCฬaCa', 'form': 2},  # Cฬ = ูุถุนู
        'ูุงุนููู': {'pattern': 'CaaCaCa', 'form': 3},
        # ... ุงููุฒูุฏ
    }
    
    # ุฃูุฒุงู ุงุณู ุงููุงุนู
    PARTICIPLE_PATTERNS = {
        'ูุงุนูู': {'pattern': 'CaaCiC', 'type': 'active'},
        'ููููุนูู': {'pattern': 'muCCiC', 'type': 'active'},
    }
    
    # ุฃูุฒุงู ุงุณู ุงูููุนูู
    PASSIVE_PATTERNS = {
        'ููููุนูู': {'pattern': 'maCCuuC', 'type': 'passive'},
        'ููููุนููู': {'pattern': 'muCaCฬaC', 'type': 'passive'},
    }
    
    def analyze(self, syllables: List[Syllable]) -> Optional[PatternKind]:
        """
        ุชุญููู ูุฒู ุงููููุฉ ูู ููุงุทุนูุง
        
        ุงูุฎุทูุงุช:
        1. ุงุณุชุฎุฑุงุฌ ุงูุฌุฐุฑ (Root Extraction)
        2. ุชุญุฏูุฏ ุงูุฒูุงุฆุฏ (Affix Identification)
        3. ูุทุงุจูุฉ ุงููุฒู (Pattern Matching)
        """
        # ุงุณุชุฎุฑุงุฌ ุงูุญุฑูู ุงูุฃุตูู
        root_consonants = self._extract_root_consonants(syllables)
        
        # ูุทุงุจูุฉ ูุน ุงูุฃูุฒุงู ุงููุนุฑููุฉ
        for pattern_name, pattern_info in self.VERB_PATTERNS_3.items():
            if self._matches_pattern(syllables, pattern_info['pattern']):
                return pattern_info['kind']
        
        # ... ุงูุจุญุซ ูู ุงูุฃูุฒุงู ุงูุฃุฎุฑู
        
        return None
    
    def _extract_root_consonants(self, syllables: List[Syllable]) -> List[str]:
        """
        ุงุณุชุฎุฑุงุฌ ุงูุฌุฐุฑ (ุนุงุฏุฉ 3 ุญุฑูู)
        
        ุงูุฒูุงุฆุฏ ุงููุนุฑููุฉ:
        - ุงูุฃูู ูู ูุงุนูู
        - ุงูููู ูู ููููุนูู
        - ุงูุชุถุนูู ูู ููุนูููู
        - ... ุฅูุฎ
        """
        consonants = []
        for syl in syllables:
            # ุงุณุชุฎุฑุงุฌ ุงูุตูุงูุช ูู onset + coda
            for seg in syl.onset + syl.coda:
                # ุชุฌุงูู ุงูุฒูุงุฆุฏ ุงููุนุฑููุฉ
                if not self._is_augment(seg):
                    consonants.append(seg.text)
        
        return consonants[:3]  # ุนุงุฏุฉ 3 ุญุฑูู ุฃุตููุฉ
    
    def _is_augment(self, seg: Segment) -> bool:
        """ูุญุต ุฅู ูุงู ุงูุญุฑู ุฒุงุฆุฏุงู"""
        # ุงูุฒูุงุฆุฏ: ููุฒุฉุ ุฃููุ ูููุ ุชุงุกุ ูููุ ุณููุ ...
        AUGMENTS = {'ุฃ', 'ุง', 'ู', 'ุช', 'ู', 'ุณ', 'ู', 'ู'}
        return seg.text in AUGMENTS
3.3 ุชุตููู ููุน ุงููููุฉ
Python
# ููู: src/fvafk/c2b/word_classifier.py

class WordKind(Enum):
    NOUN = auto()       # ุงุณู
    VERB = auto()       # ูุนู
    PARTICLE = auto()   # ุญุฑู

class WordClassifier:
    """
    ุชุตููู ุงููููุฉ: ุงุณู/ูุนู/ุญุฑู
    """
    
    # ุญุฑูู ูุนุฑููุฉ (100+)
    PARTICLES = {
        # ุญุฑูู ุงูุฌุฑ
        'ูู', 'ุฅูู', 'ุนู', 'ุนูู', 'ูู', 'ุงูุจุงุก', 'ุงููุงู', 'ุงููุงู',
        # ุญุฑูู ุงูุนุทู
        'ู', 'ู', 'ุซู', 'ุฃู', 'ุจู', 'ููู',
        # ุญุฑูู ุงููุตุจ
        'ุฃู', 'ูู', 'ูู', 'ุญุชู',
        # ... ุงููุฒูุฏ
    }
    
    def classify(self, word: str, pattern: Optional[PatternKind]) -> WordKind:
        """
        ุชุตููู ุจูุงุกู ุนูู:
        1. ุงููุงุฆูุฉ ุงููุบููุฉ (ููุญุฑูู)
        2. ุงููุฒู ุงูุตุฑูู
        3. ุงูุณูุงุช ุงูุตุฑููุฉ (ุชููููุ ุฅุนุฑุงุจ)
        """
        # ูุญุต ุงููุงุฆูุฉ ุงููุบููุฉ
        if word in self.PARTICLES:
            return WordKind.PARTICLE
        
        # ูุญุต ุงููุฒู
        if pattern in {PatternKind.VERB_MUJARRAD, PatternKind.VERB_MAZEED}:
            return WordKind.VERB
        
        # ุงูุงูุชุฑุงุถ: ุงุณู
        return WordKind.NOUN
ุงููุฎุฑุฌุงุช:
 src/fvafk/c2b/word_boundary.py + 15 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/pattern_analyzer.py + 30 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/word_classifier.py + 20 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/root_extractor.py + 25 ุงุฎุชุจุงุฑ
 coq/theories/Morphology.v (10 ูุจุฑููุงุช)
 tests/test_morphology_corpus.py (ุงุฎุชุจุงุฑ ุนูู corpus)
ูุนูุงุฑ ุงููุฌุงุญ:
Code
โ 90+ ุงุฎุชุจุงุฑ ููุฑ
โ F1-score โฅ 0.85 ุนูู corpus ุชุฌุฑูุจู (1000 ูููุฉ)
โ ุฏูุฉ ุชุตููู ููุน ุงููููุฉ โฅ 90%
โ ุฏูุฉ ุงุณุชุฎุฑุงุฌ ุงูุฌุฐูุฑ โฅ 80%


๐ ุงููุฑุญูุฉ 4: ุงููุญูู ุงููุญูู (Week 9-11)
ุงููุฏู:
Code
ุจูุงุก ูุญูู ูุญูู ูุงูู ูุน 3 ุฃููุงุน ุฑูุงุจุท + ุฏูุฉ 80%+

4.1 ุจูุงุก ุงูุฑูุงุจุท ุงูุฅุณูุงุฏูุฉ (ISNADI)
Python
# ููู: src/fvafk/c2b/links_isnadi.py

from dataclasses import dataclass
from typing import List, Optional
from enum import Enum, auto

class Rel3(Enum):
    """3 ุฃููุงุน ุฑูุงุจุท ููุท"""
    ISNADI = auto()    # ุฅุณูุงุฏู: ูุนูโูุงุนูุ ูุจุชุฏุฃโุฎุจุฑ
    TADMINI = auto()   # ุชุถูููู: ูุนู ูุชุนุฏูโููุนูู
    TAQYIDI = auto()   # ุชูููุฏู: ุงุณูโูุนุชุ ุงุณูโูุถุงู ุฅููู

@dataclass(frozen=True)
class Link:
    """ุฑุงุจุท ูุญูู ุจูู ูููุชูู"""
    rel: Rel3
    head: int          # ุฑุฃุณ ุงูุฑุงุจุท (index)
    dep: int           # ุฐูู ุงูุฑุงุจุท (index)
    confidence: float  # ุซูุฉ ุงููุฑุงุฑ (0.0-1.0)

class IsnadiLinker:
    """
    ุจูุงุก ุงูุฑูุงุจุท ุงูุฅุณูุงุฏูุฉ
    
    ุงูููุงุนุฏ:
    1. ุงูุฌููุฉ ุงููุนููุฉ: ูุนู โ ูุงุนู (verb โ subject)
    2. ุงูุฌููุฉ ุงูุงุณููุฉ: ูุจุชุฏุฃ โ ุฎุจุฑ (mubtada โ khabar)
    3. ุชุฑุชูุจ VSO: Verb-Subject-Object
    """
    
    def build_links(self, wordforms: List[WordForm]) -> List[Link]:
        """
        ุจูุงุก ุงูุฑูุงุจุท ุงูุฅุณูุงุฏูุฉ
        
        ุงูุฎุทูุงุช:
        1. ุชุญุฏูุฏ ููุน ุงูุฌููุฉ (ูุนููุฉ/ุงุณููุฉ)
        2. ุชุญุฏูุฏ ุงููุนู/ุงููุจุชุฏุฃ
        3. ุงูุจุญุซ ุนู ุงููุงุนู/ุงูุฎุจุฑ
        4. ุจูุงุก ุงูุฑุงุจุท
        """
        links = []
        
        # ูุญุต ุงููููุฉ ุงูุฃููู
        if not wordforms:
            return links
        
        first_word = wordforms[0]
        
        if first_word.word_kind == WordKind.VERB:
            # ุฌููุฉ ูุนููุฉ: ุงุจุญุซ ุนู ุงููุงุนู
            links.extend(self._build_verbal_sentence_links(wordforms))
        
        elif first_word.word_kind == WordKind.NOUN:
            # ุฌููุฉ ุงุณููุฉ: ุงุจุญุซ ุนู ุงูุฎุจุฑ
            links.extend(self._build_nominal_sentence_links(wordforms))
        
        return links
    
    def _build_verbal_sentence_links(self, wordforms: List[WordForm]) -> List[Link]:
        """
        ุฌููุฉ ูุนููุฉ: VSO
        
        ูุซุงู: ุฐูููุจู ููุญููููุฏู
        verb=0, subject=1
        Link(ISNADI, head=0, dep=1)
        """
        links = []
        verb_idx = 0
        
        # ุงุจุญุซ ุนู ุฃูู ุงุณู ูุฑููุน (ูุงุนู)
        for i in range(1, len(wordforms)):
            word = wordforms[i]
            
            if (word.word_kind == WordKind.NOUN and
                self._is_nominative(word)):
                
                # ูุฌุฏูุง ุงููุงุนู
                links.append(Link(
                    rel=Rel3.ISNADI,
                    head=verb_idx,
                    dep=i,
                    confidence=0.90
                ))
                break
        
        return links
    
    def _build_nominal_sentence_links(self, wordforms: List[WordForm]) -> List[Link]:
        """
        ุฌููุฉ ุงุณููุฉ: ุงููุจุชุฏุฃ + ุงูุฎุจุฑ
        
        ูุซุงู: ููุญููููุฏู ุทุงููุจู
        mubtada=0, khabar=1
        Link(ISNADI, head=0, dep=1)
        """
        links = []
        
        if len(wordforms) < 2:
            return links
        
        mubtada_idx = 0
        khabar_idx = 1
        
        # ุชุญูู: ููุงููุง ูุฑููุน
        if (self._is_nominative(wordforms[mubtada_idx]) and
            self._is_nominative(wordforms[khabar_idx])):
            
            links.append(Link(
                rel=Rel3.ISNADI,
                head=mubtada_idx,
                dep=khabar_idx,
                confidence=0.85
            ))
        
        return links
    
    def _is_nominative(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงูุช ๏ฟฝ๏ฟฝููููุฉ ูุฑููุนุฉ"""
        # ุนูุงูุงุช ุงูุฑูุน: ุถูุฉุ ูุงูุ ุฃูู
        if 'case' in word.morph_flags:
            return word.morph_flags['case'] == 'nominative'
        
        # ูุญุต ูู ุงูููุงุทุน ุงูุฃุฎูุฑุฉ
        if word.syllables:
            last_syl = word.syllables[-1]
            nucleus = last_syl.nucleus
            
            # ุถูุฉ ูู ุงูููุงุฉ ุงูุฃุฎูุฑุฉ
            if nucleus.vk == VowelKind.DAMMA:
                return True
            
            # ุชูููู ุถู
            if nucleus.vk == VowelKind.TANWIN_DAMM:
                return True
        
        return False

4.2 ุจูุงุก ุงูุฑูุงุจุท ุงูุชุถููููุฉ (TADMINI)
Python
# ููู: src/fvafk/c2b/links_tadmini.py

class TadminiLinker:
    """
    ุจูุงุก ุงูุฑูุงุจุท ุงูุชุถููููุฉ: ูุนู ูุชุนุฏู โ ููุนูู
    
    ุงูููุงุนุฏ:
    1. ุงููุนู ุงููุชุนุฏู ูุญุชุงุฌ ููุนููุงู (ููุตูุจ)
    2. ุงููุนู ุงููุงุฒู ูุง ๏ฟฝ๏ฟฝุญุชุงุฌ ููุนููุงู
    3. ุจุนุถ ุงูุฃูุนุงู ุชุชุนุฏู ูููุนูููู
    """
    
    # ูุงุฆูุฉ ุงูุฃูุนุงู ุงููุชุนุฏูุฉ ุงูุดุงุฆุนุฉ
    TRANSITIVE_VERBS = {
        'ูุชุจ', 'ูุฑุฃ', 'ุฃูู', 'ุดุฑุจ', 'ูุชุญ', 'ุฃุฎุฐ', 'ุถุฑุจ',
        'ุนูู', 'ุฑุฃู', 'ุณูุน', 'ูุฌุฏ', 'ุฌุนู', 'ุธู',
        # ... ุงููุฒูุฏ (500+)
    }
    
    # ุฃูุนุงู ุชุชุนุฏู ูููุนูููู
    DITRANSITIVE_VERBS = {
        'ุฃุนุทู', 'ููุญ', 'ููุจ', 'ุนููู', 'ุฃุฑู', 'ุธู', 'ุญุณุจ',
        # ... ุงููุฒูุฏ (50+)
    }
    
    def build_links(self, wordforms: List[WordForm], 
                    isnadi_links: List[Link]) -> List[Link]:
        """
        ุจูุงุก ุงูุฑูุงุจุท ุงูุชุถููููุฉ
        
        ุงูุฎุทูุงุช:
        1. ุชุญุฏูุฏ ุงููุนู ุงููุชุนุฏู
        2. ุงูุจุญุซ ุนู ุงูููุนูู (ููุตูุจ)
        3. ุจูุงุก ุงูุฑุงุจุท
        """
        links = []
        
        # ุงุจุญุซ ุนู ุงูุฃูุนุงู
        for i, word in enumerate(wordforms):
            if word.word_kind == WordKind.VERB:
                
                # ูุญุต ุฅู ูุงู ูุชุนุฏูุงู
                if self._is_transitive(word):
                    
                    # ุงุจุญุซ ุนู ุงูููุนูู (ุงุณู ููุตูุจ)
                    obj_idx = self._find_object(wordforms, i)
                    
                    if obj_idx is not None:
                        links.append(Link(
                            rel=Rel3.TADMINI,
                            head=i,
                            dep=obj_idx,
                            confidence=0.85
                        ))
        
        return links
    
    def _is_transitive(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงู ุงููุนู ูุชุนุฏูุงู"""
        # ุงุณุชุฎุฑุงุฌ ุงูุฌุฐุฑ
        root = self._extract_root(word)
        
        # ูุญุต ุงููุงุฆูุฉ
        if root in self.TRANSITIVE_VERBS:
            return True
        
        # ูุงุนุฏุฉ ุนุงูุฉ: ุฃูุฒุงู ูุฒูุฏุฉ ุนุงุฏุฉ ูุชุนุฏูุฉ
        if word.pattern == PatternKind.VERB_MAZEED:
            return True
        
        return False
    
    def _find_object(self, wordforms: List[WordForm], 
                     verb_idx: int) -> Optional[int]:
        """ุงูุจุญุซ ุนู ุงูููุนูู ุจู"""
        # ุงุจุญุซ ุจุนุฏ ุงููุนู
        for i in range(verb_idx + 1, len(wordforms)):
            word = wordforms[i]
            
            if (word.word_kind == WordKind.NOUN and
                self._is_accusative(word)):
                
                return i
        
        return None
    
    def _is_accusative(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงูุช ุงููููุฉ ููุตูุจุฉ"""
        if 'case' in word.morph_flags:
            return word.morph_flags['case'] == 'accusative'
        
        # ูุญุต ูู ุงูููุงุทุน ุงูุฃุฎูุฑุฉ
        if word.syllables:
            last_syl = word.syllables[-1]
            nucleus = last_syl.nucleus
            
            # ูุชุญุฉ ูู ุงูููุงุฉ ุงูุฃุฎูุฑุฉ
            if nucleus.vk == VowelKind.FATHA:
                return True
            
            # ุชูููู ูุชุญ
            if nucleus.vk == VowelKind.TANWIN_FATH:
                return True
        
        return False
    
    def _extract_root(self, word: WordForm) -> str:
        """ุงุณุชุฎุฑุงุฌ ุฌุฐุฑ ุงููุนู"""
        # TODO: ุชูููุฐ ุงุณุชุฎุฑุงุฌ ุงูุฌุฐุฑ
        # ุญุงููุงู: ุงุณุชุฎุฏุงู ูุต ุงููููุฉ ูุจุงุดุฑุฉ (ุชุจุณูุท)
        text = ''.join(
            seg.text for syl in word.syllables
            for seg in syl.onset + [syl.nucleus] + syl.coda
            if seg.kind == SegmentKind.CONSONANT
        )
        return text[:3]  # ุฃูู 3 ุญุฑูู ุฃุตููุฉ

4.3 ุจูุงุก ุงูุฑูุงุจุท ุงูุชูููุฏูุฉ (TAQYIDI)
Python
# ููู: src/fvafk/c2b/links_taqyidi.py

class TaqyidiLinker:
    """
    ุจูุงุก ุงูุฑูุงุจุท ุงูุชูููุฏูุฉ: ุงุณู โ ูุนุช/ูุถุงู ุฅููู
    
    ุงูููุงุนุฏ:
    1. ุงููุนุช: ูุทุงุจู ุงูููุนูุช ูู (ุฅุนุฑุงุจุ ุชุนุฑููุ ุนุฏุฏุ ุฌูุณ)
    2. ุงููุถุงู ุฅููู: ูุฌุฑูุฑ ุฏุงุฆูุงู
    3. ุงูุธุฑู: ููุงู/ุฒูุงู
    """
    
    def build_links(self, wordforms: List[WordForm]) -> List[Link]:
        """
        ุจูุงุก ุงูุฑูุงุจุท ุงูุชูููุฏูุฉ
        
        ุงูุฎุทูุงุช:
        1. ุชุญุฏูุฏ ุงูุฃุณูุงุก
        2. ุงูุจุญุซ ุนู ุงููุนุช/ุงููุถุงู ุฅููู ุจุนุฏูุง
        3. ูุญุต ุงูุชุทุงุจู
        4. ุจูุงุก ุงูุฑุงุจุท
        """
        links = []
        
        for i in range(len(wordforms) - 1):
            word = wordforms[i]
            next_word = wordforms[i + 1]
            
            if word.word_kind == WordKind.NOUN:
                
                # ูุญุต ุงููุนุช
                if self._is_adjective_of(next_word, word):
                    links.append(Link(
                        rel=Rel3.TAQYIDI,
                        head=i,
                        dep=i + 1,
                        confidence=0.80
                    ))
                
                # ูุญุต ุงููุถุงู ุฅููู
                elif self._is_genitive_of(next_word, word):
                    links.append(Link(
                        rel=Rel3.TAQYIDI,
                        head=i,
                        dep=i + 1,
                        confidence=0.85
                    ))
        
        return links
    
    def _is_adjective_of(self, adjective: WordForm, noun: WordForm) -> bool:
        """
        ูุญุต ุฅู ูุงูุช ุงููููุฉ ูุนุชุงู ููุงุณู
        
        ุดุฑูุท ุงูุชุทุงุจู:
        1. ุงูุฅุนุฑุงุจ (ุฑูุน/ูุตุจ/ุฌุฑ)
        2. ุงูุชุนุฑูู/ุงูุชูููุฑ
        3. ุงูุนุฏุฏ (ููุฑุฏ/ูุซูู/ุฌูุน)
        4. ุงูุฌูุณ (ูุฐูุฑ/ูุคูุซ)
        """
        # 1. ุชุทุงุจู ุงูุฅุนุฑุงุจ
        noun_case = self._get_case(noun)
        adj_case = self._get_case(adjective)
        
        if noun_case != adj_case:
            return False
        
        # 2. ุชุทุงุจู ุงูุชุนุฑูู
        noun_def = noun.morph_flags.get('definite', False)
        adj_def = adjective.morph_flags.get('definite', False)
        
        if noun_def != adj_def:
            return False
        
        # 3. ุชุทุงุจู ุงูุนุฏุฏ
        noun_num = noun.morph_flags.get('number', 'singular')
        adj_num = adjective.morph_flags.get('number', 'singular')
        
        if noun_num != adj_num:
            return False
        
        # 4. ุชุทุงุจู ุงูุฌูุณ
        noun_gen = noun.morph_flags.get('gender', 'masculine')
        adj_gen = adjective.morph_flags.get('gender', 'masculine')
        
        if noun_gen != adj_gen:
            return False
        
        return True
    
    def _is_genitive_of(self, genitive: WordForm, noun: WordForm) -> bool:
        """
        ูุญุต ุฅู ูุงูุช ุงููููุฉ ูุถุงูุงู ุฅููู
        
        ุดุฑูุท:
        1. ุงูุงุณู ุงูุฃูู (ุงููุถุงู) ุจุฏูู ุชูููู
        2. ุงูุงุณู ุงูุซุงูู (ุงููุถุงู ุฅููู) ูุฌุฑูุฑ
        """
        # 1. ุงููุถุงู: ูุง ุชูููู
        if self._has_tanwin(noun):
            return False
        
        # 2. ุงููุถุงู ุฅููู: ูุฌุฑูุฑ
        if not self._is_genitive(genitive):
            return False
        
        return True
    
    def _get_case(self, word: WordForm) -> Optional[str]:
        """ุงุณุชุฎุฑุงุฌ ุญุงูุฉ ุงูุฅุนุฑุงุจ"""
        return word.morph_flags.get('case', None)
    
    def _has_tanwin(self, word: WordForm) -> bool:
        """ูุญุต ูุฌูุฏ ุชูููู"""
        if word.syllables:
            last_syl = word.syllables[-1]
            nucleus = last_syl.nucleus
            return nucleus.vk in {
                VowelKind.TANWIN_FATH,
                VowelKind.TANWIN_DAMM,
                VowelKind.TANWIN_KASR
            }
        return False
    
    def _is_genitive(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงูุช ุงููููุฉ ูุฌุฑูุฑุฉ"""
        if 'case' in word.morph_flags:
            return word.morph_flags['case'] == 'genitive'
        
        # ูุญุต ูู ุงูููุงุทุน ุงูุฃุฎูุฑุฉ
        if word.syllables:
            last_syl = word.syllables[-1]
            nucleus = last_syl.nucleus
            
            # ูุณุฑุฉ ูู ุงูููุงุฉ ุงูุฃุฎูุฑุฉ
            if nucleus.vk == VowelKind.KASRA:
                return True
            
            # ุชูููู ูุณุฑ
            if nucleus.vk == VowelKind.TANWIN_KASR:
                return True
        
        return False

4.4 ุงููุญูู ุงููุญูู ุงููุงูู (Orchestrator)
Python
# ููู: src/fvafk/c2b/parser.py

class SyntacticParser:
    """
    ุงููุญูู ุงููุญูู ุงููุงูู: ูุฏูุฌ ุฌููุน ุฃููุงุน ุงูุฑูุงุจุท
    
    ุงููุฑุงุญู:
    1. ุจูุงุก ุงูุฑูุงุจุท ุงูุฅุณูุงุฏูุฉ (ISNADI)
    2. ุจูุงุก ุงูุฑูุงุจุท ุงูุชุถููููุฉ (TADMINI)
    3. ุจูุงุก ุงูุฑูุงุจุท ุงูุชูููุฏูุฉ (TAQYIDI)
    4. ุงูุชุญูู ูู ุงููููุฏ ุงููุญููุฉ
    """
    
    def __init__(self):
        self.isnadi_linker = IsnadiLinker()
        self.tadmini_linker = TadminiLinker()
        self.taqyidi_linker = TaqyidiLinker()
    
    def parse(self, wordforms: List[WordForm]) -> Tuple[List[Link], List[str]]:
        """
        ุชุญููู ูุญูู ูุงูู
        
        ุฅุฑุฌุงุน:
        - links: ูุงุฆูุฉ ุงูุฑูุงุจุท
        - errors: ูุงุฆูุฉ ุงูุฃุฎุทุงุก ุงููุญููุฉ
        """
        links = []
        errors = []
        
        # 1. ุงูุฑูุงุจุท ุงูุฅุณูุงุฏูุฉ (ุฃููุงู)
        isnadi_links = self.isnadi_linker.build_links(wordforms)
        links.extend(isnadi_links)
        
        # 2. ุงูุฑูุงุจุท ุงูุชุถููููุฉ
        tadmini_links = self.tadmini_linker.build_links(wordforms, isnadi_links)
        links.extend(tadmini_links)
        
        # 3. ุงูุฑูุงุจุท ุงูุชูููุฏูุฉ
        taqyidi_links = self.taqyidi_linker.build_links(wordforms)
        links.extend(taqyidi_links)
        
        # 4. ุงูุชุญูู ูู ุงููููุฏ (ุงููุฑุญูุฉ ุงูุชุงููุฉ)
        # errors = self._validate_constraints(wordforms, links)
        
        return links, errors
    
    def visualize(self, wordforms: List[WordForm], links: List[Link]) -> str:
        """
        ุชุตููุฑ ุจุตุฑู ููุชุญููู ุงููุญูู
        
        ูุซุงู:
        ```
        ุฐูููุจู    ููุญููููุฏู    ุฅูููู    ุงูููุฏูุฑูุณูุฉู
        verb      noun        prep     noun
          โโISNADIโโ
               โโโTADMINIโโโโโโโโโ
        ```
        """
        # TODO: ุชูููุฐ ุงูุชุตููุฑ ุงูุจุตุฑู
        pass

ุงููุฎุฑุฌุงุช ูููุฑุญูุฉ 4:
 src/fvafk/c2b/links_isnadi.py + 20 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/links_tadmini.py + 20 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/links_taqyidi.py + 25 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/parser.py + 15 ุงุฎุชุจุงุฑ
 coq/theories/Syntax.v (15 ูุจุฑููุฉ)
 tests/test_parser_corpus.py (ุงุฎุชุจุงุฑ ุนูู corpus)
ูุนูุงุฑ ุงููุฌุงุญ:
Code
โ 80+ ุงุฎุชุจุงุฑ ููุฑ
โ UAS (Unlabeled Attachment Score) โฅ 0.80
โ LAS (Labeled Attachment Score) โฅ 0.75
โ ุฏูุฉ ุชุญุฏูุฏ ููุน ุงูุฑุงุจุท โฅ 85%

โ๏ธ ุงููุฑุญูุฉ 5: ุงููููุฏ ุงููุญููุฉ (Week 12-13)
ุงููุฏู:
Code
ุชุทุจูู 5 ูููุฏ ูุญููุฉ ุจุงููุงูู (ุจุฏูู stubs)

5.1 ุงูููุฏ 1: ูุง ูุนู ุจูุง ูุงุนู
Python
# ููู: src/fvafk/c2b/constraints/verb_subject.py

class VerbSubjectConstraint:
    """
    ุงูููุฏ: ูุง ูุนู ุจูุง ูุงุนู (ุฅูุง ูู ุงููุจูู ูููุฌููู)
    
    ุงููุงุนุฏุฉ:
    - ูู ูุนู ูุญุชุงุฌ ูุงุนูุงู (ุฑุงุจุท ISNADI)
    - ุงุณุชุซูุงุก: ุงููุนู ุงููุจูู ูููุฌููู (ูุญุชุงุฌ ูุงุฆุจ ูุงุนู)
    """
    
    def validate(self, wordforms: List[WordForm], 
                 links: List[Link]) -> List[ConstraintViolation]:
        """
        ุงูุชุญูู ูู ุงูููุฏ
        
        ุฅุฑุฌุงุน: ูุงุฆูุฉ ุงูุงูุชูุงูุงุช
        """
        violations = []
        
        # ุงุจุญุซ ุนู ุงูุฃูุนุงู
        for i, word in enumerate(wordforms):
            if word.word_kind == WordKind.VERB:
                
                # ูุญุต ุฅู ูุงู ูุจููุงู ูููุฌููู
                is_passive = self._is_passive_voice(word)
                
                # ูุญุต ูุฌูุฏ ุฑุงุจุท ISNADI ูู ุงููุนู
                has_subject = any(
                    link.rel == Rel3.ISNADI and link.head == i
                    for link in links
                )
                
                if not has_subject and not is_passive:
                    violations.append(ConstraintViolation(
                        constraint_id="NO_VERB_WITHOUT_SUBJECT",
                        word_idx=i,
                        message=f"ุงููุนู '{self._get_word_text(word)}' ูุญุชุงุฌ ูุงุนูุงู",
                        severity="ERROR"
                    ))
        
        return violations
    
    def _is_passive_voice(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงู ุงููุนู ูุจููุงู ูููุฌููู"""
        # ุนูุงูุงุช ุงูุจูุงุก ูููุฌููู:
        # 1. ุถู ุฃูู ุญุฑู ูู ุงููุงุถู (ุถูุฑูุจู)
        # 2. ุถู ุฃูู ุญุฑู ููุชุญ ูุจู ุงูุขุฎุฑ ูู ุงููุถุงุฑุน (ููุถูุฑูุจ)
        
        if word.syllables:
            first_syl = word.syllables[0]
            nucleus = first_syl.nucleus
            
            # ุถูุฉ ูู ุงูููุทุน ุงูุฃูู
            if nucleus.vk == VowelKind.DAMMA:
                return True
        
        return False
    
    def _get_word_text(self, word: WordForm) -> str:
        """ุงุณุชุฎุฑุงุฌ ูุต ุงููููุฉ"""
        return ''.join(
            seg.text for syl in word.syllables
            for seg in syl.onset + [syl.nucleus] + syl.coda
        )

5.2 ุงูููุฏ 2: ูุง ูุชุนุฏู ุจูุง ููุนูู
Python
# ููู: src/fvafk/c2b/constraints/transitive_object.py

class TransitiveObjectConstraint:
    """
    ุงูููุฏ: ูุง ูุนู ูุชุนุฏู ุจูุง ููุนูู
    
    ุงููุงุนุฏุฉ:
    - ูู ูุนู ูุชุนุฏู ูุญุชุงุฌ ููุนููุงู (ุฑุงุจุท TADMINI)
    """
    
    # ูุงุฆูุฉ ุงูุฃูุนุงู ุงููุชุนุฏูุฉ (500+)
    TRANSITIVE_VERBS = {
        'ูุชุจ', 'ูุฑุฃ', 'ุฃูู', 'ุดุฑุจ', 'ูุชุญ', 'ุฃุฎุฐ',
        # ... (ูููู ุชุญููููุง ูู ููู ุฎุงุฑุฌู)
    }
    
    def validate(self, wordforms: List[WordForm], 
                 links: List[Link]) -> List[ConstraintViolation]:
        violations = []
        
        for i, word in enumerate(wordforms):
            if word.word_kind == WordKind.VERB:
                
                # ูุญุต ุฅู ูุงู ูุชุนุฏูุงู
                if self._is_transitive(word):
                    
                    # ูุญุต ูุฌูุฏ ุฑุงุจุท TADMINI ูู ุงููุนู
                    has_object = any(
                        link.rel == Rel3.TADMINI and link.head == i
                        for link in links
                    )
                    
                    if not has_object:
                        violations.append(ConstraintViolation(
                            constraint_id="NO_TRANSITIVE_WITHOUT_OBJECT",
                            word_idx=i,
                            message=f"ุงููุนู ุงููุชุนุฏู '{self._get_word_text(word)}' ูุญุชุงุฌ ููุนููุงู",
                            severity="ERROR"
                        ))
        
        return violations
    
    def _is_transitive(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงู ุงููุนู ูุชุนุฏูุงู"""
        root = self._extract_root(word)
        return root in self.TRANSITIVE_VERBS

5.3 ุงูููุฏ 3: ุชุทุงุจู ุงููุนุช ูุงูููุนูุช
Python
# ููู: src/fvafk/c2b/constraints/adjective_agreement.py

class AdjectiveAgreementConstraint:
    """
    ุงูููุฏ: ุชุทุงุจู ุงููุนุช ูุงูููุนูุช ูู 4 ุฃูุฌู
    
    ุงููุงุนุฏุฉ:
    - ุงููุนุช ูุทุงุจู ุงูููุนูุช ูู:
      1. ุงูุฅุนุฑุงุจ (ุฑูุน/ูุตุจ/ุฌุฑ)
      2. ุงูุชุนุฑูู/๏ฟฝ๏ฟฝูุชูููุฑ
      3. ุงูุนุฏุฏ (ููุฑุฏ/ูุซูู/ุฌูุน)
      4. ุงูุฌูุณ (ูุฐูุฑ/ูุคูุซ)
    """
    
    def validate(self, wordforms: List[WordForm], 
                 links: List[Link]) -> List[ConstraintViolation]:
        violations = []
        
        # ุงุจุญุซ ุนู ุฑูุงุจุท TAQYIDI (ูุนุช)
        for link in links:
            if link.rel == Rel3.TAQYIDI:
                
                noun = wordforms[link.head]
                adjective = wordforms[link.dep]
                
                # ูุญุต ุงูุชุทุงุจู ูู 4 ุฃูุฌู
                mismatches = self._check_agreement(noun, adjective)
                
                if mismatches:
                    violations.append(ConstraintViolation(
                        constraint_id="ADJECTIVE_NOUN_MISMATCH",
                        word_idx=link.dep,
                        message=f"ุนุฏู ุชุทุงุจู: {', '.join(mismatches)}",
                        severity="ERROR"
                    ))
        
        return violations
    
    def _check_agreement(self, noun: WordForm, 
                         adjective: WordForm) -> List[str]:
        """ูุญุต ุงูุชุทุงุจู ูู 4 ุฃูุฌู"""
        mismatches = []
        
        # 1. ุงูุฅุนุฑุงุจ
        noun_case = noun.morph_flags.get('case')
        adj_case = adjective.morph_flags.get('case')
        if noun_case != adj_case:
            mismatches.append(f"ุงูุฅุนุฑุงุจ ({noun_case} โ {adj_case})")
        
        # 2. ุงูุชุนุฑูู
        noun_def = noun.morph_flags.get('definite', False)
        adj_def = adjective.morph_flags.get('definite', False)
        if noun_def != adj_def:
            mismatches.append(f"ุงูุชุนุฑูู ({noun_def} โ {adj_def})")
        
        # 3. ุงูุนุฏุฏ
        noun_num = noun.morph_flags.get('number')
        adj_num = adjective.morph_flags.get('number')
        if noun_num != adj_num:
            mismatches.append(f"ุงูุนุฏุฏ ({noun_num} โ {adj_num})")
        
        # 4. ุงูุฌูุณ
        noun_gen = noun.morph_flags.get('gender')
        adj_gen = adjective.morph_flags.get('gender')
        if noun_gen != adj_gen:
            mismatches.append(f"ุงูุฌูุณ ({noun_gen} โ {adj_gen})")
        
        return mismatches

5.4 ุงูููุฏ 4: ุงูุณุจุจูุฉ ุชุชุทูุจ ุฃุญุฏุงุซุงู
Python
# ููู: src/fvafk/c2b/constraints/causality_events.py

class CausalityEventsConstraint:
    """
    ุงูููุฏ: ุงูุณุจุจูุฉ ุชุชุทูุจ ุฃุญุฏุงุซุงู
    
    ุงููุงุนุฏุฉ:
    - ุฅุฐุง ููุฌุฏุช ุนูุงูุฉ ุณุจุจูุฉ (cause โ effect)
    - ูุฌุจ ุฃู ูููู ููุงููุง ุญุฏุซุงู (event)
    """
    
    # ุฃุฏูุงุช ุงูุณุจุจูุฉ
    CAUSALITY_PARTICLES = {
        'ูุฃู', 'ูุฐูู', 'ูู', 'ุฅุฐู', 'ุญุชู', 'ูู', 'ูู'
    }
    
    def validate(self, wordforms: List[WordForm], 
                 links: List[Link],
                 events: List[Event]) -> List[ConstraintViolation]:
        violations = []
        
        # ุงุจุญุซ ุนู ุฃุฏูุงุช ุงูุณุจุจูุฉ
        for i, word in enumerate(wordforms):
            word_text = self._get_word_text(word)
            
            if word_text in self.CAUSALITY_PARTICLES:
                
                # ูุญุต ูุฌูุฏ ุญุฏุซ ูุจู ูุจุนุฏ ุงูุฃุฏุงุฉ
                has_event_before = self._has_event_at(events, i - 1)
                has_event_after = self._has_event_at(events, i + 1)
                
                if not (has_event_before and has_event_after):
                    violations.append(ConstraintViolation(
                        constraint_id="CAUSALITY_WITHOUT_EVENTS",
                        word_idx=i,
                        message=f"ุงูุฃุฏุงุฉ ุงูุณุจุจูุฉ '{word_text}' ุชุญุชุงุฌ ุญุฏุซูู",
                        severity="WARNING"
                    ))
        
        return violations
    
    def _has_event_at(self, events: List[Event], word_idx: int) -> bool:
        """ูุญุต ูุฌูุฏ ุญุฏุซ ุนูุฏ ุงูููุฑุณ ุงููุญุฏุฏ"""
        return any(event.word_idx == word_idx for event in events)

5.5 ุงูููุฏ 5: ุงููุจูู ูููุฌููู ูุชุทูุจ ุชุบููุฑ ุตูุบุฉ
Python
# ููู: src/fvafk/c2b/constraints/passive_voice.py

class PassiveVoiceConstraint:
    """
    ุงูููุฏ: ุงููุจูู ูููุฌููู ูุชุทูุจ ุชุบููุฑ ุตูุบุฉ
    
    ุงููุงุนุฏุฉ:
    - ุงููุนู ุงููุจูู ูููุฌููู:
      1. ุถู ุฃูู ุญุฑู ูู ุงููุงุถู (ุถูุฑูุจู)
      2. ูุณุฑ ูุง ูุจู ุงูุขุฎุฑ
    - ูุญุชุงุฌ ูุงุฆุจ ูุงุนู (ูุฑููุน)
    """
    
    def validate(self, wordforms: List[WordForm], 
                 links: List[Link]) -> List[ConstraintViolation]:
        violations = []
        
        for i, word in enumerate(wordforms):
            if word.word_kind == WordKind.VERB:
                
                # ูุญุต ุฅู ูุงู ูุจููุงู ูููุฌููู
                if self._is_passive_voice(word):
                    
                    # ูุญุต ุงูุตูุบุฉ ุงูุตุฑููุฉ
                    if not self._has_passive_morphology(word):
                        violations.append(ConstraintViolation(
                            constraint_id="PASSIVE_WITHOUT_MORPHOLOGY",
                            word_idx=i,
                            message="ุงููุนู ุงููุจูู ูููุฌููู ูุญุชุงุฌ ุชุบููุฑ ุตูุบุฉ",
                            severity="ERROR"
                        ))
                    
                    # ูุญุต ูุฌูุฏ ูุงุฆุจ ูุงุนู (ISNADI)
                    has_deputy_subject = any(
                        link.rel == Rel3.ISNADI and link.head == i
                        for link in links
                    )
                    
                    if not has_deputy_subject:
                        violations.append(ConstraintViolation(
                            constraint_id="PASSIVE_WITHOUT_DEPUTY_SUBJECT",
                            word_idx=i,
                            message="ุงููุนู ุงููุจูู ูููุฌููู ูุญุชุงุฌ ูุงุฆุจ ูุงุนู",
                            severity="ERROR"
                        ))
        
        return violations
    
    def _is_passive_voice(self, word: WordForm) -> bool:
        """ูุญุต ุฅู ูุงู ุงููุนู ูุจููุงู ูููุฌููู"""
        # ุถูุฉ ูู ุงูููุทุน ุงูุฃูู
        if word.syllables:
            first_syl = word.syllables[0]
            if first_syl.nucleus.vk == VowelKind.DAMMA:
                return True
        return False
    
    def _has_passive_morphology(self, word: WordForm) -> bool:
        """ูุญุต ูุฌูุฏ ุตูุบุฉ ุงููุจูู ูููุฌููู"""
        if len(word.syllables) < 2:
            return False
        
        # ุถู ุงูุฃูู + ูุณุฑ ูุง ูุจู ุงูุขุฎุฑ
        first = word.syllables[0].nucleus
        penult = word.syllables[-2].nucleus if len(word.syllables) > 1 else None
        
        return (first.vk == VowelKind.DAMMA and
                penult is not None and 
                penult.vk == VowelKind.KASRA)

5.6 ูุธุงู ุงูุชุญูู ุงููุงูู
Python
# ููู: src/fvafk/c2b/constraint_validator.py

@dataclass
class ConstraintViolation:
    """ุงูุชูุงู ููุฏ ูุญูู"""
    constraint_id: str
    word_idx: int
    message: str
    severity: str  # ERROR | WARNING | INFO

class ConstraintValidator:
    """
    ูุธุงู ุงูุชุญูู ูู ุฌููุน ุงููููุฏ ุงููุญููุฉ
    """
    
    def __init__(self):
        self.constraints = [
            VerbSubjectConstraint(),
            TransitiveObjectConstraint(),
            AdjectiveAgreementConstraint(),
            CausalityEventsConstraint(),
            PassiveVoiceConstraint(),
        ]
    
    def validate_all(self, wordforms: List[WordForm], 
                     links: List[Link],
                     events: List[Event]) -> Tuple[bool, List[ConstraintViolation]]:
        """
        ุงูุชุญูู ูู ุฌููุน ุงููููุฏ
        
        ุฅุฑุฌุงุน:
        - is_valid: ูู ุงููุต ุตุญูุญ ูุญููุงูุ
        - violations: ูุงุฆูุฉ ุงูุงูุชูุงูุงุช
        """
        all_violations = []
        
        for constraint in self.constraints:
            violations = constraint.validate(wordforms, links, events)
            all_violations.extend(violations)
        
        # ููุท ุงูุฃุฎุทุงุก ุชุฌุนู ุงููุต ุบูุฑ ุตุญูุญ
        has_errors = any(v.severity == "ERROR" for v in all_violations)
        is_valid = not has_errors
        
        return is_valid, all_violations
    
    def generate_report(self, violations: List[ConstraintViolation]) -> str:
        """
        ุชูุฑูุฑ ููุตูู ุนู ุงูุงูุชูุงูุงุช
        """
        if not violations:
            return "โ ุงููุต ุตุญูุญ ูุญููุงู"
        
        report = f"โ๏ธ ููุฌุฏ {len(violations)} ุงูุชูุงู:\n\n"
        
        for i, v in enumerate(violations, 1):
            report += f"{i}. [{v.severity}] {v.constraint_id}\n"
            report += f"   ุงููููุฉ #{v.word_idx}: {v.message}\n\n"
        
        return report

ุงููุฎุฑุฌุงุช ูููุฑุญูุฉ 5:
 5 ูููุงุช constraints (ูุงุญุฏ ููู ููุฏ) + 50 ุงุฎุชุจุงุฑ
 src/fvafk/c2b/constraint_validator.py + 15 ุงุฎุชุจุงุฑ
 coq/theories/Constraints.v (10 ูุจุฑููุงุช)
 tests/test_constraints_corpus.py (ุงุฎุชุจุงุฑ ุนูู corpus)
ูุนูุงุฑ ุงููุฌุงุญ:
Code
โ 65+ ุงุฎุชุจุงุฑ ููุฑ
โ ุฏูุฉ ูุดู ุงูุฃุฎุทุงุก โฅ 90%
โ ูุนุฏู false positives โค 10%
โ 0 ุงูุชูุงูุงุช ุนูู ูุตูุต ุตุญูุญุฉ

| Constraint | Test artifacts | Metric target | Data source |
| --- | --- | --- | --- |
| ูุง ูุนู ุจูุง ูุงุนู | `tests/test_constraints_corpus.py` scenarios + corpus subject checks | 0 violations on valid sentences | Annotated active/passive sentences |
| ูุง ูุชุนุฏู ุจูุง ููุนูู | Transitive verb cases | โฅ95% detection of missing objects | `tests/` + targeted verbs dataset |
| ุชุทุงุจู ุงููุนุช ูุงูููุนูุช | Adjective/Noun agreement bench | 0 mismatches on annotated pairs | Grammar corpus (nouns/adjectives) |
| ุงูุณุจุจูุฉ ุชุชุทูุจ ุฃุญุฏุงุซุงู | EventExtractor-driven tests | Evidence coverage โฅ90% | Causal corpus with particles (ูุฃูุ ูุฐูู...) |
| ุงููุจูู ูููุฌููู ูุชุทูุจ ุชุบููุฑ ุตูุบุฉ | Passive constructions + root checks | โฅ90% detection accuracy | Passive voice dataset + root extractor output |

๐ ุงููุฑุญูุฉ 6: ุงูุชูุงูู ูุงูุชุญุณูู (Week 14-16)
ุงููุฏู:
Code
ุชูุงูู ุฌููุน ุงูููููุงุช + ุงุฎุชุจุงุฑ end-to-end + ุชุญุณูู ุงูุฃุฏุงุก

6.1 Pipeline ุงููุงูู
Python
# ููู: src/fvafk/pipeline/complete_pipeline.py

class CompletePipeline:
    """
    ุงููุนุงูุฌุฉ ุงููุงููุฉ: ูุต โ ูุนูู
    
    ุงููุฑุงุญู:
    C1: Text โ Segments
    C2a: Segments โ Syllables (10 phonological gates)
    C2b: Syllables โ WordForms + Links (morphology + syntax)
    C2c: Accept/Reject decision (semantic gates)
    C3: Meaning (if accepted)
    """
    
    def __init__(self):
        # C1: Text adapter
        self.codec = FormCodecV2(UnitDictionary())
        
        # C2a: Phonological gates (10)
        self.phono_gates = [
            GateSukun(),
            GateShadda(),
            GateTanwin(),
            GateAssimilation(),
            GateIdgham(),
            GateHamza(),
            GateMadd(),
            GateWaqf(),
            GateDeletion(),
            GateEpenthesis(),
        ]
        
        # C2a: Syllabifier
        self.syllabifier = Syllabifier()
        
        # C2b: Morphological analyzer
        self.word_boundary_detector = WordBoundaryDetector()
        self.pattern_analyzer = PatternAnalyzer()
        self.word_classifier = WordClassifier()
        
        # C2b: Syntactic parser
        self.parser = SyntacticParser()
        
        # C2b: Constraint validator
        self.constraint_validator = ConstraintValidator()
        
        # C2c: Semantic gates
        self.semantic_gate = SemanticGate()
        
        # Statistics
        self.stats = PipelineStatistics()
    
    def process(self, text: str, prior: PriorInfo) -> ProcessingResult:
        """
        ูุนุงูุฌุฉ ูุงููุฉ ูู ูุต ุฅูู ูุนูู
        
        ุงููุฑุงุญู:
        1. C1: ุชุญููู ุงููุต ูู segments
        2. C2a: ุชุทุจูู ุงูุจูุงุจุงุช ุงูุตูุชูุฉ
        3. C2a: ุชูุทูุน ูููุงุทุน
        4. C2b: ุชุญููู ุตุฑูู
        5. C2b: ุชุญููู ูุญูู
        6. C2b: ุงูุชุญูู ูู ุงููููุฏ
        7. C2c: ูุฑุงุฑ ุงููุจูู/ุงูุฑูุถ
        8. C3: ุชูููุฏ ุงููุนูู (ุฅู ููุจู)
        """
        import time
        start_time = time.time()
        
        result = ProcessingResult()
        
        try:
            # ========== C1 ==========
            c1_start = time.time()
            
            # ุชุญููู ุงููุต ูู units
            units, payload, checksum = self.codec.encode_with_header(text)
            
            # ุงูุชุญูู ูู ุงูุนููุณูุฉ (T_CODEC_REVERSIBLE)
            decoded = self.codec.decode_with_header(payload, checksum)
            assert decoded == text, "Codec reversibility failed!"
            
            result.c1_units = units
            result.c1_time_ms = (time.time() - c1_start) * 1000
            
            # ========== C2a: Phonological Gates ==========
            c2a_start = time.time()
            
            # ุชุทุจูู ุงูุจูุงุจุงุช ุงูุตูุชูุฉ
            current_units = units
            for gate in self.phono_gates:
                gate_result = gate.run(current_units)
                
                result.gate_results.append(gate_result)
                
                if gate_result.status == GateStatus.REJECT:
                    result.accept = False
                    result.reject_reason = gate_result.reason
                    return result
                
                current_units = gate_result.output
            
            # ุชูุทูุน ูููุงุทุน
            syllables = self.syllabifier.syllabify(current_units)
            if syllables is None:
                result.accept = False
                result.reject_reason = "Syllabification failed"
                return result
            
            result.syllables = syllables
            result.c2a_time_ms = (time.time() - c2a_start) * 1000
            
            # ========== C2b: Morphology ==========
            c2b_start = time.time()
            
            # ุชุญุฏูุฏ ุญุฏูุฏ ุงููููุงุช
            word_boundaries = self.word_boundary_detector.detect_boundaries(syllables)
            
            # ุชุญููู ูู ูููุฉ
            wordforms = []
            for start_idx, end_idx in word_boundaries:
                word_syls = syllables[start_idx:end_idx+1]
                
                # ุชุญููู ุงููุฒู
                pattern = self.pattern_analyzer.analyze(word_syls)
                
                # ุชุตููู ููุน ุงููููุฉ
                word_text = self._syllables_to_text(word_syls)
                word_kind = self.word_classifier.classify(word_text, pattern)
                
                # ุจูุงุก WordForm
                wordform = WordForm(
                    syllables=word_syls,
                    word_kind=word_kind,
                    i3rab=I3rabKind.MU3RAB,  # TODO: ุชุญุฏูุฏ ุฏููู
                    pattern=pattern if pattern else PatternKind.JAMID,
                    root_gate=RootGateKind.JAMID_ROOT,  # TODO
                    morph_flags=self._extract_morph_flags(word_syls)
                )
                
                wordforms.append(wordform)
            
            result.wordforms = wordforms
            
            # ========== C2b: Syntax ==========
            
            # ุชุญููู ูุญูู
            links, parse_errors = self.parser.parse(wordforms)
            result.links = links
            
            # ุงูุชุญูู ูู ุงููููุฏ
            events = []  # TODO: ุงุณุชุฎุฑุงุฌ ุงูุฃุญุฏุงุซ
            is_valid, violations = self.constraint_validator.validate_all(
                wordforms, links, events
            )
            
            result.constraint_violations = violations
            result.c2b_time_ms = (time.time() - c2b_start) * 1000
            
            # ========== C2c: Semantic Gate ==========
            c2c_start = time.time()
            
            # ุจูุงุก TraceC2
            trace = TraceC2(
                syllables=syllables,
                wordforms=wordforms,
                links=links,
                prior=prior,
                evidence=EvidenceWeight(score=1.0, parts=[]),
                conflict=ConflictResolutionRule(strategy="max_evidence"),
                scope=ScopeRule(quantifier_scope={}),
                reality=RealityLink(truth_ok=True, reference_ok=True, reality_tests=[]),
                events=events,
                accept=is_valid and not parse_errors,
                reject_reason=None if is_valid else "Constraint violations"
            )
            
            result.trace = trace
            result.accept = trace.accept
            result.reject_reason = trace.reject_reason
            result.c2c_time_ms = (time.time() - c2c_start) * 1000
            
            # ========== C3: Meaning ==========
            if trace.accept:
                c3_start = time.time()
                
                meaning = Meaning(
                    trace=trace,
                    payload={
                        "text": text,
                        "wordforms": [self._wordform_to_dict(wf) for wf in wordforms],
                        "links": [self._link_to_dict(link) for link in links],
                    }
                )
                
                result.meaning = meaning
                result.c3_time_ms = (time.time() - c3_start) * 1000
            
            # ========== Statistics ==========
            result.total_time_ms = (time.time() - start_time) * 1000
            
            self.stats.record(result)
            
        except Exception as e:
            result.accept = False
            result.reject_reason = f"Pipeline error: {e}"
            result.exception = e
        
        return result
    
    def _syllables_to_text(self, syllables: List[Syllable]) -> str:
        """ุชุญููู ููุงุทุน ููุต"""
        return ''.join(
            seg.text for syl in syllables
            for seg in syl.onset + [syl.nucleus] + syl.coda
        )
    
    def _extract_morph_flags(self, syllables: List[Syllable]) -> Dict[str, Any]:
        """ุงุณุชุฎุฑุงุฌ ุงูุณูุงุช ุงูุตุฑููุฉ"""
        # TODO: ุชูููุฐ ุงุณุชุฎุฑุงุฌ ุฏููู
        return {
            'case': 'nominative',
            'definite': False,
            'number': 'singular',
            'gender': 'masculine',
        }
    
    def _wordform_to_dict(self, wf: WordForm) -> Dict:
        """ุชุญููู WordForm ูู dict"""
        return {
            'text': self._syllables_to_text(wf.syllables),
            'kind': wf.word_kind.name,
            'pattern': wf.pattern.name,
        }
    
    def _link_to_dict(self, link: Link) -> Dict:
        """ุชุญููู Link ูู dict"""
        return {
            'rel': link.rel.name,
            'head': link.head,
            'dep': link.dep,
            'confidence': link.confidence,
        }

@dataclass
class ProcessingResult:
    """ูุชูุฌุฉ ุงููุนุงูุฌุฉ ุงููุงููุฉ"""
    # C1
    c1_units: List[Unit] = field(default_factory=list)
    c1_time_ms: float = 0.0
    
    # C2a
    gate_results: List[GateResult] = field(default_factory=list)
    syllables: List[Syllable] = field(default_factory=list)
    c2a_time_ms: float = 0.0
    
    # C2b
    wordforms: List[WordForm] = field(default_factory=list)
    links: List[Link] = field(default_factory=list)
    constraint_violations: List[ConstraintViolation] = field(default_factory=list)
    c2b_time_ms: float = 0.0
    
    # C2c
    trace: Optional[TraceC2] = None
    c2c_time_ms: float = 0.0
    
    # C3
    meaning: Optional[Meaning] = None
    c3_time_ms: float = 0.0
    
    # Decision
    accept: bool = True
    reject_reason: Optional[str] = None
    exception: Optional[Exception] = None
    
    # Total
    total_time_ms: float = 0.0

6.2 ุงุฎุชุจุงุฑ Corpus ุดุงูู
Python
# ููู: tests/test_complete_corpus.py

import pytest
from pathlib import Path

class TestCompleteCorpus:
    """
    ุงุฎุชุจุงุฑ ุดุงูู ุนูู corpus ุญูููู
    
    Corpus:
    - 100 ุขูุฉ ูู ุงููุฑุขู
    - 50 ุญุฏูุซ ูุจูู
    - 50 ุฌููุฉ MSA
    """
    
    @pytest.fixture
    def pipeline(self):
        return CompletePipeline()
    
    @pytest.fixture
    def quran_corpus(self):
        """ุชุญููู ุขูุงุช ูุฑุขููุฉ"""
        corpus_file = Path(__file__).parent / "data" / "quran_100.txt"
        with open(corpus_file, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    
    @pytest.fixture
    def hadith_corpus(self):
        """ุชุญููู ุฃุญุงุฏูุซ"""
        corpus_file = Path(__file__).parent / "data" / "hadith_50.txt"
        with open(corpus_file, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    
    def test_quran_corpus_processing(self, pipeline, quran_corpus):
        """ูุนุงูุฌุฉ 100 ุขูุฉ ูุฑุขููุฉ"""
        results = []
        
        for i, ayah in enumerate(quran_corpus, 1):
            result = pipeline.process(ayah, PriorInfo())
            results.append(result)
            
            # ุชุญูู ุฃุณุงุณู
            assert result.c1_units, f"Ayah {i}: No C1 units"
            assert result.syllables, f"Ayah {i}: No syllables"
            assert result.wordforms, f"Ayah {i}: No wordforms"
        
        # ุฅุญุตุงุฆูุงุช
        accept_rate = sum(1 for r in results if r.accept) / len(results)
        avg_time = sum(r.total_time_ms for r in results) / len(results)
        
        print(f"\n๐ Quran Corpus Statistics:")
        print(f"  Processed: {len(results)} ayahs")
        print(f"  Accept rate: {accept_rate:.2%}")
        print(f"  Avg time: {avg_time:.2f}ms")
        
        # ูุนูุงุฑ ุงููุฌุงุญ
        assert accept_rate >= 0.85, f"Accept rate too low: {accept_rate:.2%}"
        assert avg_time <= 50.0, f"Processing too slow: {avg_time:.2f}ms"
    
    def test_morphology_accuracy(self, pipeline, quran_corpus):
        """ุฏูุฉ ุงูุชุญููู ุงูุตุฑูู"""
        # TODO: ูุญุชุงุฌ gold-standard annotations
        pass
    
    def test_syntax_accuracy(self, pipeline, quran_corpus):
        """ุฏูุฉ ุงูุชุญููู ุงููุญูู"""
        # TODO: ูุญุชุงุฌ gold-standard annotations
        pass

### Evidence, PriorInfo & CLI deliverables
- **SemanticGate evidence composition**: combine `gate_results`, `wordforms`, `links`, and `events` into a single `EvidenceWeight` object with fields `{phonology:30%, morphology:25%, syntax:25%, events:10%, context:10%}`; documented in `docs/SEMANTIC_GATE.md`.
- **PriorInfo shape**: include `expected_register`, `topic`, `conversation_id`, `memory_terms` so `TraceC2` can compare against evidence history; add helper builder `PriorInfo.from_metadata()` and log its values in CLI JSON output.
- **RealityLink & Accept criteria**: each `ProcessingResult` stores `reality_tests` (list of `RealityTest` ids) and sets `accept` only if `evidence.score >= 0.5`, `scope_ok`, `truth_ok`, and `reference_ok` are true.
- **CLI module** (`python -m fvafk.cli`): Accepts `--verbose`, `--json`, `--coq-verify`; prints JSON containing gate decisions, events, links, violations, evidence score, and final accept/reject reason (matches docs/CLI.md sample).
- **Property-based tests**: Hypothesis scenarios for idempotence, preservation, and reversibility; results written to `tests/results/property_{id}.json` for CI tracking.
- **Documentation outputs**: produce `docs/TRACE.md` (trace format), `docs/EVIDENCE.md` (weights & falsifiability), `docs/CLI.md` (CLI schema with sample JSON) as part of week 16 deliverables.

6.3 ุชุญุณูู ุงูุฃุฏุงุก
Python
# ููู: src/fvafk/optimization/caching.py

from functools import lru_cache
from typing import Tuple

class PerformanceOptimizer:
    """
    ุชุญุณููุงุช ุงูุฃุฏุงุก:
    1. Caching ูููุชุงุฆุฌ ุงูููุฑุฑุฉ
    2. Batch processing
    3. Parallel processing (optional)
    """
    
    @staticmethod
    @lru_cache(maxsize=10000)
    def cached_syllabify(units_tuple: Tuple[Unit, ...]) -> Tuple[Syllable, ...]:
        """ุชูุทูุน ูููุงุทุน ูุน cache"""
        # ุชุญููู tuple โ list
        units = list(units_tuple)
        
        # ุชูุทูุน
        syllables = Syllabifier().syllabify(units)
        
        # ุชุญููู list โ tuple (ููู cache)
        return tuple(syllables) if syllables else ()
    
    @staticmethod
    @lru_cache(maxsize=5000)
    def cached_pattern_analysis(syllables_tuple: Tuple[Syllable, ...]) -> Optional[PatternKind]:
        """ุชุญููู ูุฒู ูุน cache"""
        syllables = list(syllables_tuple)
        return PatternAnalyzer().analyze(syllables)
    
    @staticmethod
    def batch_process(pipeline: CompletePipeline, 
                     texts: List[str],
                     batch_size: int = 32) -> List[ProcessingResult]:
        """ูุนุงูุฌุฉ ุฏูุนุงุช (batch)"""
        results = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            
            for text in batch:
                result = pipeline.process(text, PriorInfo())
                results.append(result)
        
        return results

ุงููุฎุฑุฌุงุช ูููุฑุญูุฉ 6:
 src/fvafk/pipeline/complete_pipeline.py + 10 ุงุฎุชุจุงุฑ
 tests/test_complete_corpus.py (100 ุขูุฉ + 50 ุญุฏูุซ)
 src/fvafk/optimization/caching.py + 5 ุงุฎุชุจุงุฑุงุช
 docs/PERFORMANCE_REPORT.md (ุชูุฑูุฑ ุงูุฃุฏุงุก)
 docs/ACCURACY_REPORT.md (ุชูุฑูุฑ ุงูุฏูุฉ)
 examples/complete_demo.py (demo ุดุงูู)
ูุนูุงุฑ ุงููุฌุงุญ:
Code
โ ูุนุงูุฌุฉ 1000 ูููุฉ ูู <1 ุซุงููุฉ
โ ูุนุฏู ุงููุจูู โฅ 85% ุนูู corpus
โ ุฏูุฉ ุตุฑููุฉ โฅ 85% (F1-score)
โ ุฏูุฉ ูุญููุฉ โฅ 80% (UAS)
โ ุงุณุชููุงู ุฐุงูุฑุฉ <500MB ูู1000 ุฌููุฉ

<a name="timeline"></a>
๐ ุฌุฏูู ุงูุชูููุฐ ุงููุงูู (16 ุฃุณุจูุน)
Code
Week 1-2:   ุงููุฑุญูุฉ 1 - ุงูุจููุฉ ุงูุชุญุชูุฉ
            โโ Segment inventory (30 ุตุงูุชุงู)
            โโ Syllable system (6 ุฃููุงุน)
            โโ Gate framework

Week 3-5:   ุงููุฑุญูุฉ 2 - ุงูุจูุงุจุงุช ุงูุตูุชูุฉ
            โโ Week 3: 4 ุจูุงุจุงุช ุฃุณุงุณูุฉ
            โโ Week 4: 3 ุจูุงุจุงุช ูุชูุฏูุฉ
            โโ Week 5: 3 ุจูุงุจุงุช ููู/ุญุฐู

Week 6-8:   ุงููุฑุญูุฉ 3 - ุงููุญูู ุงูุตุฑูู
            โโ Word boundary detection
            โโ Pattern analysis
            โโ Word classification
            โโ Root extraction

Week 9-11:  ุงููุฑุญูุฉ 4 - ุงููุญูู ุงููุญูู
            โโ ISNADI links (ุฅุณูุงุฏู)
            โโ TADMINI links (ุชุถูููู)
            โโ TAQYIDI links (ุชูููุฏู)

Week 12-13: ุงููุฑุญูุฉ 5 - ุงููููุฏ ุงููุญููุฉ
            โโ 5 ูููุฏ ููุทุจูุฉ ุจุงููุงูู
            โโ Constraint validator

Week 14-16: ุงููุฑุญูุฉ 6 - ุงูุชูุงูู ูุงูุชุญุณูู
            โโ Complete pipeline
            โโ Corpus testing
            โโ Performance optimization
            โโ Documentation

๐ ููุฎุต ุงููุฎุฑุฌุงุช ุงูููุงุฆูุฉ
YAML
ุงูููุฏ:
  Python: ~15,000 ุฃุณุทุฑ
    - src/fvafk/c1/: 500 ุณุทุฑ
    - src/fvafk/c2a/: 4,000 ุณุทุฑ (10 ุจูุงุจุงุช)
    - src/fvafk/c2b/: 8,000 ุณุทุฑ (ุตุฑู + ูุญู + ูููุฏ)
    - src/fvafk/c2c/: 1,000 ุณุทุฑ
    - src/fvafk/pipeline/: 1,500 ุณุทุฑ
  
  Coq: ~3,000 ุณุทุฑ
    - 50 ูุจุฑููุฉ ุฌุฏูุฏุฉ
    - ุฌููุนูุง ููุซุจุชุฉ (Qed)

ุงูุงุฎุชุจุงุฑุงุช:
  - 300+ ุงุฎุชุจุงุฑ ูุญุฏุฉ
  - 50 ุงุฎุชุจุงุฑ ุชูุงูู
  - 20 ุงุฎุชุจุงุฑ property-based
  - Corpus: 100 ุขูุฉ + 50 ุญุฏูุซ + 50 MSA

ุงูุชูุซูู:
  - 50,000+ ูููุฉ
  - 10 ูููุงุช markdown
  - ุชุบุทูุฉ 100%

ุงูุฃุฏุงุก:
  - ูุนุงูุฌุฉ: 1000 ูููุฉ/ุซุงููุฉ
  - ุฏูุฉ ุตุฑููุฉ: 85%+
  - ุฏูุฉ ูุญููุฉ: 80%+
  - ุงุณุชููุงู ุฐุงูุฑุฉ: <500MB


1. ุฅุถุงูุฉ C2c Layer ููุฑุญูุฉ ูููุตูุฉ
Python
ุงููุฑุญูุฉ 2.5: C2c - Semantic Gates (Week 5.5-6.5)

ุงูุฃูุฏุงู:
  - Evidence model: 5 ูุตุงุฏุฑ (linguistic 30%, logic 30%, world 20%, memory 15%, bias 5%)
  - Falsifiability protocol: ูู Meaning ูุฏูู List[FailureTest]
  - Reality link: ูุตู truth/reference/reality
  - Accept threshold: evidence.score >= 0.5 AND scope_ok AND truth_ok AND reference_ok

ุงูููููุงุช:
  - EvidenceWeight: ุญุณุงุจ ุงูุฃูุฒุงู
  - FalsifiabilityProtocol: ุจุฑูุชูููู ุงูุงุฎุชุจุงุฑ
  - RealityLink: truth_ok, reference_ok, reality_tests
  - SemanticGate: ุงููุฑุงุฑ ุงูููุงุฆู

ูุนุงููุฑ ุงููุฌุงุญ:
  โ 30+ ุงุฎุชุจุงุฑ ููุฑ
  โ ุฏูุฉ ูุฑุงุฑ ุงููุจูู/ุงูุฑูุถ โฅ 90%
  โ ูุนุฏู false positives โค 5%

2. ุฅุถุงูุฉ OrthographyAdapter ูู ุงููุฑุญูุฉ 1
Python
ุงููุฑุญูุฉ 1: ุงูุจููุฉ ุงูุชุญุชูุฉ (ูุญุฏูุซุฉ)

ุฅุถุงูุฉ:
  - OrthographyAdapter: ุชุญููู ููุชูุจโููุทูู
    - ููุฒุฉ ุงููุตู: ูฑ โ ุง ูุน kasra
    - ุชุงุก ูุฑุจูุทุฉ: ุฉ โ ุช/ู ุญุณุจ ุงูุณูุงู
    - ุฃูู ููุตูุฑุฉ: ู โ ู
    - ุชูููู: ูู ูู ูู โ ููู ุณุงููุฉ ูู ุงูููู
    - ููุฌุฏ ุฏุงุฎู `src/fvafk/orthography_adapter.py` ุจุงุนุชุจุงุฑู ูุญุฏุฉ ุนุงูุฉ ุถูู `fvafk`

3. ุฅุถุงูุฉ Amil-Sign Rules ูู ุงููุฑุญูุฉ 5
Python
ุงููุฑุญูุฉ 5: ุงููููุฏ ุงููุญููุฉ (ูุญุฏูุซุฉ)

ุฅุถุงูุฉ ููุฏ ุณุงุฏุณ:
  6. Amil-Sign Rules (AููSignConstraint)
     - ูุง ุฅุนุฑุงุจ ุจุฏูู ุนุงูู (no i3rab without operator)
     - ูุง ุนุงูู ุจุฏูู ุฑุงุจุท (no operator without link)

4. ุฅุถุงูุฉ Event Extraction
Python
ุงููุฑุญูุฉ 4: ุงููุญูู ุงููุญูู (ูุญุฏูุซุฉ)

ุฅุถุงูุฉ ูููู:
  - EventExtractor: ุงุณุชุฎุฑุงุฌ ุงูุฃุญุฏุงุซ ูู ุงูุฃูุนุงู
    - ุชุญุฏูุฏ ููุน ุงูุญุฏุซ (past, present, future)
    - ุชุญุฏูุฏ ุงููุดุงุฑููู (participants)
    - ุชุญุฏูุฏ ุงูุฒูู ูุงูููุงู

### Event Extraction Schema
| Field | Description | Source Signals | Evaluation |
| --- | --- | --- | --- |
| `event_type` | Temporal classification (past/present/future) | Verb pattern (mood/tense), time particles (ุณููุ ูุฏ) | Accuracy vs. annotated 1000+ sentences |
| `participants` | Subject/object roles associated with event | ISNADI/TADMINI links, case markers, pronoun resolution | F1 for participant extraction โฅ 0.80 |
| `time_ref` | Temporal anchoring phrase | Prepositional/time adverbs + orthography adapter output | Precision on annotated clause boundaries |
| `place_ref` | Locative phrase or prepositional object | TAQYIDI links + prepositions | Recall on location mentions โฅ 0.75 |
| `certainty` | Evidence level (Epistemic state) | SemanticGate evidence weights | Matches QA requirements in C2c |

Events feed the constraint validator and SemanticGate decision layers; align the schema with `tests/test_complete_corpus.py` or new event-annotated corpus slices.

5. ุฅุถุงูุฉ CLI ูู ุงููุฑุญูุฉ 6
Python
ุงููุฑุญูุฉ 6: ุงูุชูุงูู (ูุญุฏูุซุฉ)

ุฅุถุงูุฉ:
  - CLI Module: python -m fvafk.cli
    - ูุนุงูุฌุฉ ูู ุณุทุฑ ุงูุฃูุงูุฑ
    - ุฎูุงุฑุงุช: --verbose, --json, --coq-verify
    - ุฅุฎุฑุงุฌ ููุณู

6. ุฅุถุงูุฉ Property-Based Tests
Python
ุงููุฑุญูุฉ 6: ุงูุชูุงูู (ูุญุฏูุซุฉ)

ุฅุถุงูุฉ:
  - Property tests (Hypothesis):
    - Idempotence: process(process(x)) == process(x)
    - Preservation: well-formed(x) โ well-formed(process(x))
    - Reversibility: decode(encode(x)) == x

7. ุฅุถุงูุฉ Documentation Files
Python
ุงููุฑุญูุฉ 6: ุงูุชูุงูู (ูุญุฏูุซุฉ)

ุฅุถุงูุฉ ูููุงุช:
  - docs/SPEC.md: Type system, constraints, formal semantics
  - docs/ARCHITECTURE.md: Layer separation rationale
  - docs/GATES.md: All gates with pre/post conditions
  - docs/FAILABILITY.md: Falsifiability protocol
  - docs/EXAMPLES.md: 7 examples with processing traces
  - docs/EVALUATION_UPDATED_2026.md: Metrics and progress

๐ ุงูุฌุฏูู ุงูุฒููู ุงููุญุฏูุซ
Code
Week 1-2:     ุงููุฑุญูุฉ 1 - ุงูุจููุฉ ุงูุชุญุชูุฉ + OrthographyAdapter
Week 3-5:     ุงููุฑุญูุฉ 2 - ุงูุจูุงุจุงุช ุงูุตูุชูุฉ (10)
Week 5.5-6.5: ุงููุฑุญูุฉ 2.5 - C2c Semantic Gates (ุฌุฏูุฏ)
Week 6.5-8:   ุงููุฑุญูุฉ 3 - ุงููุญูู ุงูุตุฑูู + Affix identification
Week 9-11:    ุงููุฑุญูุฉ 4 - ุงููุญูู ุงููุญูู + Event extraction
Week 12-13:   ุงููุฑุญูุฉ 5 - ุงููููุฏ ุงููุญููุฉ (6 ูููุฏ)
Week 14-17:   ุงููุฑุญูุฉ 6 - ุงูุชูุงูู + CLI + Property tests + Docs

ุงูุฅุฌูุงูู: 17 ุฃุณุจูุนุงู (ุจุฏูุงู ูู 16)




"""
Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ© (Fractal Pattern Engine)
Fractal Pattern Engine for Arabic Text Analysis

This engine analyzes and generates fractal-like recursive patterns in Arabic text,
including morphological recursion, semantic patterns, and structural self-similarity.

In Arabic linguistics, fractal patterns can be found in:
- Root-pattern morphology (Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚)
- Recursive phrase structures
- Semantic field relationships
- Rhythmic and phonetic patterns

Author: Eqratech Arabic Diana Project
Date: 2025-12-15
"""

import pandas as pd
from typing import List, Dict, Tuple, Set
import re
from base_reconstruction_engine import BaseReconstructionEngine
from reconstruction_utils import reconstruct_from_base_df


class FractalPatternEngine(BaseReconstructionEngine):
    """
    Ù…Ø­Ø±Ùƒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ© ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    Analyzes fractal (recursive, self-similar) patterns in Arabic text.
    """
    
    SHEET_NAME = 'Ø§Ù„Ø£Ù†Ù…Ø§Ø·_Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ©'
    
    # Arabic root patterns (Ø£ÙˆØ²Ø§Ù†) that demonstrate fractal-like properties
    FRACTAL_PATTERNS = [
        {
            "pattern": "ÙÙØ¹ÙÙ‘Ù„Ù",
            "structure": "C1aC2C2aC3",
            "type": "ØªÙƒØ±Ø§Ø± ØµÙˆØªÙŠ",
            "example": "ÙƒÙØ³ÙÙ‘Ø±Ù",
            "description": "ØªÙƒØ±Ø§Ø± Ø§Ù„Ø­Ø±Ù Ø§Ù„Ø«Ø§Ù†ÙŠ ÙŠØ®Ù„Ù‚ Ø¨ÙÙ†ÙŠØ© Ù…ØªÙƒØ±Ø±Ø©"
        },
        {
            "pattern": "ØªÙÙÙØ¹ÙÙ‘Ù„Ù",
            "structure": "taC1aC2C2aC3",
            "type": "Ø¨Ù†Ø§Ø¡ Ù…ØªØ¯Ø§Ø®Ù„",
            "example": "ØªÙÙƒÙØ³ÙÙ‘Ø±Ù",
            "description": "Ø¨Ù†Ø§Ø¡ Ù…ØªØ¯Ø§Ø®Ù„ Ù…Ø¹ ØªÙƒØ±Ø§Ø± Ø¯Ø§Ø®Ù„ÙŠ"
        },
        {
            "pattern": "Ø§ÙÙÙ’ØªÙØ¹ÙÙ„Ù",
            "structure": "iC1taC2aC3",
            "type": "Ù†Ù…Ø· Ø§ÙØªØ¹Ø§Ù„",
            "example": "Ø§ÙÙƒÙ’ØªÙØ³ÙØ¨Ù",
            "description": "Ø¥Ø¯Ù…Ø§Ø¬ ØªØ§Ø¡ Ø§Ù„Ø§ÙØªØ¹Ø§Ù„ ÙÙŠ Ø§Ù„Ø¨Ù†ÙŠØ©"
        },
        {
            "pattern": "Ø§ÙØ³Ù’ØªÙÙÙ’Ø¹ÙÙ„Ù",
            "structure": "istaC1C2aC3",
            "type": "Ø§Ø³ØªÙØ¹Ø§Ù„ Ù…Ø±ÙƒØ¨",
            "example": "Ø§ÙØ³Ù’ØªÙØ®Ù’Ø±ÙØ¬Ù",
            "description": "Ø¨Ù†Ø§Ø¡ Ø«Ù„Ø§Ø«ÙŠ Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"
        },
        {
            "pattern": "ÙÙØ¹Ù’Ù„ÙÙ„Ù",
            "structure": "C1aC2C3C4",
            "type": "Ø±Ø¨Ø§Ø¹ÙŠ Ù…Ø¬Ø±Ø¯",
            "example": "Ø¯ÙØ­Ù’Ø±ÙØ¬Ù",
            "description": "Ø£ØµÙ„ Ø±Ø¨Ø§Ø¹ÙŠ Ù…Ø¹ ØªÙ…Ø§Ø«Ù„ ØµÙˆØªÙŠ"
        },
        {
            "pattern": "ØªÙÙÙØ¹Ù’Ù„ÙÙ„Ù",
            "structure": "taC1aC2C3C4",
            "type": "Ø±Ø¨Ø§Ø¹ÙŠ Ù…Ø²ÙŠØ¯",
            "example": "ØªÙØ¯ÙØ­Ù’Ø±ÙØ¬Ù",
            "description": "Ø±Ø¨Ø§Ø¹ÙŠ Ù…Ø¹ Ø²ÙŠØ§Ø¯Ø© ØªØ§Ø¡ Ø§Ù„Ø¨Ù†Ø§Ø¡"
        },
    ]
    
    # Recursive semantic patterns
    SEMANTIC_RECURSION = [
        {
            "root": "Ùƒ Øª Ø¨",
            "derivatives": ["ÙƒÙØ§ØªÙØ¨", "Ù…ÙÙƒÙ’ØªÙÙˆØ¨", "ÙƒÙØªÙØ§Ø¨", "Ù…ÙÙƒÙ’ØªÙØ¨", "ÙƒÙØªÙÙ‘Ø§Ø¨"],
            "recursion_type": "Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…ØªØ³Ù„Ø³Ù„",
            "pattern_depth": 3
        },
        {
            "root": "Ø¹ Ù„ Ù…",
            "derivatives": ["Ø¹ÙØ§Ù„ÙÙ…", "Ù…ÙØ¹Ù’Ù„ÙÙˆÙ…", "Ø¹ÙÙ„Ù’Ù…", "ØªÙØ¹Ù’Ù„ÙÙŠÙ…", "Ù…ÙØ¹ÙÙ„ÙÙ‘Ù…"],
            "recursion_type": "Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…Ø¹Ø±ÙÙŠ",
            "pattern_depth": 3
        },
        {
            "root": "Ù‚ Ùˆ Ù„",
            "derivatives": ["Ù‚ÙØ§Ø¦ÙÙ„", "Ù…ÙÙ‚ÙÙˆÙ„", "Ù‚ÙÙˆÙ’Ù„", "Ù…ÙÙ‚ÙØ§Ù„", "Ù…ÙÙ‚Ù’ÙˆÙÙ„"],
            "recursion_type": "Ø§Ø´ØªÙ‚Ø§Ù‚ ÙƒÙ„Ø§Ù…ÙŠ",
            "pattern_depth": 2
        },
    ]
    
    @classmethod
    def make_df(cls):
        """Generate DataFrame with fractal pattern analysis."""
        rows = []
        
        # Add morphological fractal patterns
        for pattern_data in cls.FRACTAL_PATTERNS:
            pattern_name = pattern_data["pattern"]
            structure = pattern_data["structure"]
            pattern_type = pattern_data["type"]
            example = pattern_data["example"]
            description = pattern_data["description"]
            
            # Calculate recursion depth based on repeated elements
            recursion_depth = cls._calculate_recursion_depth(structure)
            
            rows.append({
                "Ø§Ù„Ø£Ø¯Ø§Ø©": pattern_name,
                "Ø§Ù„Ù‚Ø§Ù„Ø¨/Ø§Ù„ØªØ±ÙƒÙŠØ¨": structure,
                "Ø§Ù„Ù†ÙˆØ¹": "Ù†Ù…Ø· ØµØ±ÙÙŠ ÙƒØ³ÙŠØ±ÙŠ",
                "Ù…Ø«Ø§Ù„": example,
                "Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª": " ".join(list(pattern_name)),
                "Ø§Ù„Ø­Ø±ÙƒØ§Øª": cls._extract_harakat(pattern_name),
                "Ø¹Ù…Ù‚ Ø§Ù„ØªÙƒØ±Ø§Ø±": recursion_depth,
                "Ø§Ù„Ø£Ø«Ø± Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ÙŠ": "Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆÙ‚Ø¹",
                "Ø´Ø±Ø·/Ø³ÙŠØ§Ù‚": pattern_type,
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù†Ø­ÙˆÙŠØ©": "ÙØ¹Ù„ Ø£Ùˆ Ø§Ø³Ù… Ù…Ø´ØªÙ‚",
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©": description,
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµØ±ÙÙŠØ©": f"ÙˆØ²Ù† {pattern_name}",
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØªÙŠØ©": cls._analyze_phonetic_pattern(pattern_name),
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚ÙŠØ©": "Ù†Ù…Ø· Ø§Ø´ØªÙ‚Ø§Ù‚ÙŠ Ù…ØªÙƒØ±Ø±",
                "Ù…Ù„Ø§Ø­Ø¸Ø§Øª": f"Ù†Ù…Ø· ÙƒØ³ÙŠØ±ÙŠ Ù…Ù† Ù†ÙˆØ¹: {pattern_type}"
            })
        
        # Add semantic recursion patterns
        for semantic_data in cls.SEMANTIC_RECURSION:
            root = semantic_data["root"]
            derivatives = semantic_data["derivatives"]
            recursion_type = semantic_data["recursion_type"]
            depth = semantic_data["pattern_depth"]
            
            # Create entries for each derivative showing the recursive relationship
            for idx, derivative in enumerate(derivatives):
                rows.append({
                    "Ø§Ù„Ø£Ø¯Ø§Ø©": derivative,
                    "Ø§Ù„Ù‚Ø§Ù„Ø¨/Ø§Ù„ØªØ±ÙƒÙŠØ¨": f"Ù…Ø´ØªÙ‚ Ù…Ù† Ø¬Ø°Ø±: {root}",
                    "Ø§Ù„Ù†ÙˆØ¹": "Ù†Ù…Ø· Ø¯Ù„Ø§Ù„ÙŠ ÙƒØ³ÙŠØ±ÙŠ",
                    "Ù…Ø«Ø§Ù„": derivative,
                    "Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª": " ".join(list(derivative)),
                    "Ø§Ù„Ø­Ø±ÙƒØ§Øª": cls._extract_harakat(derivative),
                    "Ø¹Ù…Ù‚ Ø§Ù„ØªÙƒØ±Ø§Ø±": depth,
                    "Ø§Ù„Ø£Ø«Ø± Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ÙŠ": "Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆÙ‚Ø¹",
                    "Ø´Ø±Ø·/Ø³ÙŠØ§Ù‚": recursion_type,
                    "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù†Ø­ÙˆÙŠØ©": cls._determine_grammatical_function(derivative),
                    "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©": f"Ù…Ø´ØªÙ‚ {idx + 1} Ù…Ù† Ø§Ù„Ø¬Ø°Ø± {root}",
                    "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµØ±ÙÙŠØ©": cls._determine_morphological_function(derivative),
                    "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØªÙŠØ©": cls._analyze_phonetic_pattern(derivative),
                    "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚ÙŠØ©": f"Ø§Ø´ØªÙ‚Ø§Ù‚ Ù…ØªÙƒØ±Ø± - Ù…Ø³ØªÙˆÙ‰ {idx + 1}",
                    "Ù…Ù„Ø§Ø­Ø¸Ø§Øª": f"Ø¬Ø²Ø¡ Ù…Ù† Ø³Ù„Ø³Ù„Ø© Ø§Ø´ØªÙ‚Ø§Ù‚ÙŠØ© ÙƒØ³ÙŠØ±ÙŠØ©"
                })
        
        # Add compound recursive structures
        compound_structures = cls._generate_compound_recursive_structures()
        rows.extend(compound_structures)
        
        dataframe = pd.DataFrame(rows)
        return reconstruct_from_base_df(dataframe)
    
    @staticmethod
    def _calculate_recursion_depth(structure: str) -> int:
        """
        Calculate the recursion depth of a morphological structure.
        Depth is based on repeated elements and nested patterns.
        """
        # Count repeated consonants (C followed by number)
        consonant_pattern = re.findall(r'C\d', structure)
        unique_consonants = set(consonant_pattern)
        
        # If consonants repeat, increase depth
        depth = 1
        if len(consonant_pattern) > len(unique_consonants):
            depth += (len(consonant_pattern) - len(unique_consonants))
        
        # Check for prefixes (t, i, st, etc.)
        if structure.startswith('ta') or structure.startswith('ista'):
            depth += 1
        
        return depth
    
    @staticmethod
    def _extract_harakat(text: str) -> str:
        """Extract diacritical marks (harakat) from Arabic text."""
        harakat_pattern = re.compile(r'[\u064B-\u0652]')
        harakat = harakat_pattern.findall(text)
        return " ".join(harakat) if harakat else "Ø¨Ø¯ÙˆÙ† ØªØ´ÙƒÙŠÙ„"
    
    @staticmethod
    def _analyze_phonetic_pattern(text: str) -> str:
        """Analyze the phonetic pattern of the text."""
        # Remove diacritics for analysis
        clean_text = re.sub(r'[\u064B-\u0652]', '', text)
        
        length = len(clean_text)
        if length <= 3:
            return "Ù‚ØµÙŠØ±"
        elif length <= 5:
            return "Ù…ØªÙˆØ³Ø·"
        else:
            return "Ø·ÙˆÙŠÙ„"
    
    @staticmethod
    def _determine_grammatical_function(word: str) -> str:
        """Determine the grammatical function based on morphological markers."""
        # Simple heuristic based on common patterns
        if word.startswith("Ù…Ù") or word.startswith("Ù…Ù"):
            return "Ø§Ø³Ù… Ù…ÙØ¹ÙˆÙ„ Ø£Ùˆ Ø§Ø³Ù… Ù…ÙƒØ§Ù†"
        elif word.endswith("ÙÙ…") or word.endswith("ÙØ©"):
            return "Ø§Ø³Ù…"
        elif "Ù€ÙÙ€" in word or "Ù€ÙÙ€" in word:
            return "ÙØ¹Ù„"
        else:
            return "Ø§Ø³Ù… Ø£Ùˆ ÙØ¹Ù„"
    
    @staticmethod
    def _determine_morphological_function(word: str) -> str:
        """Determine morphological function."""
        if any(marker in word for marker in ["ÙƒÙØ§ØªÙØ¨", "Ø¹ÙØ§Ù„ÙÙ…", "Ù‚ÙØ§Ø¦ÙÙ„"]):
            return "Ø§Ø³Ù… ÙØ§Ø¹Ù„"
        elif any(marker in word for marker in ["Ù…ÙÙƒÙ’ØªÙÙˆØ¨", "Ù…ÙØ¹Ù’Ù„ÙÙˆÙ…"]):
            return "Ø§Ø³Ù… Ù…ÙØ¹ÙˆÙ„"
        else:
            return "Ù…Ø´ØªÙ‚"
    
    @staticmethod
    def _generate_compound_recursive_structures() -> List[Dict]:
        """Generate compound structures showing recursive patterns."""
        structures = []
        
        # Nested phrase structures (Ø§Ù„ØªØ±ÙƒÙŠØ¨ Ø§Ù„Ù…ØªØ¯Ø§Ø®Ù„)
        nested_phrases = [
            {
                "phrase": "Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø°ÙŠ ÙÙŠ Ø§Ù„Ø¨ÙŠØª Ø§Ù„Ø°ÙŠ ÙÙŠ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©",
                "recursion_type": "ØªØ±ÙƒÙŠØ¨ Ù…ØªØ¯Ø§Ø®Ù„",
                "nesting_level": 3,
                "description": "Ø¬Ù…Ù„Ø© Ù…ÙˆØµÙˆÙ„ÙŠØ© Ù…ØªØ¯Ø§Ø®Ù„Ø©"
            },
            {
                "phrase": "Ù‚Ø§Ù„ Ø£Ù†Ù‡ Ù‚Ø§Ù„ Ø£Ù†Ù‡ Ø³ÙŠØ£ØªÙŠ",
                "recursion_type": "ØªØ¶Ù…ÙŠÙ† Ù…ØªÙƒØ±Ø±",
                "nesting_level": 2,
                "description": "Ø£ÙØ¹Ø§Ù„ Ù‚ÙˆÙ„ÙŠØ© Ù…ØªØ¯Ø§Ø®Ù„Ø©"
            },
        ]
        
        for phrase_data in nested_phrases:
            phrase = phrase_data["phrase"]
            recursion_type = phrase_data["recursion_type"]
            level = phrase_data["nesting_level"]
            description = phrase_data["description"]
            
            structures.append({
                "Ø§Ù„Ø£Ø¯Ø§Ø©": phrase[:20] + "..." if len(phrase) > 20 else phrase,
                "Ø§Ù„Ù‚Ø§Ù„Ø¨/Ø§Ù„ØªØ±ÙƒÙŠØ¨": "ØªØ±ÙƒÙŠØ¨ Ø¬Ù…Ù„ÙŠ Ù…ØªØ¯Ø§Ø®Ù„",
                "Ø§Ù„Ù†ÙˆØ¹": "Ù†Ù…Ø· Ù†Ø­ÙˆÙŠ ÙƒØ³ÙŠØ±ÙŠ",
                "Ù…Ø«Ø§Ù„": phrase,
                "Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª": " ".join(phrase.split()[:3]),  # First 3 words
                "Ø§Ù„Ø­Ø±ÙƒØ§Øª": "Ù…ØªÙ†ÙˆØ¹",
                "Ø¹Ù…Ù‚ Ø§Ù„ØªÙƒØ±Ø§Ø±": level,
                "Ø§Ù„Ø£Ø«Ø± Ø§Ù„Ø¥Ø¹Ø±Ø§Ø¨ÙŠ": "Ø¬Ù…Ù„Ø© ÙƒØ§Ù…Ù„Ø©",
                "Ø´Ø±Ø·/Ø³ÙŠØ§Ù‚": recursion_type,
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù†Ø­ÙˆÙŠØ©": "Ø¬Ù…Ù„Ø© Ù…ØªØ¯Ø§Ø®Ù„Ø©",
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©": description,
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµØ±ÙÙŠØ©": "ØªØ±ÙƒÙŠØ¨ Ø¬Ù…Ù„ÙŠ",
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØªÙŠØ©": "Ø·ÙˆÙŠÙ„ ÙˆÙ…Ø±ÙƒØ¨",
                "Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚ÙŠØ©": "Ø¨Ù†ÙŠØ© Ù†Ø­ÙˆÙŠØ© Ù…ØªÙƒØ±Ø±Ø©",
                "Ù…Ù„Ø§Ø­Ø¸Ø§Øª": f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¯Ø§Ø®Ù„: {level}"
            })
        
        return structures


class FractalAnalyzer:
    """
    Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ© - Ø£Ø¯Ø§Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©
    Utility class for analyzing fractal patterns in custom text.
    """
    
    def __init__(self):
        """Initialize the fractal analyzer."""
        self.engine = FractalPatternEngine()
    
    def analyze_root_derivatives(self, root: str) -> pd.DataFrame:
        """
        Analyze all derivatives of a given Arabic root.
        
        Args:
            root: Arabic root (e.g., "Ùƒ Øª Ø¨")
            
        Returns:
            DataFrame with derivative analysis
        """
        # This is a simplified version - in production would use full morphological database
        results = []
        root_clean = root.replace(" ", "")
        
        # Common derivative patterns
        patterns = [
            ("ÙØ§Ø¹Ù„", f"{root_clean[0]}Ø§{root_clean[1]}Ù{root_clean[2]}"),
            ("Ù…ÙØ¹ÙˆÙ„", f"Ù…{root_clean[0]}{root_clean[1]}Ùˆ{root_clean[2]}"),
            ("ÙØ¹Ù„", f"{root_clean}"),
        ]
        
        for pattern_name, _ in patterns:
            results.append({
                "Ø§Ù„Ø¬Ø°Ø±": root,
                "Ø§Ù„ÙˆØ²Ù†": pattern_name,
                "Ø§Ù„Ù†ÙˆØ¹": "Ù…Ø´ØªÙ‚",
                "Ø¹Ù…Ù‚_Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚": 1
            })
        
        return pd.DataFrame(results)
    
    def find_recursive_patterns(self, text: str) -> Dict:
        """
        Find recursive/repeating patterns in Arabic text.
        
        Args:
            text: Arabic text to analyze
            
        Returns:
            Dictionary with pattern analysis
        """
        words = text.split()
        
        # Find repeated words
        word_counts = {}
        for word in words:
            word_counts[word] = word_counts.get(word, 0) + 1
        
        repeated_words = {w: c for w, c in word_counts.items() if c > 1}
        
        # Find repeated roots (simplified - just look for word patterns)
        patterns = {}
        for word in words:
            if len(word) >= 3:
                # Simple pattern: first 3 letters
                pattern = word[:3]
                patterns[pattern] = patterns.get(pattern, 0) + 1
        
        return {
            "repeated_words": repeated_words,
            "pattern_frequency": patterns,
            "recursion_detected": len(repeated_words) > 0 or any(c > 1 for c in patterns.values())
        }
    
    def generate_fractal_report(self, text: str) -> pd.DataFrame:
        """
        Generate a comprehensive fractal pattern report for given text.
        
        Args:
            text: Arabic text to analyze
            
        Returns:
            DataFrame with comprehensive analysis
        """
        analysis = self.find_recursive_patterns(text)
        
        results = []
        for word, count in analysis['repeated_words'].items():
            results.append({
                "Ø§Ù„Ø¹Ù†ØµØ±": word,
                "Ù†ÙˆØ¹_Ø§Ù„Ù†Ù…Ø·": "ØªÙƒØ±Ø§Ø± ÙƒÙ„Ù…Ø©",
                "Ø¹Ø¯Ø¯_Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª": count,
                "Ù…Ø³ØªÙˆÙ‰_Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ©": "Ø¹Ø§Ù„ÙŠ" if count > 2 else "Ù…ØªÙˆØ³Ø·"
            })
        
        return pd.DataFrame(results) if results else pd.DataFrame({
            "Ø§Ù„Ø¹Ù†ØµØ±": ["Ù„Ø§ ÙŠÙˆØ¬Ø¯"],
            "Ù†ÙˆØ¹_Ø§Ù„Ù†Ù…Ø·": ["---"],
            "Ø¹Ø¯Ø¯_Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª": [0],
            "Ù…Ø³ØªÙˆÙ‰_Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ©": ["Ù…Ù†Ø®ÙØ¶"]
        })


def main():
    """Main function to demonstrate fractal pattern engine."""
    print("=" * 70)
    print("Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ© ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("Arabic Fractal Pattern Engine")
    print("=" * 70)
    
    # Generate the main dataframe
    engine = FractalPatternEngine()
    dataframe = engine.make_df()
    
    print("\nğŸ“Š Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ© Ø§Ù„Ù…Ø­Ù„Ù„Ø©:")
    print("-" * 70)
    print(dataframe[['Ø§Ù„Ø£Ø¯Ø§Ø©', 'Ø§Ù„Ù†ÙˆØ¹', 'Ø¹Ù…Ù‚ Ø§Ù„ØªÙƒØ±Ø§Ø±', 'Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©']].head(10).to_string())
    
    print(f"\nâœ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {len(dataframe)}")
    print(f"âœ“ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {dataframe['Ø§Ù„Ù†ÙˆØ¹'].nunique()}")
    
    # Demonstrate the analyzer
    print("\n" + "=" * 70)
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ù…Ø®ØµØµ:")
    print("-" * 70)
    
    analyzer = FractalAnalyzer()
    sample_text = "Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„ÙƒØ¨ÙŠØ± ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒØªØ¨ ÙƒØ«ÙŠØ±Ø©"
    
    patterns = analyzer.find_recursive_patterns(sample_text)
    print(f"\nØ§Ù„Ù†Øµ: {sample_text}")
    print(f"\nØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©: {patterns['repeated_words']}")
    print(f"Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {len(patterns['pattern_frequency'])}")
    print(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù ØªÙƒØ±Ø§Ø± ÙƒØ³ÙŠØ±ÙŠ: {'Ù†Ø¹Ù…' if patterns['recursion_detected'] else 'Ù„Ø§'}")
    
    # Generate report
    report_df = analyzer.generate_fractal_report(sample_text)
    print("\nğŸ“ˆ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙƒØ±Ø§Ø±:")
    print(report_df.to_string())
    
    # Save to Excel
    try:
        dataframe.to_excel("fractal_patterns_analysis.xlsx", index=False, sheet_name='Ø§Ù„Ø£Ù†Ù…Ø§Ø·_Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ©')
        print(f"\nâœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ: fractal_patterns_analysis.xlsx")
    except Exception as error:
        print(f"\nâš  ØªØ¹Ø°Ø± Ø§Ù„Ø­ÙØ¸: {str(error)}")
    
    print("\n" + "=" * 70)
    print("âœ“ Ø§ÙƒØªÙ…Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙƒØ³ÙŠØ±ÙŠØ©")
    print("=" * 70)


if __name__ == "__main__":
    main()

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salemqundil/Eqratech_Arabic_Diana_Project/blob/main/Eqratech_Arabic_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eqratech Arabic Diana Project - Google Colab Integration\n",
        "\n",
        "## Ù…Ø´Ø±ÙˆØ¹ Ø¥Ù‚Ø±Ø£ØªÙƒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ø¯ÙŠØ§Ù†Ø§\n",
        "\n",
        "This notebook provides a complete environment for working with the Eqratech Arabic Diana Project in Google Colab.\n",
        "\n",
        "Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± ÙŠÙˆÙØ± Ø¨ÙŠØ¦Ø© ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø¹Ù…Ù„ Ù…Ø¹ Ù…Ø´Ø±ÙˆØ¹ Ø¥Ù‚Ø±Ø£ØªÙƒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯ÙŠØ§Ù†Ø§ ÙÙŠ Google Colab."
      ],
      "metadata": {
        "id": "title_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone the Repository\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹"
      ],
      "metadata": {
        "id": "clone_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/salemqundil/Eqratech_Arabic_Diana_Project.git\n",
        "\n",
        "# Change to the project directory\n",
        "%cd Eqratech_Arabic_Diana_Project\n",
        "\n",
        "# List files to confirm\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Install Dependencies\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª"
      ],
      "metadata": {
        "id": "install_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "print(\"âœ… Dependencies installed successfully!\")\n",
        "print(\"âœ… ØªÙ… ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!\")"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Import and Test Basic Engines\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙˆØ§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"
      ],
      "metadata": {
        "id": "test_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Set UTF-8 encoding for Arabic text\n",
        "import os\n",
        "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
        "\n",
        "print(\"âœ… Environment configured for Arabic text processing\")\n",
        "print(\"âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\")"
      ],
      "metadata": {
        "id": "config_env"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Example - Generate Grammar Data\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 4: Ù…Ø«Ø§Ù„ - ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"
      ],
      "metadata": {
        "id": "example_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Generate phonemes data\n",
        "# Ù…Ø«Ø§Ù„: ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª\n",
        "\n",
        "try:\n",
        "    from phonemes_engine import PhonemesEngine\n",
        "    \n",
        "    # Generate phonemes DataFrame\n",
        "    df_phonemes = PhonemesEngine.make_df()\n",
        "    \n",
        "    print(\"\\nğŸ“Š Phonemes Data / Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª:\")\n",
        "    print(f\"Total phonemes: {len(df_phonemes)}\")\n",
        "    print(f\"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª: {len(df_phonemes)}\")\n",
        "    print(\"\\nFirst 5 rows / Ø£ÙˆÙ„ 5 ØµÙÙˆÙ:\")\n",
        "    display(df_phonemes.head())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not load phonemes engine: {e}\")\n",
        "    print(\"This is expected if the engine structure has changed.\")"
      ],
      "metadata": {
        "id": "example_phonemes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Example - Generate Verbs Data\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 5: Ù…Ø«Ø§Ù„ - ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙØ¹Ø§Ù„"
      ],
      "metadata": {
        "id": "verbs_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Generate verbs data\n",
        "# Ù…Ø«Ø§Ù„: ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙØ¹Ø§Ù„\n",
        "\n",
        "try:\n",
        "    from verbs_engine import VerbsEngine\n",
        "    \n",
        "    # Generate verbs DataFrame\n",
        "    df_verbs = VerbsEngine.make_df()\n",
        "    \n",
        "    print(\"\\nğŸ“Š Verbs Data / Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙØ¹Ø§Ù„:\")\n",
        "    print(f\"Total verbs: {len(df_verbs)}\")\n",
        "    print(f\"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£ÙØ¹Ø§Ù„: {len(df_verbs)}\")\n",
        "    print(\"\\nFirst 5 rows / Ø£ÙˆÙ„ 5 ØµÙÙˆÙ:\")\n",
        "    display(df_verbs.head())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not load verbs engine: {e}\")\n",
        "    print(\"This is expected if the engine structure has changed.\")"
      ],
      "metadata": {
        "id": "example_verbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Export Full Grammar (Optional)\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 6: ØªØµØ¯ÙŠØ± Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
        "\n",
        "**Note:** This may take several minutes to complete.\n",
        "\n",
        "**Ù…Ù„Ø§Ø­Ø¸Ø©:** Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¹Ø¯Ø© Ø¯Ù‚Ø§Ø¦Ù‚ Ù„Ù„Ø¥ÙƒÙ…Ø§Ù„."
      ],
      "metadata": {
        "id": "export_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export full multilayer grammar to Excel\n",
        "# ØªØµØ¯ÙŠØ± Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø¥Ù„Ù‰ Excel\n",
        "\n",
        "try:\n",
        "    print(\"ğŸ”„ Starting export process...\")\n",
        "    print(\"ğŸ”„ Ø¬Ø§Ø±Ù Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØµØ¯ÙŠØ±...\")\n",
        "    \n",
        "    # Import the export script\n",
        "    from export_full_multilayer_grammar_minimal import main as export_main\n",
        "    \n",
        "    # Run the export\n",
        "    export_main()\n",
        "    \n",
        "    print(\"\\nâœ… Export completed successfully!\")\n",
        "    print(\"âœ… ØªÙ… Ø§Ù„ØªØµØ¯ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­!\")\n",
        "    print(\"\\nğŸ“ Output file: full_multilayer_grammar.xlsx\")\n",
        "    \n",
        "    # Download the file\n",
        "    from google.colab import files\n",
        "    files.download('full_multilayer_grammar.xlsx')\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Export failed: {e}\")\n",
        "    print(f\"âš ï¸ ÙØ´Ù„ Ø§Ù„ØªØµØ¯ÙŠØ±: {e}\")"
      ],
      "metadata": {
        "id": "export_grammar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Simple Sentence Generation Example\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 7: Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©"
      ],
      "metadata": {
        "id": "sentences_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Simple sentence generation\n",
        "# Ù…Ø«Ø§Ù„: ØªÙˆÙ„ÙŠØ¯ Ø¬Ù…Ù„ Ø¨Ø³ÙŠØ·Ø©\n",
        "\n",
        "try:\n",
        "    from simple_sentence_generator import SimpleSentenceGenerator\n",
        "    \n",
        "    # Create generator instance\n",
        "    generator = SimpleSentenceGenerator()\n",
        "    \n",
        "    print(\"âœ… Sentence generator initialized\")\n",
        "    print(\"âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø¬Ù…Ù„\")\n",
        "    \n",
        "    # Load basic engines\n",
        "    generator.load_basic_engines()\n",
        "    \n",
        "    print(\"\\nâœ… Basic engines loaded\")\n",
        "    print(\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Could not initialize sentence generator: {e}\")\n",
        "    print(f\"âš ï¸ Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† ØªÙ‡ÙŠØ¦Ø© Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø¬Ù…Ù„: {e}\")"
      ],
      "metadata": {
        "id": "example_sentences"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Explore Available Engines\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 8: Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"
      ],
      "metadata": {
        "id": "explore_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all available engine files\n",
        "# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©\n",
        "\n",
        "import glob\n",
        "\n",
        "engine_files = glob.glob('*_engine.py')\n",
        "engine_files.sort()\n",
        "\n",
        "print(\"ğŸ“‹ Available Engines / Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\\n\")\n",
        "for i, engine in enumerate(engine_files, 1):\n",
        "    print(f\"{i:2d}. {engine}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Total engines: {len(engine_files)}\")\n",
        "print(f\"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª: {len(engine_files)}\")"
      ],
      "metadata": {
        "id": "explore_engines"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 9: Working with CSV Data Files\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 9: Ø§Ù„Ø¹Ù…Ù„ Ù…Ø¹ Ù…Ù„ÙØ§Øª Ø¨ÙŠØ§Ù†Ø§Øª CSV"
      ],
      "metadata": {
        "id": "csv_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all CSV files in the project\n",
        "# Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª CSV ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\n",
        "\n",
        "csv_files = glob.glob('*.csv')\n",
        "csv_files.sort()\n",
        "\n",
        "print(\"ğŸ“‹ CSV Data Files / Ù…Ù„ÙØ§Øª Ø¨ÙŠØ§Ù†Ø§Øª CSV:\\n\")\n",
        "for i, csv_file in enumerate(csv_files, 1):\n",
        "    print(f\"{i:2d}. {csv_file}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Total CSV files: {len(csv_files)}\")\n",
        "print(f\"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª CSV: {len(csv_files)}\")"
      ],
      "metadata": {
        "id": "list_csv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 10: View Sample CSV Data\n",
        "## Ø§Ù„Ø®Ø·ÙˆØ© 10: Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª CSV"
      ],
      "metadata": {
        "id": "view_csv_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View a sample CSV file (adjust filename as needed)\n",
        "# Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ù…Ù„Ù CSV (Ù‚Ù… Ø¨ØªØ¹Ø¯ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©)\n",
        "\n",
        "try:\n",
        "    # Try to load Harakat.csv as an example\n",
        "    df_sample = pd.read_csv('Harakat.csv')\n",
        "    \n",
        "    print(\"ğŸ“Š Sample CSV Data - Harakat.csv:\")\n",
        "    print(f\"Shape: {df_sample.shape}\")\n",
        "    print(f\"Ø§Ù„Ø´ÙƒÙ„: {df_sample.shape}\")\n",
        "    print(\"\\nColumns / Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©:\")\n",
        "    print(df_sample.columns.tolist())\n",
        "    print(\"\\nFirst 5 rows / Ø£ÙˆÙ„ 5 ØµÙÙˆÙ:\")\n",
        "    display(df_sample.head())\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"âš ï¸ Harakat.csv not found. Try another CSV file from the list above.\")\n",
        "    print(\"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Harakat.csv. Ø¬Ø±Ø¨ Ù…Ù„Ù CSV Ø¢Ø®Ø± Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Error loading CSV: {e}\")"
      ],
      "metadata": {
        "id": "view_sample_csv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Resources\n",
        "## Ù…ØµØ§Ø¯Ø± Ø¥Ø¶Ø§ÙÙŠØ©\n",
        "\n",
        "- GitHub Repository: https://github.com/salemqundil/Eqratech_Arabic_Diana_Project\n",
        "- Ù…Ø³ØªÙˆØ¯Ø¹ GitHub: https://github.com/salemqundil/Eqratech_Arabic_Diana_Project\n",
        "\n",
        "For more information about the project structure and available engines, check the repository README."
      ],
      "metadata": {
        "id": "resources"
      }
    }
  ]
}

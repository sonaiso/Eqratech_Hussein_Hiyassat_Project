# Ø®Ø·Ø© Ø¯Ù…Ø¬ Phonology V2 ÙÙŠ FVAFK Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ù†Ø³Ø® ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ…

### 1.1 Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©

```bash
# Ù…Ù† Terminal Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ
cd /Users/husseinhiyassat/fractal/Eqratech_Hussein_Hiyassat_Project

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ phonology_v2 ÙÙŠ FVAFK
mkdir -p src/fvafk/phonology_v2

# Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
cp src/fvafk/phonology/phonology_types.py src/fvafk/phonology_v2/
cp src/fvafk/phonology/phonology_vc_classify.py src/fvafk/phonology_v2/
cp src/fvafk/phonology/phonology_lattice.py src/fvafk/phonology_v2/
cp src/fvafk/phonology/phonology_utils.py src/fvafk/phonology_v2/
cp src/fvafk/phonology/phonology_init.py src/fvafk/phonology_v2/

# Ù†Ø³Ø® Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
cp src/fvafk/phonology/awzan_merged_final_clean.csv src/fvafk/phonology_v2/
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ÙÙ‡Ù… Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©

### 2.1 Ø§ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©

```bash
# Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù‚Ø¯ÙŠÙ…
grep -r "def.*classify" src/fvafk/ --include="*.py"

# Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù…Ø§Øª CV
grep -r "CV.*pattern\|cv_pattern" src/fvafk/ --include="*.py"

# Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¨ÙˆØ§Ø¨Ø§Øª
find src/fvafk -name "*gate*.py"
```

### 2.2 Ø­Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ ØªØ¹Ø¯ÙŠÙ„

Ø§ØµÙ†Ø¹ Ù‚Ø§Ø¦Ù…Ø©:
```
â–¡ src/fvafk/codec/form_codec_v2.py     - Ø§Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
â–¡ src/fvafk/gates/*.py                 - Ø§Ù„Ø¨ÙˆØ§Ø¨Ø§Øª
â–¡ src/fvafk/cli/main.py                - CLI Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
â–¡ ...
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø¥Ù†Ø´Ø§Ø¡ Adapter Layer

### 3.1 Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù phonology_adapter.py

```python
"""
FVAFK Phonology V2 Adapter
===========================

Ø±Ø¨Ø· Ø¨ÙŠÙ† Phonology V2 ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…

Author: Hussein Hiyassat
Date: 2025-02-10
"""

from typing import List, Optional, Dict, Any
from phonology_v2.phonology_lattice import build_syllable_lattice_v2, find_best_syllabification
from phonology_v2.phonology_utils import text_to_graphemes, syllables_to_cv_pattern, format_syllabification
from phonology_v2.phonology_types import CVRole, VCWitness


class PhonologyV2Adapter:
    """
    Ù…Ø­ÙˆÙ„ Ø¨ÙŠÙ† Phonology V2 ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…
    
    ÙŠÙˆÙØ± Ù†ÙØ³ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ…
    Ù„ÙƒÙ† ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¯Ø§Ø®Ù„
    """
    
    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­ÙˆÙ„"""
        self.version = "2.0"
    
    def analyze_word(self, word: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©
        
        Args:
            word: Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…ÙØ´ÙƒÙ‘Ù„Ø©
            
        Returns:
            Ù‚Ø§Ù…ÙˆØ³ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
            - cv_pattern: Ù†Ù…Ø· CV (Ù…Ø«Ù„: CVCVVC)
            - syllables: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
            - syllabification: Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø·Ø¹ÙŠ (Ù…Ø«Ù„: ÙƒÙ.ØªÙØ§Ø¨)
            - success: Ù‡Ù„ Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            - witnesses: Ø´Ù‡ÙˆØ¯ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        """
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ graphemes
            graphemes = text_to_graphemes(word)
            
            if not graphemes:
                return {
                    'word': word,
                    'cv_pattern': '',
                    'syllables': [],
                    'syllabification': '',
                    'success': False,
                    'error': 'ÙƒÙ„Ù…Ø© ÙØ§Ø±ØºØ©'
                }
            
            # Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹
            lattice = build_syllable_lattice_v2(graphemes)
            
            # Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ ØªÙ‚Ø·ÙŠØ¹
            best_path = find_best_syllabification(lattice)
            
            if not best_path:
                return {
                    'word': word,
                    'cv_pattern': '',
                    'syllables': [],
                    'syllabification': '',
                    'success': False,
                    'error': 'Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥ÙŠØ¬Ø§Ø¯ ØªÙ‚Ø·ÙŠØ¹ ØµØ­ÙŠØ­'
                }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            cv = syllables_to_cv_pattern(best_path)
            syll = format_syllabification(best_path)
            syllables = [s.surface for s in best_path]
            
            # Ø¬Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø´Ù‡ÙˆØ¯
            witnesses = []
            for syll_obj in best_path:
                for trace in syll_obj.vc_traces:
                    witnesses.append({
                        'grapheme': trace.base,
                        'role': trace.decided_role.name,
                        'witness': trace.witness.name,
                        'need_nucleus': trace.need_nucleus,
                        'force_onset_c': trace.force_onset_c
                    })
            
            return {
                'word': word,
                'cv_pattern': cv,
                'syllables': syllables,
                'syllabification': syll,
                'syllable_count': len(best_path),
                'success': True,
                'witnesses': witnesses,
                'version': self.version
            }
        
        except Exception as e:
            return {
                'word': word,
                'cv_pattern': '',
                'syllables': [],
                'syllabification': '',
                'success': False,
                'error': str(e)
            }
    
    def get_cv_pattern(self, word: str) -> Optional[str]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ù…Ø· CV ÙÙ‚Ø· (Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ API Ø§Ù„Ù‚Ø¯ÙŠÙ…)
        
        Args:
            word: Ø§Ù„ÙƒÙ„Ù…Ø©
            
        Returns:
            Ù†Ù…Ø· CV Ø£Ùˆ None
        """
        result = self.analyze_word(word)
        return result['cv_pattern'] if result['success'] else None
    
    def get_syllables(self, word: str) -> Optional[List[str]]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ ÙÙ‚Ø· (Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ API Ø§Ù„Ù‚Ø¯ÙŠÙ…)
        
        Args:
            word: Ø§Ù„ÙƒÙ„Ù…Ø©
            
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø£Ùˆ None
        """
        result = self.analyze_word(word)
        return result['syllables'] if result['success'] else None


# Ù†Ø³Ø®Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹
_phonology = PhonologyV2Adapter()

def analyze_word(word: str) -> Dict[str, Any]:
    """ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ù„ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø©"""
    return _phonology.analyze_word(word)

def get_cv_pattern(word: str) -> Optional[str]:
    """ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ CV"""
    return _phonology.get_cv_pattern(word)

def get_syllables(word: str) -> Optional[List[str]]:
    """ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹"""
    return _phonology.get_syllables(word)
```

Ø§Ø­ÙØ¸ Ù‡Ø°Ø§ ÙÙŠ:
```
src/fvafk/phonology_v2/phonology_adapter.py
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£ÙˆÙ„ÙŠ

### 4.1 Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­ÙˆÙ„

```python
# Ù…Ù„Ù: test_adapter.py
from phonology_v2.phonology_adapter import PhonologyV2Adapter

adapter = PhonologyV2Adapter()

# Ø§Ø®ØªØ¨Ø§Ø± 1: ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ·
result = adapter.analyze_word("ÙƒÙØªÙØ§Ø¨")
print(f"ÙƒÙØªÙØ§Ø¨ â†’ {result['cv_pattern']}")
assert result['cv_pattern'] == 'CVCVVC', "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„!"

# Ø§Ø®ØªØ¨Ø§Ø± 2: Ù…Ù‚Ø§Ø·Ø¹
syllables = adapter.get_syllables("Ù…ÙØ¯Ù’Ø±ÙØ³ÙØ©")
print(f"Ù…ÙØ¯Ù’Ø±ÙØ³ÙØ© â†’ {syllables}")
assert syllables == ['Ù…ÙØ¯', 'Ø±Ù', 'Ø³ÙØ©'], "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹!"

# Ø§Ø®ØªØ¨Ø§Ø± 3: ÙƒÙ„Ù…Ø© Ù…Ø¹Ù‚Ø¯Ø©
result = adapter.analyze_word("ÙŠÙØ³Ù’ØªÙÙÙ’Ø¹ÙÙ„Ù")
print(f"ÙŠÙØ³Ù’ØªÙÙÙ’Ø¹ÙÙ„Ù â†’ {result['cv_pattern']}")

print("\nâœ… ÙƒÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª!")
```

Ø´ØºÙ‘Ù„Ù‡:
```bash
python3 test_adapter.py
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ FormCodecV2

### 5.1 ØªØ­Ø¯ÙŠØ« form_codec_v2.py

```python
# ÙÙŠ src/fvafk/codec/form_codec_v2.py

# Ø£Ø¶Ù ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©:
from phonology_v2.phonology_adapter import PhonologyV2Adapter

class FormCodecV2:
    def __init__(self):
        # ... Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        self.phonology = PhonologyV2Adapter()
    
    def encode(self, text: str):
        # ... Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
        
        # Ø¨Ø¯Ù„ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù‚Ø¯ÙŠÙ…:
        # OLD: cv_pattern = self.old_classify(word)
        
        # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯:
        phono_result = self.phonology.analyze_word(word)
        cv_pattern = phono_result['cv_pattern']
        syllables = phono_result['syllables']
        
        # ... Ø¨Ù‚ÙŠØ© Ø§Ù„ÙƒÙˆØ¯
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙˆØ§Ø¨Ø§Øª

### 6.1 ØªØ­Ø¯ÙŠØ« gate_base.py (Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯)

```python
# ÙÙŠ src/fvafk/gates/gate_base.py

from phonology_v2.phonology_adapter import get_cv_pattern

class GateBase:
    def apply(self, segment):
        # ... Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
        
        # Ø¨Ø¯Ù„:
        # cv = self.old_cv_method(segment)
        
        # Ø§Ø³ØªØ®Ø¯Ù…:
        cv = get_cv_pattern(segment.text)
        
        # ... Ø¨Ù‚ÙŠØ© Ø§Ù„ÙƒÙˆØ¯
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: ØªØ­Ø¯ÙŠØ« CLI

### 7.1 ØªØ­Ø¯ÙŠØ« main.py

```python
# ÙÙŠ src/fvafk/cli/main.py

from phonology_v2.phonology_adapter import PhonologyV2Adapter

def main():
    # Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Phonology V2
    parser.add_argument('--phonology-v2', action='store_true',
                       help='Use Phonology V2 (100% accuracy)')
    
    # ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆØ§Ù…Ø±:
    if args.phonology_v2:
        phonology = PhonologyV2Adapter()
        result = phonology.analyze_word(word)
        print(f"CV: {result['cv_pattern']}")
        print(f"Syllables: {result['syllabification']}")
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 8: Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„

### 8.1 Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙƒØ§Ù…Ù„

```bash
# Ø§Ø®ØªØ¨Ø§Ø± 1: CLI
python3 -m fvafk.cli.main --phonology-v2 "ÙƒÙØªÙØ§Ø¨"

# Ø§Ø®ØªØ¨Ø§Ø± 2: Ø§Ù„Ø¨ÙˆØ§Ø¨Ø§Øª
python3 test_gates_with_v2.py

# Ø§Ø®ØªØ¨Ø§Ø± 3: Codec
python3 test_codec_with_v2.py
```

### 8.2 Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬

```python
# Ù…Ù„Ù: compare_old_vs_new.py

from old_phonology import analyze as old_analyze
from phonology_v2.phonology_adapter import analyze_word as new_analyze

test_words = ["ÙƒÙØªÙØ§Ø¨", "Ù…ÙØ¯Ù’Ø±ÙØ³ÙØ©", "Ù…ÙØ¹ÙÙ„ÙÙ‘Ù…"]

for word in test_words:
    old_result = old_analyze(word)
    new_result = new_analyze(word)
    
    print(f"{word}:")
    print(f"  Old: {old_result['cv']}")
    print(f"  New: {new_result['cv_pattern']}")
    print()
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 9: Ø§Ù„ØªÙˆØ«ÙŠÙ‚

### 9.1 Ø¥Ù†Ø´Ø§Ø¡ MIGRATION_GUIDE.md

```markdown
# Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Phonology V2

## Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

### API Ø§Ù„Ù‚Ø¯ÙŠÙ…:
```python
from fvafk.phonology import classify_word
result = classify_word("ÙƒÙØªÙØ§Ø¨")
cv = result.cv_pattern
```

### API Ø§Ù„Ø¬Ø¯ÙŠØ¯:
```python
from fvafk.phonology_v2.phonology_adapter import analyze_word
result = analyze_word("ÙƒÙØªÙØ§Ø¨")
cv = result['cv_pattern']
```

## Ø§Ù„ÙÙˆØ§Ø¦Ø¯
- âœ… Ø¯Ù‚Ø© 100% (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 88%)
- âœ… Ù†Ø¸Ø§Ù… Ø´Ù‡ÙˆØ¯ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø¥Ø«Ø¨Ø§Øª
- âœ… Assumption A Ù…Ø·Ø¨Ù‚
```

---

## ğŸ“‹ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 10: Ø§Ù„Ù†Ø´Ø±

### 10.1 ØªØ­Ø¯ÙŠØ« requirements.txt (Ø¥Ø°Ø§ Ù„Ø²Ù…)

```txt
# Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ¨Ø¹ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©!
# Phonology V2 ÙŠØ³ØªØ®Ø¯Ù… Python Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ ÙÙ‚Ø·
```

### 10.2 Git Commit

```bash
git add src/fvafk/phonology_v2/
git commit -m "feat: Integrate Phonology V2 with 100% accuracy

- Add Phonology V2 module with context-driven classification
- Implement Assumption A (Ùˆ/ÙŠ/Ø§ default to consonants)
- Add witness system for formal verification
- Create adapter layer for backward compatibility
- Update FormCodecV2, gates, and CLI
- Achieve 100% accuracy on 81 test patterns

Closes #XXX"
```

---

## âœ… Checklist Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ

Ù‚Ø¨Ù„ Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ø¯Ù…Ø¬ ÙƒØ§Ù…Ù„Ø§Ù‹:

### Ø§Ù„ÙƒÙˆØ¯:
- [ ] Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„Ù‰ phonology_v2/
- [ ] Ø¥Ù†Ø´Ø§Ø¡ phonology_adapter.py
- [ ] ØªØ­Ø¯ÙŠØ« FormCodecV2
- [ ] ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙˆØ§Ø¨Ø§Øª
- [ ] ØªØ­Ø¯ÙŠØ« CLI

### Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:
- [ ] test_adapter.py ÙŠØ¹Ù…Ù„
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ FormCodecV2
- [ ] Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨ÙˆØ§Ø¨Ø§Øª
- [ ] Ø§Ø®ØªØ¨Ø§Ø± CLI
- [ ] Ù…Ù‚Ø§Ø±Ù†Ø© Old vs New

### Ø§Ù„ØªÙˆØ«ÙŠÙ‚:
- [ ] MIGRATION_GUIDE.md
- [ ] ØªØ­Ø¯ÙŠØ« README.md
- [ ] Ø¥Ø¶Ø§ÙØ© docstrings

### Git:
- [ ] .gitignore Ù…Ø­Ø¯Ø«
- [ ] Commit ÙˆØ§Ø¶Ø­
- [ ] Push to GitHub

---

## ğŸ¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©

### 1. Ø§Ù„ØªÙˆØ§ÙÙ‚ Ø§Ù„Ø®Ù„ÙÙŠ (Backward Compatibility)

Ø§Ù„Ù…Ø­ÙˆÙ„ (Adapter) ÙŠØ¶Ù…Ù†:
- âœ… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±
- âœ… ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ† V1 Ùˆ V2
- âœ… API Ù…ÙˆØ­Ø¯

### 2. Ø§Ù„Ø£Ø¯Ø§Ø¡

Phonology V2 Ø£Ø³Ø±Ø¹ Ù…Ù† V1:
- Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹: O(nÂ²)
- Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙØ¶Ù„ Ù…Ø³Ø§Ø±: O(nÂ²)
- Ø¥Ø¬Ù…Ø§Ù„ÙŠ: ~10ms Ù„ÙƒÙ„Ù…Ø© Ù…ØªÙˆØ³Ø·Ø©

### 3. Ø§Ù„Ø¯Ù‚Ø©

```
V1 (Ø§Ù„Ù‚Ø¯ÙŠÙ…): ~88% Ø¯Ù‚Ø©
V2 (Ø§Ù„Ø¬Ø¯ÙŠØ¯): 100% Ø¯Ù‚Ø© (Ø¹Ù„Ù‰ 81 Ù†Ù…Ø· Ù…Ø®ØªØ¨Ø±)
```

---

## ğŸ› Ø­Ù„ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

### Ù…Ø´ÙƒÙ„Ø©: ModuleNotFoundError

```bash
# Ø§Ù„Ø­Ù„: ØªØ£ÙƒØ¯ Ù…Ù† PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/path/to/Eqratech_Hussein_Hiyassat_Project/src"
```

### Ù…Ø´ÙƒÙ„Ø©: Ù†ØªØ§Ø¦Ø¬ Ù…Ø®ØªÙ„ÙØ© Ø¹Ù† V1

```
Ù‡Ø°Ø§ Ø·Ø¨ÙŠØ¹ÙŠ! V2 Ø£Ø¯Ù‚ Ù…Ù† V1.
Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙÙŠ benchmark_report.json
```

### Ù…Ø´ÙƒÙ„Ø©: Ø¨Ø·Ø¡ ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡

```python
# Ø§Ø³ØªØ®Ø¯Ù… caching:
from functools import lru_cache

@lru_cache(maxsize=1000)
def cached_analyze(word):
    return analyze_word(word)
```

---

## ğŸ“ Ø§Ù„Ø¯Ø¹Ù…

Ø¥Ø°Ø§ ÙˆØ§Ø¬Ù‡Øª Ù…Ø´Ø§ÙƒÙ„:
1. Ø±Ø§Ø¬Ø¹ benchmark_report.json
2. Ø§Ø®ØªØ¨Ø± Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¨Ø³ÙŠØ·Ø© Ø£ÙˆÙ„Ø§Ù‹
3. Ù‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

---

**ØªÙ…Øª ÙƒØªØ§Ø¨Ø© Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© Claude**
**ØªØ§Ø±ÙŠØ®: 2025-02-10**
**Ø§Ù„Ù†Ø³Ø®Ø©: Phonology V2.0**

---

## Post-integration milestones (postâ€“Phonology V2)

After Phonology V2 is integrated and CLI supports `--phonology-v2`, the following milestones are tracked in the **enhanced roadmap** (see repo root: `ENHANCED_ROADMAP.md` and `docs/PLAN_MERGE_ANALYSIS.md`):

| Milestone | Description | Sprint |
|-----------|-------------|--------|
| **Syntax in CLI** | Build WordForms from C2b; run ISNADI; add `result["syntax"]` (isnadi_links). | 1 |
| **TADMINI linker** | Transitive verb â†’ object links; add to `result["syntax"]`. | 2 |
| **TAQYIDI linker** | Nounâ†’adjective, nounâ†’mudhaf ilayh; integrate into parser. | 3 |
| **SyntacticParser** | Orchestrate ISNADI â†’ TADMINI â†’ TAQYIDI; single entry for syntax. | 3 |
| **Constraint modules** | Verbâ€“subject, transitiveâ€“object, adjective agreement, causality, passive (5â€“6 constraints). | 4 |
| **ConstraintValidator** | Input: wordforms + links â†’ output: list of violations. | 4 |
| **Corpus evaluation** | Trial corpus; F1 (morphology), UAS/LAS (syntax); report in docs. | 5 |
| **Polish + 300 tests** | Test count â‰¥300; property-based tests; C2c design doc. | 6 |

These do not modify Phonology V2 or the existing C1/C2a/C2b pipeline; they extend the CLI and add syntax/constraint layers incrementally.


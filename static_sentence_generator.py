import pandas as pd
import sys
import os

class StaticSentenceGenerator:
    """
    Ù…ÙˆÙ„Ø¯ Ø¬Ù…Ù„ ÙŠØ³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø«Ø§Ø¨ØªØ© Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª
    """
    
    def __init__(self):
        self.sentences = []
        self.MAX_SENTENCES = 5000
        
    def get_static_data(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø«Ø§Ø¨ØªØ© Ù„Ù„ØªÙˆÙ„ÙŠØ¯"""
        data = {
            # ÙØ§Ø¹Ù„
            'fael': ['Ø£Ø­Ù…Ø¯', 'ÙØ§Ø·Ù…Ø©', 'Ø§Ù„Ø±Ø¬Ù„', 'Ø§Ù„Ù…Ø±Ø£Ø©', 'Ø§Ù„Ø·Ø§Ù„Ø¨', 'Ø§Ù„Ø·Ø§Ù„Ø¨Ø©', 'Ø§Ù„ÙˆÙ„Ø¯', 'Ø§Ù„Ø¨Ù†Øª', 
                    'Ø§Ù„Ù…Ø¹Ù„Ù…', 'Ø§Ù„Ù…Ø¹Ù„Ù…Ø©', 'Ø§Ù„Ø·Ø¨ÙŠØ¨', 'Ø§Ù„Ù…Ù…Ø±Ø¶Ø©', 'Ø§Ù„ÙƒØ§ØªØ¨', 'Ø§Ù„Ù‚Ø§Ø±Ø¦', 'Ø§Ù„Ø¨Ø§Ø­Ø«'],
            
            # Ø£ÙØ¹Ø§Ù„
            'verbs': ['ÙƒØªØ¨', 'Ù‚Ø±Ø£', 'Ø¯Ø±Ø³', 'Ø¹Ù„Ù…', 'Ø¬Ù„Ø³', 'Ù‚Ø§Ù…', 'Ø°Ù‡Ø¨', 'Ø¬Ø§Ø¡', 'Ø£ÙƒÙ„', 'Ø´Ø±Ø¨', 
                     'Ù†Ø§Ù…', 'Ø§Ø³ØªÙŠÙ‚Ø¸', 'Ø³Ø§ÙØ±', 'ÙˆØµÙ„', 'ÙÙ‡Ù…', 'ØªØ¹Ù„Ù…', 'Ø¹Ù…Ù„', 'Ø³Ø§Ø¹Ø¯', 'Ù„Ø¹Ø¨', 'Ù…Ø´Ù‰'],
            
            # Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡
            'mafool': ['Ø§Ù„ÙƒØªØ§Ø¨', 'Ø§Ù„Ø¯Ø±Ø³', 'Ø§Ù„Ù‚Ù„Ù…', 'Ø§Ù„ÙˆØ±Ù‚Ø©', 'Ø§Ù„Ø·Ø¹Ø§Ù…', 'Ø§Ù„Ù…Ø§Ø¡', 'Ø§Ù„Ø±Ø³Ø§Ù„Ø©', 'Ø§Ù„Ø®Ø¨Ø±',
                      'Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©', 'Ø§Ù„Ø¹Ù„Ù…', 'Ø§Ù„ÙÙ†', 'Ø§Ù„Ù„ØºØ©', 'Ø§Ù„Ù‚ØµØ©', 'Ø§Ù„Ø´Ø¹Ø±', 'Ø§Ù„Ù…Ù‚Ø§Ù„'],
            
            # Ø£Ø³Ù…Ø§Ø¡ Ø¹Ø§Ù…Ø©
            'nouns': ['Ø§Ù„Ø¨ÙŠØª', 'Ø§Ù„Ù…Ø¯Ø±Ø³Ø©', 'Ø§Ù„Ø­Ø¯ÙŠÙ‚Ø©', 'Ø§Ù„Ù…ÙƒØªØ¨Ø©', 'Ø§Ù„Ø³ÙˆÙ‚', 'Ø§Ù„Ù…Ø³Ø¬Ø¯', 'Ø§Ù„Ø´Ø§Ø±Ø¹', 
                     'Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©', 'Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰', 'Ø§Ù„Ù…ØªØ­Ù', 'Ø§Ù„Ù…Ø·Ø¹Ù…', 'Ø§Ù„ÙÙ†Ø¯Ù‚', 'Ø§Ù„Ù…Ø·Ø§Ø±', 'Ø§Ù„Ù…Ø­Ø·Ø©'],
            
            # ØµÙØ§Øª
            'adjectives': ['Ø¬Ù…ÙŠÙ„', 'ÙƒØ¨ÙŠØ±', 'ØµØºÙŠØ±', 'Ø·ÙˆÙŠÙ„', 'Ù‚ØµÙŠØ±', 'Ø°ÙƒÙŠ', 'Ù†Ø´ÙŠØ·', 'Ù…Ø¬ØªÙ‡Ø¯', 
                          'Ø³Ø¹ÙŠØ¯', 'Ø­Ø²ÙŠÙ†', 'Ø¬Ø¯ÙŠØ¯', 'Ù‚Ø¯ÙŠÙ…', 'Ø³Ø±ÙŠØ¹', 'Ø¨Ø·ÙŠØ¡', 'Ù‚ÙˆÙŠ', 'Ø¶Ø¹ÙŠÙ'],
            
            # Ø­Ø±ÙˆÙ Ø¬Ø±
            'jar': ['ÙÙŠ', 'Ø¥Ù„Ù‰', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø¹Ù†', 'Ù…Ø¹', 'Ø¨Ø¯ÙˆÙ†', 'Ø¶Ø¯', 'Ø­ÙˆÙ„', 'ØªØ­Øª', 'ÙÙˆÙ‚', 'Ø£Ù…Ø§Ù…', 'Ø®Ù„Ù'],
            
            # Ø£Ø¯ÙˆØ§Øª Ù†ÙÙŠ
            'nafi': ['Ù„Ø§', 'Ù…Ø§', 'Ù„Ù…', 'Ù„Ù†', 'Ù„ÙŠØ³'],
            
            # Ø£Ø¯ÙˆØ§Øª Ø§Ø³ØªÙÙ‡Ø§Ù…
            'istifham': ['Ù‡Ù„', 'Ù…Ø§Ø°Ø§', 'Ù…ØªÙ‰', 'Ø£ÙŠÙ†', 'ÙƒÙŠÙ', 'Ù„Ù…Ø§Ø°Ø§', 'Ù…ÙÙ†', 'Ù…Ø§'],
            
            # Ø£Ø¯ÙˆØ§Øª Ø¹Ø·Ù
            'atf': ['Ùˆ', 'Ø£Ùˆ', 'Ù„ÙƒÙ†', 'Ø¨Ù„', 'Ø«Ù…'],
            
            # Ø£Ø³Ù…Ø§Ø¡ Ø¥Ø´Ø§Ø±Ø©
            'demonstratives': ['Ù‡Ø°Ø§', 'Ù‡Ø°Ù‡', 'Ø°Ù„Ùƒ', 'ØªÙ„Ùƒ', 'Ù‡Ø¤Ù„Ø§Ø¡', 'Ø£ÙˆÙ„Ø¦Ùƒ'],
            
            # Ø¸Ø±ÙˆÙ
            'adverbs': ['Ø§Ù„ÙŠÙˆÙ…', 'Ø£Ù…Ø³', 'ØºØ¯Ø§Ù‹', 'Ø§Ù„Ø¢Ù†', 'ØµØ¨Ø§Ø­Ø§Ù‹', 'Ù…Ø³Ø§Ø¡Ù‹', 'Ù‡Ù†Ø§', 'Ù‡Ù†Ø§Ùƒ', 'Ø¨Ø³Ø±Ø¹Ø©', 'Ø¨Ø¨Ø·Ø¡'],
            
            # Ø£Ø¹Ù„Ø§Ù…
            'proper_nouns': ['Ù…Ø­Ù…Ø¯', 'Ø¹Ù„ÙŠ', 'Ø®Ø¯ÙŠØ¬Ø©', 'Ø¹Ø§Ø¦Ø´Ø©', 'Ù…ÙƒØ©', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©', 'Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©', 'Ø¨ØºØ¯Ø§Ø¯', 'Ø¯Ù…Ø´Ù‚'],
            
            # Ù†Ø¯Ø§Ø¡
            'nida': ['ÙŠØ§', 'Ø£ÙŠÙ‘', 'Ø£ÙŠÙ‘ØªÙ‡Ø§'],
        }
        return data
    
    def add_sentence(self, sentence, pattern, stype, components):
        """Ø¥Ø¶Ø§ÙØ© Ø¬Ù…Ù„Ø© Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©"""
        sentence = sentence.strip()
        if not sentence or len(self.sentences) >= self.MAX_SENTENCES:
            return False
        
        # Ø¨Ù†Ø§Ø¡ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        comp_strings = []
        for label, token in components:
            comp_strings.append(f"{label}={token}")
        
        self.sentences.append({
            'Ø§Ù„Ø£Ø¯Ø§Ø©': sentence,
            'Ø§Ù„Ù‚Ø§Ù„Ø¨/Ø§Ù„ØªØ±ÙƒÙŠØ¨': pattern,
            'Ø§Ù„Ù†ÙˆØ¹': stype,
            'Ù…ÙƒÙˆÙ‘Ù†Ø§Øª': ' | '.join(comp_strings),
            'UTF-8 Ù„Ù„Ù…ÙƒÙˆÙ‘Ù†Ø§Øª': '',
            'Ø§Ù„ÙÙˆÙ†ÙŠÙ…Ø§Øª': '',
            'Ø§Ù„Ø­Ø±ÙƒØ§Øª': '',
            'Ø´Ø±Ø·/Ø³ÙŠØ§Ù‚': 'static generation',
            'Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù†Ø­ÙˆÙŠØ©': f'Ø¬Ù…Ù„Ø© {stype}',
            'Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©': 'Ù…Ø«Ø§Ù„ ØªØ·Ø¨ÙŠÙ‚ÙŠ',
            'Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµØ±ÙÙŠØ©': 'ØªØ±ÙƒÙŠØ¨',
            'Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØªÙŠØ©': f'ÙƒÙ„Ù…Ø§Øª:{len(sentence.split())}',
            'Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø§Ø´ØªÙ‚Ø§Ù‚ÙŠØ©': pattern,
            'Ù…Ù„Ø§Ø­Ø¸Ø§Øª': f'Ù…ÙˆÙ„Ø¯ Ù…Ù† Ù†Ù…Ø·: {pattern}'
        })
        
        return True
    
    def generate_comprehensive_sentences(self):
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø´Ø§Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ø¬Ù…Ù„"""
        print("\n=== Ø¨Ø¯Ø¡ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø¬Ù…Ù„ ===")
        
        data = self.get_static_data()
        
        # 1. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (ÙØ§Ø¹Ù„ + ÙØ¹Ù„)
        print("[1] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")
        count1 = 0
        for fael in data['fael']:
            for verb in data['verbs']:
                if self.add_sentence(f"{fael} {verb}", 'ÙØ§Ø¹Ù„+ÙØ¹Ù„', 'ÙØ¹Ù„ÙŠØ©', 
                                   [('ÙØ§Ø¹Ù„', fael), ('ÙØ¹Ù„', verb)]):
                    count1 += 1
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count1} Ø¬Ù…Ù„Ø© ÙØ¹Ù„ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ©")
        
        # 2. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯ÙŠØ© (ÙØ§Ø¹Ù„ + ÙØ¹Ù„ + Ù…ÙØ¹ÙˆÙ„)
        print("[2] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø§Ù„Ù…ØªØ¹Ø¯ÙŠØ©...")
        count2 = 0
        for fael in data['fael'][:10]:  # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ø¯Ø¯ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¬Ø§ÙˆØ²
            for verb in data['verbs'][:10]:
                for mafool in data['mafool'][:10]:
                    if self.add_sentence(f"{fael} {verb} {mafool}", 'ÙØ§Ø¹Ù„+ÙØ¹Ù„+Ù…ÙØ¹ÙˆÙ„', 'ÙØ¹Ù„ÙŠØ© Ù…ØªØ¹Ø¯ÙŠØ©', 
                                       [('ÙØ§Ø¹Ù„', fael), ('ÙØ¹Ù„', verb), ('Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡', mafool)]):
                        count2 += 1
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count2} Ø¬Ù…Ù„Ø© ÙØ¹Ù„ÙŠØ© Ù…ØªØ¹Ø¯ÙŠØ©")
        
        # 3. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø§Ø³Ù…ÙŠØ© (Ù…Ø¨ØªØ¯Ø£ + Ø®Ø¨Ø±)
        print("[3] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø§Ø³Ù…ÙŠØ©...")
        count3 = 0
        for mubtada in data['nouns'][:12]:
            for khabar in data['adjectives'][:12]:
                if self.add_sentence(f"{mubtada} {khabar}", 'Ù…Ø¨ØªØ¯Ø£+Ø®Ø¨Ø±', 'Ø§Ø³Ù…ÙŠØ©', 
                                   [('Ù…Ø¨ØªØ¯Ø£', mubtada), ('Ø®Ø¨Ø±', khabar)]):
                    count3 += 1
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count3} Ø¬Ù…Ù„Ø© Ø§Ø³Ù…ÙŠØ©")
        
        # 4. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…ÙŠØ©
        print("[4] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù…ÙŠØ©...")
        count4 = 0
        for istifham in data['istifham'][:6]:
            for fael in data['fael'][:8]:
                for verb in data['verbs'][:8]:
                    if self.add_sentence(f"{istifham} {fael} {verb}", 'Ø§Ø³ØªÙÙ‡Ø§Ù…+ÙØ§Ø¹Ù„+ÙØ¹Ù„', 'Ø§Ø³ØªÙÙ‡Ø§Ù…ÙŠØ©', 
                                       [('Ø§Ø³ØªÙÙ‡Ø§Ù…', istifham), ('ÙØ§Ø¹Ù„', fael), ('ÙØ¹Ù„', verb)]):
                        count4 += 1
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count4} Ø¬Ù…Ù„Ø© Ø§Ø³ØªÙÙ‡Ø§Ù…ÙŠØ©")
        
        # 5. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ù†ÙÙŠØ©
        print("[5] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ù†ÙÙŠØ©...")
        count5 = 0
        for nafi in data['nafi']:
            for fael in data['fael'][:10]:
                for verb in data['verbs'][:10]:
                    if self.add_sentence(f"{nafi} {fael} {verb}", 'Ù†ÙÙŠ+ÙØ§Ø¹Ù„+ÙØ¹Ù„', 'Ù…Ù†ÙÙŠØ©', 
                                       [('Ù†ÙÙŠ', nafi), ('ÙØ§Ø¹Ù„', fael), ('ÙØ¹Ù„', verb)]):
                        count5 += 1
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count5} Ø¬Ù…Ù„Ø© Ù…Ù†ÙÙŠØ©")
        
        # 6. Ø´Ø¨Ù‡ Ø§Ù„Ø¬Ù…Ù„ (Ø¬Ø§Ø± + Ù…Ø¬Ø±ÙˆØ±)
        print("[6] Ø´Ø¨Ù‡ Ø§Ù„Ø¬Ù…Ù„...")
        count6 = 0
        for jar in data['jar']:
            for noun in data['nouns']:
                if self.add_sentence(f"{jar} {noun}", 'Ø¬Ø§Ø±+Ù…Ø¬Ø±ÙˆØ±', 'Ø´Ø¨Ù‡ Ø¬Ù…Ù„Ø©', 
                                   [('Ø­Ø±Ù Ø¬Ø±', jar), ('Ù…Ø¬Ø±ÙˆØ±', noun)]):
                    count6 += 1
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count6} Ø´Ø¨Ù‡ Ø¬Ù…Ù„Ø©")
        
        # 7. Ø¬Ù…Ù„ Ø§Ù„Ù†Ø¯Ø§Ø¡
        print("[7] Ø¬Ù…Ù„ Ø§Ù„Ù†Ø¯Ø§Ø¡...")
        count7 = 0
        for nida in data['nida']:
            for name in data['proper_nouns']:
                if self.add_sentence(f"{nida} {name}", 'Ù†Ø¯Ø§Ø¡+Ù…Ù†Ø§Ø¯Ù‰', 'Ù†Ø¯Ø§Ø¦ÙŠØ©', 
                                   [('Ø£Ø¯Ø§Ø© Ù†Ø¯Ø§Ø¡', nida), ('Ù…Ù†Ø§Ø¯Ù‰', name)]):
                    count7 += 1
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count7} Ø¬Ù…Ù„Ø© Ù†Ø¯Ø§Ø¦ÙŠØ©")
        
        # 8. Ø¬Ù…Ù„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©
        print("[8] Ø¬Ù…Ù„ Ø§Ù„Ø¥Ø´Ø§Ø±Ø©...")
        count8 = 0
        for demo in data['demonstratives']:
            for noun in data['nouns'][:12]:
                if self.add_sentence(f"{demo} {noun}", 'Ø¥Ø´Ø§Ø±Ø©+Ø§Ø³Ù…', 'Ø¥Ø´Ø§Ø±ÙŠØ©', 
                                   [('Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©', demo), ('Ù…Ø´Ø§Ø± Ø¥Ù„ÙŠÙ‡', noun)]):
                    count8 += 1
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count8} Ø¬Ù…Ù„Ø© Ø¥Ø´Ø§Ø±ÙŠØ©")
        
        # 9. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¸Ø±ÙÙŠØ©
        print("[9] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¸Ø±ÙÙŠØ©...")
        count9 = 0
        for fael in data['fael'][:8]:
            for verb in data['verbs'][:8]:
                for adv in data['adverbs'][:10]:
                    if self.add_sentence(f"{fael} {verb} {adv}", 'ÙØ§Ø¹Ù„+ÙØ¹Ù„+Ø¸Ø±Ù', 'Ø¸Ø±ÙÙŠØ©', 
                                       [('ÙØ§Ø¹Ù„', fael), ('ÙØ¹Ù„', verb), ('Ø¸Ø±Ù', adv)]):
                        count9 += 1
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count9} Ø¬Ù…Ù„Ø© Ø¸Ø±ÙÙŠØ©")
        
        # 10. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø¹Ø·ÙˆÙØ©
        print("[10] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø¹Ø·ÙˆÙØ©...")
        count10 = 0
        for fael1 in data['fael'][:6]:
            for verb1 in data['verbs'][:6]:
                for atf in data['atf'][:4]:
                    for fael2 in data['fael'][:6]:
                        for verb2 in data['verbs'][:6]:
                            if fael1 != fael2 or verb1 != verb2:  # ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±
                                sentence = f"{fael1} {verb1} {atf} {fael2} {verb2}"
                                if self.add_sentence(sentence, 'ÙØ§Ø¹Ù„+ÙØ¹Ù„+Ø¹Ø·Ù+ÙØ§Ø¹Ù„+ÙØ¹Ù„', 'Ù…Ø¹Ø·ÙˆÙØ©', 
                                                   [('ÙØ§Ø¹Ù„1', fael1), ('ÙØ¹Ù„1', verb1), ('Ø¹Ø·Ù', atf), 
                                                    ('ÙØ§Ø¹Ù„2', fael2), ('ÙØ¹Ù„2', verb2)]):
                                    count10 += 1
                            if len(self.sentences) >= self.MAX_SENTENCES: break
                        if len(self.sentences) >= self.MAX_SENTENCES: break
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count10} Ø¬Ù…Ù„Ø© Ù…Ø¹Ø·ÙˆÙØ©")
        
        # 11. Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø±ÙƒØ¨Ø© (Ø¬Ø§Ø±+Ù…Ø¬Ø±ÙˆØ± Ù…Ø¹ ÙØ¹Ù„)
        print("[11] Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ù…Ø±ÙƒØ¨Ø©...")
        count11 = 0
        for fael in data['fael'][:6]:
            for verb in data['verbs'][:6]:
                for jar in data['jar'][:8]:
                    for noun in data['nouns'][:8]:
                        sentence = f"{fael} {verb} {jar} {noun}"
                        if self.add_sentence(sentence, 'ÙØ§Ø¹Ù„+ÙØ¹Ù„+Ø¬Ø§Ø±+Ù…Ø¬Ø±ÙˆØ±', 'Ù…Ø±ÙƒØ¨Ø©', 
                                           [('ÙØ§Ø¹Ù„', fael), ('ÙØ¹Ù„', verb), ('Ø¬Ø§Ø±', jar), ('Ù…Ø¬Ø±ÙˆØ±', noun)]):
                            count11 += 1
                        if len(self.sentences) >= self.MAX_SENTENCES: break
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count11} Ø¬Ù…Ù„Ø© Ù…Ø±ÙƒØ¨Ø©")
        
        # 12. Ø¬Ù…Ù„ Ù…ØªÙ†ÙˆØ¹Ø© (Ø¥Ø´Ø§Ø±Ø© + Ø§Ø³Ù… + ØµÙØ©)
        print("[12] Ø¬Ù…Ù„ ÙˆØµÙÙŠØ©...")
        count12 = 0
        for demo in data['demonstratives'][:4]:
            for noun in data['nouns'][:8]:
                for adj in data['adjectives'][:8]:
                    sentence = f"{demo} {noun} {adj}"
                    if self.add_sentence(sentence, 'Ø¥Ø´Ø§Ø±Ø©+Ø§Ø³Ù…+ØµÙØ©', 'ÙˆØµÙÙŠØ©', 
                                       [('Ø¥Ø´Ø§Ø±Ø©', demo), ('Ù…ÙˆØµÙˆÙ', noun), ('ØµÙØ©', adj)]):
                        count12 += 1
                    if len(self.sentences) >= self.MAX_SENTENCES: break
                if len(self.sentences) >= self.MAX_SENTENCES: break
            if len(self.sentences) >= self.MAX_SENTENCES: break
        print(f"   ØªÙˆÙ„ÙŠØ¯ {count12} Ø¬Ù…Ù„Ø© ÙˆØµÙÙŠØ©")
        
        total = count1 + count2 + count3 + count4 + count5 + count6 + count7 + count8 + count9 + count10 + count11 + count12
        print(f"\n=== Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙˆÙ„ÙŠØ¯: {total} Ø¬Ù…Ù„Ø© Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© ===")
        
        return pd.DataFrame(self.sentences) if self.sentences else pd.DataFrame()
    
    def save_comprehensive_excel(self, filename="comprehensive_arabic_sentences.xlsx"):
        """Ø­ÙØ¸ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø´Ø§Ù…Ù„Ø© ÙÙŠ Excel"""
        try:
            result_dataframe = self.generate_comprehensive_sentences()
            
            if not result_dataframe.empty:
                result_dataframe.to_excel(filename, index=False, sheet_name='Ø§Ù„Ø¬Ù…Ù„_Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©_Ø§Ù„Ø´Ø§Ù…Ù„Ø©')
                print(f"\nâœ… ØªÙ… Ø­ÙØ¸ {len(result_dataframe)} Ø¬Ù…Ù„Ø© ÙÙŠ {filename}")
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:")
                print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¬Ù…Ù„: {len(result_dataframe)}")
                print(f"   â€¢ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {len(result_dataframe.columns)}")
                
                # Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¬Ù…Ù„
                types = result_dataframe['Ø§Ù„Ù†ÙˆØ¹'].value_counts()
                print(f"   â€¢ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¬Ù…Ù„:")
                for stype, count in types.items():
                    print(f"     - {stype}: {count}")
                
                return True
            else:
                print("âŒ Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø£ÙŠ Ø¬Ù…Ù„")
                return False
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸: {str(e)}")
            return False


# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
if __name__ == "__main__":
    print("ğŸš€ Ø¨Ø¯Ø¡ Ù…ÙˆÙ„Ø¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„...")
    generator = StaticSentenceGenerator()
    success = generator.save_comprehensive_excel("comprehensive_arabic_grammar.xlsx")
    
    if success:
        print("\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­!")
    else:
        print("\nğŸ’¥ ÙØ´Ù„ ÙÙŠ Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯!")